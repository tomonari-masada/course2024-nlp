{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/07_PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2zN0IvyqF"
      },
      "source": [
        "# PyTorchå…¥é–€ (3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXenjmLeAJjA"
      },
      "source": [
        "## ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡\n",
        "* https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        "\n",
        "* ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹ã¨ã“ã‚ä»¥å¤–ã¯ã€å¤§å¹…ã«å¤‰ãˆã¦ã„ã‚‹ã€‚\n",
        "  * ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®è¨“ç·´ã‹ã‚‰è‡ªå‰ã§ãŠã“ãªã†ã“ã¨ã«ã—ãŸã€‚\n",
        "  * ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯Hugging Faceã®datasetsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ä½¿ã†ã‚ˆã†ã«ã—ãŸã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAv8yYt8-Yn0"
      },
      "source": [
        "* ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’GPUã«è¨­å®šã—ã¦ãŠã“ã†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIHq0CF9oMqf"
      },
      "source": [
        "## æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Lnd-ekgblc"
      },
      "source": [
        "### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esbFOZ9pZso"
      },
      "source": [
        "* Hugging Faceã®datasetsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨tokenizersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbjXLZStpYp9"
      },
      "outputs": [],
      "source": [
        "!pip install datasets tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0jLWNWjk1DO"
      },
      "source": [
        "## å†ç¾æ€§ã®ç¢ºä¿\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2v7WucbEcF8"
      },
      "source": [
        "* å†ç¾æ€§\n",
        "  * https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EecUGZKspEal"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KPNSH_uKI7q"
      },
      "source": [
        "## ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATicCrfrKIXL"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MU1kOIZpGuB"
      },
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvExI-tmpI_4"
      },
      "source": [
        "### AG Newsãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "* ä»Šå›ã¯AG_NEWSã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã†ã€‚\n",
        "  * 4ã‚¯ãƒ©ã‚¹åˆ†é¡å•é¡Œã‚’è§£ãã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7p6LtyekseI"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"ag_news\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Q3qFfre1Vd"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EdVC8h0V7Hq"
      },
      "source": [
        "* ãƒ©ãƒ™ãƒ«ã®æ„å‘³ã¯ã€ä»¥ä¸‹ã®é€šã‚Šã€‚ï¼ˆ https://huggingface.co/datasets/ag_news ã‚’å‚ç…§ã€‚ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWE6VFnqV0f1"
      },
      "outputs": [],
      "source": [
        "ag_news_label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tec\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwIOEuIbWDWV"
      },
      "source": [
        "* ä¸­èº«ã‚’å°‘ã—è¦‹ã¦ã¿ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALJZeVnYEo2C"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTQAsjRKIWgY"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHz5r5qHVO7P"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][\"label\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa9KBFMYP7iv"
      },
      "outputs": [],
      "source": [
        "print(f\"number of different labels: {len(set(dataset['train']['label']))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6htLjG3feGD"
      },
      "source": [
        "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O18EBvE5OSZj"
      },
      "outputs": [],
      "source": [
        "train_valid = dataset[\"train\"].train_test_split(test_size=0.05)\n",
        "train_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9HDarWfOVZQ"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_valid[\"train\"],\n",
        "    \"valid\": train_valid[\"test\"],\n",
        "    \"test\": dataset[\"test\"],\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "wrwVPWo9u1Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDcs6sxBqWLa"
      },
      "source": [
        "## ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶\n",
        "* ä»¥ä¸‹ã®èª¬æ˜ã¯ã€ã»ã¼æ¬¡ã®Hugging Faceã®documentationãã®ã¾ã¾ã€‚\n",
        "  * https://huggingface.co/docs/tokenizers/pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDHxdhmfF2L7"
      },
      "source": [
        "### ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
        "* ä»Šå›ã¯WordPieceã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ã†ã€‚\n",
        "  * https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt\n",
        "  * https://huggingface.co/docs/tokenizers/api/models#tokenizers.models.BPE\n",
        "* è¦‹ãŸã“ã¨ãŒãªã„æ–‡å­—åˆ—ã¯ã€unknownãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ¤œå‡ºã™ã‚‹ã€‚\n",
        "  * unknownãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¿ã‘ã‚‹ã«ã¯ã€byteãƒ¬ãƒ™ãƒ«ã§ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚Œã°è‰¯ã„ã€‚\n",
        "  * ã ãŒã€ä»Šå›ã¯ã€ã“ã®ã‚ˆã†ãªé«˜åº¦ãªãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¯è¡Œã‚ãªã„ã€‚\n",
        "  * byteãƒ¬ãƒ™ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«ã¤ã„ã¦ã¯ã€\n",
        "  [ã“ã“](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt)ã®ç·‘è‰²ã®ã‚³ãƒ¡ãƒ³ãƒˆéƒ¨åˆ†ã‚’å‚ç…§ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdtZhLnpF5Gs"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "\n",
        "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlr_649UeVv"
      },
      "outputs": [],
      "source": [
        "tokenizer.model.unk_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBinPZyBYnWd"
      },
      "source": [
        "### ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–\n",
        "* NFDã«ã¤ã„ã¦ã¯ã€ä¾‹ãˆã°ã€ä¸‹ã®è¨˜äº‹ã‚’å‚ç…§ã€‚\n",
        "  * https://qiita.com/fury00812/items/b98a7f9428d1395fc230\n",
        "* Lowercase()ã¯å°æ–‡å­—åŒ–ã€StripAccents()ã¯ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ã®é™¤å»ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGOZg8SaWjEJ"
      },
      "outputs": [],
      "source": [
        "from tokenizers import normalizers\n",
        "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
        "\n",
        "tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MfvNaxudAId"
      },
      "source": [
        "* ã“ã®normalizerãŒã©ã‚“ãªæ­£è¦åŒ–ã‚’ã™ã‚‹ã‹ã€è¦‹ã¦ã¿ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpRm7nFec9cZ"
      },
      "outputs": [],
      "source": [
        "tokenizer.normalizer.normalize_str(\"HÃ©llÃ² hÃ´w are Ã¼?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9SeBf0iGv4x"
      },
      "source": [
        "### ãƒ—ãƒ¬ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶\n",
        "* ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’è¨“ç·´ã•ã›ã‚‹ã¨ãã€æœ€åˆã«ç„¡æ¡ä»¶ã«å®Ÿè¡Œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚’è¨­å®šã™ã‚‹ã€‚\n",
        "* ä¾‹ãˆã°ã€è‹±èªã®å ´åˆã€ã¾ãšã¯ç„¡æ¡ä»¶ã«ç©ºç™½æ–‡å­—ã§ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹ã®ãŒæ™®é€šã€‚\n",
        "  * https://huggingface.co/docs/tokenizers/api/pre-tokenizers#tokenizers.pre_tokenizers.Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xzIt-AGHCiO"
      },
      "outputs": [],
      "source": [
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "tokenizer.pre_tokenizer = Whitespace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioZHJU-yGTx9"
      },
      "source": [
        "### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®Trainer\n",
        "* ä»Šå›ã¯ã€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®šã‚’é™¤ã„ã¦ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šã‚’ä½¿ã†ã€‚\n",
        "  * ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã¯ã€ä»Šå›ã¯å®Ÿéš›ã«ã¯`[UNK]`ã—ã‹ä½¿ã‚ãªã„ã€‚\n",
        "  * ã“ã®ã‚ˆã†ã«æ›¸ã‘ã°è‰¯ã„ã¨ã„ã†ä¾‹ã¨ã—ã¦ã€ä»–ã®ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚‚ç¤ºã—ã¦ãŠãã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLQ12LPHGa3_"
      },
      "outputs": [],
      "source": [
        "from tokenizers.trainers import WordPieceTrainer\n",
        "\n",
        "trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzfpLppxGngC"
      },
      "outputs": [],
      "source": [
        "trainer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P-wl_ikUsWF"
      },
      "outputs": [],
      "source": [
        "trainer.special_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uISKPGWHHmO3"
      },
      "source": [
        "### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®è¨“ç·´\n",
        "* èªå½™é›†åˆã‚’æ±ºã‚ã‚‹ã¨ãã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã ã‘ã‚’ä½¿ã†ã€‚\n",
        "* trainerã‚’ä¸ãˆã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã‚ˆã†ã«ã€‚\n",
        "  * trainerã‚’ä¸ãˆã‚‹ã®ã‚’å¿˜ã‚Œã‚‹ã¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®šã§è¨“ç·´ã•ã‚Œã¦ã—ã¾ã†ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AG3u8G-HeRF"
      },
      "outputs": [],
      "source": [
        "tokenizer.train_from_iterator(dataset[\"train\"][\"text\"], trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMGW8almdhOh"
      },
      "source": [
        "* è¨“ç·´ã—ãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ã€JSONå½¢å¼ã§ä¿å­˜ã‚‚ã§ãã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS_Q39gJZMOJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/2024courses/nlp\"\n",
        "\n",
        "tokenizer.save(os.path.join(save_dir, \"my-tokenizer.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inu8JAr9djWP"
      },
      "source": [
        "* èªå½™ã‚µã‚¤ã‚º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HugHDvHv3mjt"
      },
      "outputs": [],
      "source": [
        "tokenizer.get_vocab_size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiSCXpKSdlIm"
      },
      "source": [
        "* èªå½™ã®å–å¾—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_TXMjnNIh-C"
      },
      "outputs": [],
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg537L4udnQU"
      },
      "source": [
        "* `[UNK]`ãƒˆãƒ¼ã‚¯ãƒ³ãŒèªå½™ã«å…¥ã£ã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQs9G2RxU4L4"
      },
      "outputs": [],
      "source": [
        "tokenizer.model.unk_token in vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwPfiU3Xq8qA"
      },
      "source": [
        "* å˜èªãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ—ãŒæ•´æ•°ã®åˆ—ã«å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JxplX7Eq5kj"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.encode(dataset[\"train\"][\"text\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSTOkdNFQ92x"
      },
      "outputs": [],
      "source": [
        "print(dataset[\"train\"][\"text\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3F6t2bDIwvo"
      },
      "outputs": [],
      "source": [
        "print(output.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueoaEp9aJV1-"
      },
      "outputs": [],
      "source": [
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiSXO-noJcEq"
      },
      "source": [
        "* offsetsã¯å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒä½•æ–‡å­—ç›®ã‹ã‚‰ä½•æ–‡å­—ç›®ã¾ã§ã‹ã‚’è¡¨ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oivhonJfyOqE"
      },
      "outputs": [],
      "source": [
        "print(output.offsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Cp3Yw8aCP3"
      },
      "source": [
        "* æ¬¡ã«ã€ã‚ã–ã¨ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãŒè¦‹ãŸã“ã¨ãªã•ãã†ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã›ã¦ã¿ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xVPZrvPZlqo"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.encode(\"Welcome to the ğŸ¤— Tokenizers library.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uwi0FTcdvqv"
      },
      "source": [
        "* çµµæ–‡å­—ãŒ`[UNK]`ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNIFXqR8aJn4"
      },
      "outputs": [],
      "source": [
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60xaGMzv3_XW"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUaiRtBo4VKO"
      },
      "source": [
        "### collateé–¢æ•°\n",
        "* ã‚µãƒ³ãƒ—ãƒ«ã«å‰å‡¦ç†ã‚’æ–½ã—ã¦ãƒŸãƒ‹ãƒãƒƒãƒã‚’ä½œã‚‹ã“ã¨ã‚’ã€collateã™ã‚‹ã€ã¨è¨€ã†ã€‚\n",
        "* collateé–¢æ•°ã®ä¸­ã§ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ã€‚\n",
        "* ä»Šå›ã¯ã€åŒã˜ãƒŸãƒ‹ãƒãƒƒãƒã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã™ã¹ã¦ã¤ãªã’ã¦ã—ã¾ã†ã€‚\n",
        "  * `offsets`ã¯ã€å„ãƒ†ã‚­ã‚¹ãƒˆãŒã€å…ˆé ­ã‹ã‚‰æ•°ãˆã¦ä½•ãƒˆãƒ¼ã‚¯ãƒ³ç›®ã‹ã‚‰å§‹ã¾ã‚‹ã‹ã‚’è¡¨ã™ã€‚\n",
        "  * æ­£ç¢ºã«ã¯ã€å…ˆé ­ã‹ã‚‰æ•°ãˆã¦ä½•ãƒˆãƒ¼ã‚¯ãƒ³ç›®ã‹ã‚‰å§‹ã¾ã‚‹ã‹ã€ãƒã‚¤ãƒŠã‚¹ï¼‘ã€ãŒã‚ªãƒ•ã‚»ãƒƒãƒˆã€‚\n",
        "* ã“ã®collateé–¢æ•°ã¯ã€å¾Œã§DataLoaderã‚’ä½œã‚‹ã¨ãã«ä½¿ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRrfbx4W4T2n"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "  label_list, text_list, offsets = [], [], [0]\n",
        "  for instance in batch:\n",
        "    _label, _text = instance[\"label\"], instance[\"text\"]\n",
        "    # ãƒ©ãƒ™ãƒ«ã¯ãƒ©ãƒ™ãƒ«ã§é›†ã‚ã‚‹\n",
        "    label_list.append(_label)\n",
        "    token_ids = torch.tensor(tokenizer.encode(_text).ids, dtype=torch.int64)\n",
        "    # ãƒˆãƒ¼ã‚¯ãƒ³idã®åˆ—ã‚‚é›†ã‚ã‚‹\n",
        "    text_list.append(token_ids)\n",
        "    # ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚‚é›†ã‚ã‚‹\n",
        "    offsets.append(token_ids.size(0))\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiPXZZyim7Zi"
      },
      "source": [
        "* è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®DataLoaderã‚’ä½œã‚‹ã€‚\n",
        "* collateé–¢æ•°ã®ä½¿ã„æ–¹ã«æ³¨ç›®ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Odw2RSygNw0"
      },
      "source": [
        "### DataLoaderã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ-6jH0h4E-1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ãƒŸãƒ‹ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã‚’é©å½“ã«æ±ºã‚ã‚‹\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset[\"valid\"], batch_size=BATCH_SIZE, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset[\"test\"], batch_size=BATCH_SIZE, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkuKQtIWK3s7"
      },
      "outputs": [],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP6WNSYVeUfn"
      },
      "source": [
        "## `torch.nn.EmbeddingBag`\n",
        "* å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã®embeddingã®å¹³å‡ã‚’ä¸€æŒ™ã«æ±‚ã‚ã‚‹layerã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgl4XiG1qLIT"
      },
      "source": [
        "* èª¬æ˜ç›®çš„ã§ã€è¦‹ã‚„ã™ã„ã‚ˆã†ã«ä½æ¬¡å…ƒã§åŸ‹ã‚è¾¼ã¿å±¤ã‚’ä½œã£ã¦ã¿ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtrYIvX0eS3r"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "embedding = nn.EmbeddingBag(len(vocab), 8, sparse=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BVikXBriB_Q"
      },
      "source": [
        "* æœ¬å½“ã«å¹³å‡ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpdkpArLeqj-"
      },
      "outputs": [],
      "source": [
        "text = \"language models\"\n",
        "input = torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "embedding(input=input, offsets=offsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAmoerAPj8t"
      },
      "outputs": [],
      "source": [
        "tokenizer.encode(text).tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_3fX1GCg_73"
      },
      "outputs": [],
      "source": [
        "text = \"language\"\n",
        "input = torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "output1 = embedding(input=input, offsets=offsets)\n",
        "output1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnTSVqsPhCEW"
      },
      "outputs": [],
      "source": [
        "text = \"models\"\n",
        "input = torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "output2 = embedding(input=input, offsets=offsets)\n",
        "output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5mc0lLghNOm"
      },
      "outputs": [],
      "source": [
        "(output1 + output2) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ig_SXomh8oN"
      },
      "source": [
        "* offsetsã¯ãƒ†ã‚­ã‚¹ãƒˆã®åˆ‡ã‚Œç›®ã‚’è¡¨ã™ã€‚\n",
        "  * offsetsã‚’åˆ©ç”¨ã™ã‚Œã°ã€è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã¤ãªã’ãŸã¾ã¾ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã§ãã‚‹ã€‚\n",
        "  * ãƒ¡ãƒ¢ãƒªã®åŠ¹ç‡ã‚‚æ™‚é–“çš„ãªåŠ¹ç‡ã‚‚è‰¯ã„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggS8gooLP0B7"
      },
      "outputs": [],
      "source": [
        "text = \"language models text classification\"\n",
        "tokenizer.encode(text).tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-IAl8zER_Ud"
      },
      "source": [
        "* ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’æŒ‡å®šã—ã¦embedã™ã‚‹ã€‚\n",
        "  * ã“ã®ä¾‹ã§ã¯ã€\"text classification\"ãŒäºŒã¤ç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãªã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGHLsNTWh0mQ"
      },
      "outputs": [],
      "source": [
        "text = \"language models text classification\"\n",
        "input = torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
        "offsets = torch.tensor([0, 2], dtype=torch.int64)\n",
        "embedding(input=input, offsets=offsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnexLcZ6Pkl"
      },
      "source": [
        "## åˆ†é¡ãƒ¢ãƒ‡ãƒ«\n",
        "* `nn.Module`ã‚’ç¶™æ‰¿ã—ã¦è‡ªå‰ã®ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã™ã‚‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRJysWR_r9cW"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super(TextClassificationModel, self).__init__()\n",
        "    # åŸ‹ã‚è¾¼ã¿å±¤\n",
        "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "    # åˆ†é¡ç”¨ã®å…¨çµåˆå±¤\n",
        "    self.fc = nn.Linear(embed_dim, num_class)\n",
        "    # è‡ªå‰ã®é‡ã¿åˆæœŸåŒ–é–¢æ•°ã‚’å‘¼ã³å‡ºã™\n",
        "    self.init_weights()\n",
        "\n",
        "  # è‡ªå‰ã®é‡ã¿åˆæœŸåŒ–é–¢æ•°\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, text, offsets):\n",
        "    embedded = self.embedding(text, offsets)\n",
        "    return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtVoatKc7vBa"
      },
      "source": [
        "* è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã‚¯ãƒ©ã‚¹ã®å€‹æ•°ã‚’èª¿ã¹ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4kpm5Ie7tMN"
      },
      "outputs": [],
      "source": [
        "unique_labels = set([label for label in dataset[\"train\"][\"label\"]])\n",
        "print(unique_labels)\n",
        "num_class = len(unique_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u1m1i7e748S"
      },
      "source": [
        "* é‡è¦ãªå®šæ•°ã‚’å¤‰æ•°ã«ã‚»ãƒƒãƒˆã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcPLpHkXsAag"
      },
      "outputs": [],
      "source": [
        "# èªå½™ã‚µã‚¤ã‚º\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒï¼ˆã“ã‚Œã¯é©å½“ã«æ±ºã‚ã‚‹ï¼‰\n",
        "emsize = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2UFwoEW71LV"
      },
      "source": [
        "* ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—GPUã¸é€ã‚‹ã€‚\n",
        " * ä¸Šã§å€¤ã‚’ã‚»ãƒƒãƒˆã—ãŸå¤‰æ•°ã‚’ä½¿ã£ã¦åˆæœŸåŒ–ã—ã¦ã„ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BXZ2xKg7zJT"
      },
      "outputs": [],
      "source": [
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxK-Sx4A7eFB"
      },
      "source": [
        "## è¨“ç·´ã«ä½¿ã†ãƒ˜ãƒ«ãƒ‘é–¢æ•°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeGMjdPd7dXM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  log_interval = 500 # ãƒ­ã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹é–“éš”\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_label = model(text, offsets)\n",
        "    loss = criterion(predicted_label, label)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(\n",
        "          f\"||| {idx:5d}/{len(dataloader):5d} batches | \"\n",
        "          f\"time: {elapsed:5.2f}s | \"\n",
        "          f\"accuracy {total_acc / total_count:8.3f}\"\n",
        "      )\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa0nVABe8GGu"
      },
      "source": [
        "## è©•ä¾¡ã«ä½¿ã†ãƒ˜ãƒ«ãƒ‘é–¢æ•°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JEgh9O3sAPj"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "      predicted_label = model(text, offsets)\n",
        "      loss = criterion(predicted_label, label)\n",
        "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc / total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPLsWoz88SrI"
      },
      "source": [
        "## ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yw5vNAlSq-M"
      },
      "source": [
        "* ã‚¨ãƒãƒƒã‚¯æ•°ã¨å­¦ç¿’ç‡ã®è¨­å®š\n",
        "  * SGDã‚’ä½¿ã†ã®ã§ã€å­¦ç¿’ç‡ã¯å¤§ãã„ç›®ã®å€¤ã«ã—ã¦ã„ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ8vB0_t8bAY"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "learning_rate = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHJtiyQqSy9B"
      },
      "source": [
        "* æå¤±é–¢æ•°ã€æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®è¨­å®š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKjAt42oS7kt"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8otKmBlT2vt"
      },
      "source": [
        "* å­¦ç¿’ã®å®Ÿè¡Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vixuo6u2r__K"
      },
      "outputs": [],
      "source": [
        "total_accu = None\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_start_time = time.time()\n",
        "  train(train_dataloader)\n",
        "  accu_val = evaluate(valid_dataloader)\n",
        "  if total_accu is not None and total_accu > accu_val:\n",
        "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æ­£è§£ç‡ãŒå‰ã®ã‚¨ãƒãƒƒã‚¯ã‚ˆã‚Šä¸‹ãŒã£ãŸã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’å‹•ã‹ã™\n",
        "    scheduler.step()\n",
        "  else:\n",
        "    total_accu = accu_val\n",
        "  print(\"-\" * 59)\n",
        "  elapsed = time.time() - epoch_start_time\n",
        "  print(\n",
        "      f\"| end of epoch {epoch+1:3d} | \"\n",
        "      f\"time: {elapsed:5.2f}s | \"\n",
        "      f\"lr = {optimizer.param_groups[0]['lr']:.3f} | \"\n",
        "      f\"validation accuracy {accu_val:8.3f}\"\n",
        "  )\n",
        "  print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), os.path.join(save_dir, \"my-model.pt\"))"
      ],
      "metadata": {
        "id": "5ShRmR9Yv-j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassificationModel(vocab_size, emsize, num_class)\n",
        "model.load_state_dict(torch.load(os.path.join(save_dir, \"my-model.pt\"), weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "8nAP4f20wDzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rToWRgOeJI6"
      },
      "source": [
        "## æœ€å¾Œã«ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o45KtyPZsF68"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "\n",
        "print(\"Checking the results of test dataset...\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(f\"test accuracy {accu_test:8.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FMoLIJ5sF3S"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor(tokenizer.encode(text).ids)\n",
        "    output = model(text, torch.tensor([0]))\n",
        "    return output.argmax(1).item()\n",
        "\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. â€“ Four days ago, Jon Rahm was \\\n",
        "    enduring the seasonâ€™s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursdayâ€™s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering heâ€™d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a {} news\".format(ag_news_label[predict(ex_text_str)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzVkJ2v-tt_"
      },
      "source": [
        "# èª²é¡Œ\n",
        "* ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„optimizerã‚„schedulerã‚’å¤‰æ›´ã—ã¦ã€validation setä¸Šã§è©•ä¾¡ã—ã¤ã¤ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã‚ˆã†ã€‚\n",
        "* ä½™è£•ãŒã‚ã‚Œã°ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã‚ˆã†ã€‚\n",
        "  * ä¾‹: ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’BPEã«å¤‰ãˆã¦ã¿ã‚‹ã€‚\n",
        "* æœ€å¾Œã«ã€è‡ªåˆ†ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸè¨­å®šã‚’ä½¿ã£ã¦ã€test setä¸Šã§è©•ä¾¡ã—ã‚ˆã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26RYXnmnbbSc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1WB-hcbrD1rix5h3hYxLeazLr-AjL2S2E",
      "authorship_tag": "ABX9TyMC17n026yUx1gQ6ebETLLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}