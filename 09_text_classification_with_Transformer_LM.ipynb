{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/09_text_classification_with_Transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVarWTq39kbp"
      },
      "source": [
        "# 言語モデルを使ったテキスト分類\n",
        "* 今回はトランスフォーマ言語モデルのファインチューニングを実践する。\n",
        "  * パラメータ数は数億個オーダのもの。\n",
        "  * パラメータ数が数十億個（数ビリオン）のものは、扱いがやや大変。\n",
        "* ファインチューニングによってテキスト分類の性能を向上させる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvZQLEUNLusJ"
      },
      "source": [
        "* 今回はTransformersライブラリを使う。\n",
        "  * Sentence Transformersは使わない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zez2VM23tb7s"
      },
      "source": [
        "* ランタイムのタイプをGPUに設定しておく。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6yr_L7y8hXa"
      },
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFoklf3F44Ci"
      },
      "outputs": [],
      "source": [
        "!pip install -U accelerate datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZILk8tmdp4kb"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_2y3RFpQ6K"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJB6XAPZ8kgE"
      },
      "source": [
        "## データセット\n",
        "* ライブドアニュースコーパスを使う。\n",
        "* 前々回に作成したtraining/validation/testのsliceを使う。\n",
        "  * https://github.com/tomonari-masada/course2024-nlp/blob/main/livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEjVRZPqOfz"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/tomonari-masada/course2024-nlp/raw/refs/heads/main/livedoor_ds.tar.gz\n",
        "!tar zxf livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxZLq3TK5GLj"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "ds = load_from_disk(\"livedoor_ds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8TtA7p05Qdg"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(ds[\"train\"][\"category\"])"
      ],
      "metadata": {
        "id": "4HqoIWyQKyLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBksh8An5cPK"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "  'movie-enter',\n",
        "  'it-life-hack',\n",
        "  'kaden-channel',\n",
        "  'topic-news',\n",
        "  'livedoor-homme',\n",
        "  'peachy',\n",
        "  'sports-watch',\n",
        "  'dokujo-tsushin',\n",
        "  'smax',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(set(ds[\"train\"][\"category\"]))\n",
        "num_labels"
      ],
      "metadata": {
        "id": "M7gjch5vK3tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUGTgOZO5j2c"
      },
      "outputs": [],
      "source": [
        "ds[\"train\"][\"content\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1tZS7C5Kr_"
      },
      "source": [
        "## トークナイザ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DP1hSvlMgpo"
      },
      "source": [
        "* E5の多言語版を使う。\n",
        "  * https://arxiv.org/abs/2212.03533\n",
        "  * https://arxiv.org/abs/2402.05672"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* テキストのトークン化をここで済ませておく。"
      ],
      "metadata": {
        "id": "Zjpjmx40IGLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5zsXVlJ5kB5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(\n",
        "    examples[\"content\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        "  )\n",
        "\n",
        "tokenized_ds = ds.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njbj3eiVWCQF"
      },
      "source": [
        "* 正解ラベルのカラムを\"label\"にrenameする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3kp_pfSPpZd"
      },
      "outputs": [],
      "source": [
        "for slice in tokenized_ds:\n",
        "  tokenized_ds[slice] = tokenized_ds[slice].rename_column(\"category\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2UC4MZJePEY"
      },
      "outputs": [],
      "source": [
        "train_ds = tokenized_ds[\"train\"]\n",
        "eval_ds = tokenized_ds[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCJltXTWPd1V"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JrC1Pr0fkUJ"
      },
      "source": [
        "## 言語モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aisD6pPONXe0"
      },
      "source": [
        "* `AutoModelForSequenceClassification`クラスを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8M0UGKeQ9f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ").to(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqfgUfzhNspd"
      },
      "source": [
        "* モデルの中身を見てみる。\n",
        "  * `classifier`というモジュールに注目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6deGrjefW63"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9fLWEHhCQRb"
      },
      "source": [
        "* 分類器として使えることを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KcYnhkSCQRb"
      },
      "outputs": [],
      "source": [
        "input = tokenize_function(tokenized_ds[\"test\"][0]).to(model.device)\n",
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6OvCLsnCQRb"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  logits = model(**input).logits\n",
        "model.train()\n",
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCJuvZ2mCQRb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.argmax(model(**input).logits, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZyeM_kCQRb"
      },
      "source": [
        "* ファインチューニング前の分類性能を見てみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeQEYuOCQRb"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate(model, ds, eval_batch_size=1):\n",
        "    model.eval()\n",
        "    predicted_class_ids = []\n",
        "    offset = 0\n",
        "    for offset in tqdm(range(0, len(ds), eval_batch_size)):\n",
        "        examples = ds[offset:offset + eval_batch_size]\n",
        "        input = tokenize_function(examples).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**input).logits\n",
        "        predicted_class_ids.append(torch.argmax(logits, axis=-1))\n",
        "    model.train()\n",
        "    return torch.concat(predicted_class_ids)\n",
        "\n",
        "predicted_class_ids = evaluate(model, ds[\"test\"], eval_batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTvJSmGlCQRb"
      },
      "outputs": [],
      "source": [
        "print(predicted_class_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjWdz_gkCQRb"
      },
      "outputs": [],
      "source": [
        "print(ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6iHkE6ICQRb"
      },
      "source": [
        "* 当然、ランダムな予測の分類性能に近い。\n",
        "  * 分類用のヘッドが全くtrainingされていないから。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPajq8ipCQRb"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "metric.compute(predictions=predicted_class_ids, references=ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTdlZjaOOLft"
      },
      "source": [
        "## 評価を実行するヘルパ関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PU6utYCQRb"
      },
      "source": [
        "* logitsと正解ラベルを渡せばaccuracyを返してくれる関数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Mg3j5hOLNN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH8mkSAZO3Os"
      },
      "source": [
        "## `Trainer`の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30AT9tzlO50G"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3, #もっと増やしてもいい。\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, _ in model.named_parameters():\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "CO1FCjERGtby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ここでは、classifier headと最後の4層だけをtrainingする。\n",
        "  * 時間とGPUメモリの節約のため。"
      ],
      "metadata": {
        "id": "ovsYwWJRHXTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  if \"classifier\" in name:\n",
        "    param.requires_grad = True\n",
        "  elif (\"roberta.encoder.layer.2\" in name\n",
        "        and \"roberta.encoder.layer.2.\" not in name):\n",
        "    param.requires_grad = True\n",
        "  else:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "Q0pZTl6JG6EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzlTDsJ386lg"
      },
      "source": [
        "## ファインチューニングの実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkRnPijhCQRf"
      },
      "source": [
        "* CUDA out of memoryエラーが出たら・・・\n",
        "  * バッチサイズを小さくするなど、GPUのメモリを使わない工夫をしてから・・・\n",
        "  * セッションを再起動して最初のセルからやり直す。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRVMtGvF6eqZ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51R3noPlCQRf"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sn33a5jCQRf"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"my_model\").to(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XckgncQsCQRf"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate(model, ds, eval_batch_size=1):\n",
        "    model.eval()\n",
        "    predicted_class_ids = []\n",
        "    offset = 0\n",
        "    for offset in tqdm(range(0, len(ds), eval_batch_size)):\n",
        "        examples = ds[offset:offset + eval_batch_size]\n",
        "        input = tokenize_function(examples).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**input).logits\n",
        "        predicted_class_ids.append(torch.argmax(logits, axis=-1))\n",
        "    model.train()\n",
        "    return torch.concat(predicted_class_ids)\n",
        "\n",
        "predicted_class_ids = evaluate(model, ds[\"test\"], eval_batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqe6jq1UCQRf"
      },
      "outputs": [],
      "source": [
        "metric.compute(predictions=predicted_class_ids, references=ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0KBQRedCQRf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}