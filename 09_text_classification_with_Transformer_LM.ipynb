{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/09_text_classification_with_Transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVarWTq39kbp"
      },
      "source": [
        "# 言語モデルを使ったテキスト分類\n",
        "* 今回はトランスフォーマ言語モデルのファインチューニングを実践する。\n",
        "  * パラメータ数は数億個オーダのもの。\n",
        "  * パラメータ数が数十億個（数ビリオン）のものは、扱いがやや大変。\n",
        "* ファインチューニングによってテキスト分類の性能を向上させる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvZQLEUNLusJ"
      },
      "source": [
        "* 今回はTransformersライブラリを使う。\n",
        "  * Sentence Transformersは使わない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zez2VM23tb7s"
      },
      "source": [
        "* ランタイムのタイプをGPUに設定しておく。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6yr_L7y8hXa"
      },
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFoklf3F44Ci"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers accelerate datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZILk8tmdp4kb"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_2y3RFpQ6K"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJB6XAPZ8kgE"
      },
      "source": [
        "## データセット\n",
        "* ライブドアニュースコーパスを使う。\n",
        "* 前々回に作成したtraining/validation/testのsliceを使う。\n",
        "  * https://github.com/tomonari-masada/course2024-nlp/blob/main/livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEjVRZPqOfz"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/tomonari-masada/course2024-nlp/raw/refs/heads/main/livedoor_ds.tar.gz\n",
        "!tar zxf livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxZLq3TK5GLj"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "ds = load_from_disk(\"livedoor_ds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8TtA7p05Qdg"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBksh8An5cPK"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "  'movie-enter',\n",
        "  'it-life-hack',\n",
        "  'kaden-channel',\n",
        "  'topic-news',\n",
        "  'livedoor-homme',\n",
        "  'peachy',\n",
        "  'sports-watch',\n",
        "  'dokujo-tsushin',\n",
        "  'smax',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUGTgOZO5j2c"
      },
      "outputs": [],
      "source": [
        "ds[\"train\"][\"content\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1tZS7C5Kr_"
      },
      "source": [
        "## トークナイザ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DP1hSvlMgpo"
      },
      "source": [
        "* E5の多言語版を使う。\n",
        "  * https://arxiv.org/abs/2212.03533\n",
        "  * https://arxiv.org/abs/2402.05672"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5zsXVlJ5kB5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large-instruct\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(\n",
        "    examples[\"content\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        "  )\n",
        "\n",
        "tokenized_ds = ds.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njbj3eiVWCQF"
      },
      "source": [
        "* 正解ラベルのカラムを\"label\"にrenameする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3kp_pfSPpZd"
      },
      "outputs": [],
      "source": [
        "for slice in tokenized_ds:\n",
        "  tokenized_ds[slice] = tokenized_ds[slice].rename_column(\"category\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2UC4MZJePEY"
      },
      "outputs": [],
      "source": [
        "train_ds = tokenized_ds[\"train\"]\n",
        "eval_ds = tokenized_ds[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCJltXTWPd1V"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JrC1Pr0fkUJ"
      },
      "source": [
        "## 言語モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aisD6pPONXe0"
      },
      "source": [
        "* `AutoModelForSequenceClassification`クラスを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8M0UGKeQ9f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"intfloat/multilingual-e5-large-instruct\",\n",
        "    num_labels=9,\n",
        ").to(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqfgUfzhNspd"
      },
      "source": [
        "* モデルの中身を見てみる。\n",
        "  * `classifier`というモジュールに注目。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6deGrjefW63"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p03oabb18zLx"
      },
      "source": [
        "* 分類器として使えることを確認する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlahoUjj8zLx"
      },
      "outputs": [],
      "source": [
        "input = tokenize_function(tokenized_ds[\"test\"][0]).to(model.device)\n",
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7yjrd9r8zLx"
      },
      "outputs": [],
      "source": [
        "model(**input).logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyKg5Neq8zLx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.argmax(model(**input).logits, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDofRn398zLx"
      },
      "source": [
        "* ファインチューニング前の分類性能を見てみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO6xSVn-8zLx"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate(model, ds, eval_batch_size=1):\n",
        "    model.eval()\n",
        "    predicted_class_ids = []\n",
        "    offset = 0\n",
        "    for offset in tqdm(range(0, len(ds), eval_batch_size)):\n",
        "        examples = ds[offset:offset + eval_batch_size]\n",
        "        input = tokenize_function(examples).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**input).logits\n",
        "        predicted_class_ids.append(torch.argmax(logits, axis=-1))\n",
        "    model.train()\n",
        "    return torch.concat(predicted_class_ids)\n",
        "\n",
        "predicted_class_ids = evaluate(model, ds[\"test\"], eval_batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWv8XV-m8zLx"
      },
      "outputs": [],
      "source": [
        "predicted_class_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpA4YcqE8zLx"
      },
      "outputs": [],
      "source": [
        "print(ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hip-m0Ol8zLy"
      },
      "source": [
        "* 当然、ランダムな予測の分類性能に近い。\n",
        "  * 分類用のヘッドが全くtrainingされていないから。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYVfwEqc8zLy"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "metric.compute(predictions=predicted_class_ids, references=ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTdlZjaOOLft"
      },
      "source": [
        "## 評価を実行するヘルパ関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnl2WZvs8zLy"
      },
      "source": [
        "* logitsと正解ラベルを渡せばaccuracyを返してくれる関数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Mg3j5hOLNN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH8mkSAZO3Os"
      },
      "source": [
        "## `Trainer`の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30AT9tzlO50G"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzlTDsJ386lg"
      },
      "source": [
        "## ファインチューニングの実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkLpr9KS8zL5"
      },
      "source": [
        "* RTX4090だと`per_device_train_batch_size`を16まで増やせるので15分ぐらいで終わる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRVMtGvF6eqZ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbYeU_Ac8zL5"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"path_to_my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGwRsQlm8zL5"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"path_to_my_model\").to(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0HK5lud8zL6"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate(model, ds, eval_batch_size=1):\n",
        "    model.eval()\n",
        "    predicted_class_ids = []\n",
        "    offset = 0\n",
        "    for offset in tqdm(range(0, len(ds), eval_batch_size)):\n",
        "        examples = ds[offset:offset + eval_batch_size]\n",
        "        input = tokenize_function(examples).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**input).logits\n",
        "        predicted_class_ids.append(torch.argmax(logits, axis=-1))\n",
        "    model.train()\n",
        "    return torch.concat(predicted_class_ids)\n",
        "\n",
        "predicted_class_ids = evaluate(model, ds[\"test\"], eval_batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-ztBQ9f8zL6"
      },
      "outputs": [],
      "source": [
        "metric.compute(predictions=predicted_class_ids, references=ds[\"test\"][\"category\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSUTxBbF8zL6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}