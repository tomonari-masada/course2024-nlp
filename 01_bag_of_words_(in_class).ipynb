{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/08aMvBUo4SN12IDWikzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/01_bag_of_words_(in_class).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzUPIsj03QUI"
      },
      "source": [
        "# テキストのBoW (bag-of-words)モデル\n",
        "* テキストを単語のmultisetとして表現したもの\n",
        "  * もはや単語の出現回数でしかテキストを区別できない。\n",
        "  * つまり、語順は無視される。\n",
        "  * それでも、それなりに興味深い分析が実現できる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前置き"
      ],
      "metadata": {
        "id": "AVYB7sE1yOl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 参考書"
      ],
      "metadata": {
        "id": "xusKXkRf4Dxc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xPPAciVN-m-"
      },
      "source": [
        "* 授業全体の参考書: 岡﨑、荒瀬、鈴木、鶴岡、宮尾著 『IT Text 自然言語処理の基礎』（オーム社）\n",
        "  * https://www.ohmsha.co.jp/book/9784274229008/\n",
        "* 本日の参考書: C. D. Manning, P. Raghavan & H. Schütze. Introduction to Information Retrieval.\n",
        "  * https://nlp.stanford.edu/IR-book/html/htmledition/irbook.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prerequisites"
      ],
      "metadata": {
        "id": "nmT0-Y2l4HwN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKEP5r0nOxjd"
      },
      "source": [
        "* この授業では、Pythonのコーディングの基礎は習得済みであることを前提します。\n",
        "* また、NumPyやscikit-learnの基本的な使い方は習得済みであることを前提します。\n",
        "* PyTorch（Hugging Faceのライブラリを使う時に必要）は、授業で説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiozJha53etL"
      },
      "source": [
        "### NLPの歴史\n",
        "* bag-of-words(BoW)は、テキストをモデル化する方法の、一つ。\n",
        "* 近年のNLPの歴史＝テキストのモデル化がBoWから文脈化埋め込みに変化した歴史\n",
        "  * BoW → word2vec → contexualized word embedding\n",
        "* word2vec\n",
        "  * 前後にどんな単語が出現するかによらず・・・\n",
        "  * 一単語に一つのベクトルを固定的に割り振る。\n",
        "  * 今は言語モデルの入力ベクトルとして使うだけ(embedding layer)。\n",
        "* 文脈化埋め込み (contextualized word embedding)\n",
        "  * LLMs (large language models) は、文脈化埋め込みを実現する手法の一つ。\n",
        "  * 他にも文脈化埋め込みを実現する方法はある(cf. [sequence memoizer](https://dl.acm.org/doi/10.1145/1897816.1897842))。\n",
        "    * https://x.com/yeewhye/status/1753267400676463054\n",
        "* NLPの歴史の参考資料\n",
        "  * スタンフォード大のNLPの授業がいかに大きく内容を変えているか、調べてみよう。\n",
        "  * http://web.stanford.edu/class/cs224n/index.html の\"Previous offerings\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 用語集"
      ],
      "metadata": {
        "id": "n2DzXzoQzCZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **単語(word)**\n",
        "  * テキストを構成する最小の単位。\n",
        "  * LLMの世界では、単語をさらに分割したサブワード(subword)が最小の単位になる。"
      ],
      "metadata": {
        "id": "5aOX2fRtifAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **語彙(vocabulary)**\n",
        "  * あるコーパスに出現する単語またはサブワードの集合のこと。\n"
      ],
      "metadata": {
        "id": "m3LQRrMAiXmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **トークン(token)**\n",
        "  * 単語(word)、またはサブワード(subword)の、一回一回の出現のこと。\n",
        "  * 例えば、このセルで「この」という単語は5回現れている。\n",
        "  * このことを、このセルでは「この」という単語のトークンが5個ある、と言い表す。\n"
      ],
      "metadata": {
        "id": "HhkRIZsVzJGq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba4ndKX4IJke"
      },
      "source": [
        "* **テキスト(text)**\n",
        "  * トークン列のこと。\n",
        "  * 当然、同じ単語のトークンが複数回現れることもある。\n",
        "  * テキストのことを、文書(document)と呼ぶこともある。\n",
        "* **コーパス(corpus)**\n",
        "  * テキストの集合のこと。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z57oKsOVGOWf"
      },
      "source": [
        "## テキストのBoW(bag-of-words)モデル\n",
        "* **bag-of-wordsモデル**とは、テキストを定量的に表現する手法のひとつ。\n",
        "  * 他にもテキストを定量的に表現する手法はある。\n",
        "* bag-of-wordsモデルにおいては、トークンの**出現順序が無視される**。\n",
        "* つまり、テキストを、バッグに入ったトークンの集まりのようにモデリングする（下図参照）。\n",
        "  * 言い換えれば、テキストを単語の**multiset**として扱うのがbag-of-wordsモデルである。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBk-WNX4IRVb"
      },
      "source": [
        "![bag-of-words.png](https://raw.githubusercontent.com/tomonari-masada/course2024-nlp/main/bag-of-words.png)\n",
        "\n",
        "* 上の図は下記のWebページより。\n",
        " * https://dudeperf3ct.github.io/lstm/gru/nlp/2019/01/28/Force-of-LSTM-and-GRU/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PilALQV12kVD"
      },
      "source": [
        "### テキストのベクトル表現の歴史\n",
        "* 最近では、単語またはsubwordのベクトル表現を利用して、テキストのベクトル表現を作る。\n",
        "  * word2vec以降の流れ。\n",
        "* 単語またはsubwordのベクトル表現は、埋め込み(embedding)と呼ばれる。\n",
        "  * 分散表現(distributive representation)とも呼ばれるが、最近あまり使わない呼び方。\n",
        "* word embeddingやsubword embeddingを元にして、テキストをembedするのが、今は主流。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-5GrvauMKDq"
      },
      "source": [
        "### BoWはまだ現役か？\n",
        "* 論文では今でも、baselineとして、TF-IDFやBM25など、BoWが引き合いに出されることがある。\n",
        "  * 新しい手法を考え出してもBoWに勝てなければ意味がない。\n",
        "* そのため、最初にBoWについて簡単に説明しておく。\n",
        "  * BM25 https://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html\n",
        "* ただし、最近でもRAGではBM25をdense retrievalと組み合わせることもあるので、まだ現役と言える。\n",
        "  * RAG = retrieval augmented generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJZFJ9B0KNQO"
      },
      "source": [
        "## BoWモデル1: Word count\n",
        "* テキストは、各単語の出現回数を要素とするベクトルとして表現できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhf7MJe4NH3P"
      },
      "source": [
        "### scikit-learnのCountVectorizer\n",
        "* 各テキストは、半角スペースでつながれた単語の列として準備しておく。\n",
        "* CountVectorizerのインスタンスを作り、テキスト集合にfitさせる。\n",
        "  * 語彙の抽出と、出現回数の集計が実行される。\n",
        "* そして他の任意のテキスト集合をtransformする。\n",
        "  * この使い方は、scikit-learnにおける他の前処理のときと同様。\n",
        "  * fitメソッドに与えたテキスト集合の語彙が使われる。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAsV0OzFGKr8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSPMo5HnOeLK"
      },
      "source": [
        "* コーパス（＝テキストの集合）を用意する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JvB4acfMxQq"
      },
      "source": [
        "corpus = [\n",
        "    \"This document is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Where is the fourth one?\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9piYSlbPSan"
      },
      "source": [
        "* CountVectorizerをデフォルトの設定で使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEcGpcc4M7bo"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16VoXJLcNtmW"
      },
      "source": [
        "* テキストのBoW表現の確認\n",
        " * 疎なベクトルとして得られることに注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nl4fjykNDo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf30b31a-b91a-4e21-a0b1-ec05a4fd5036"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 9)\t1\n",
            "  (0, 1)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 1)\t2\n",
            "  (1, 4)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 6)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 5)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 7)\t1\n",
            "  (3, 5)\t1\n",
            "  (3, 10)\t1\n",
            "  (3, 3)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HVn-V4OMa02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "d4cd8691-5e4e-45d4-9352-1adb03038187"
      },
      "source": [
        "type(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix.\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "    csr_matrix(D)\n",
              "        where D is a 2-D ndarray\n",
              "\n",
              "    csr_matrix(S)\n",
              "        with another sparse array or matrix S (equivalent to S.tocsr())\n",
              "\n",
              "    csr_matrix((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSR representation where the column indices for\n",
              "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
              "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
              "        If the shape parameter is not supplied, the matrix dimensions\n",
              "        are inferred from the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "size\n",
              "data\n",
              "    CSR format data array of the matrix\n",
              "indices\n",
              "    CSR format index array of the matrix\n",
              "indptr\n",
              "    CSR format index pointer array of the matrix\n",
              "has_sorted_indices\n",
              "has_canonical_format\n",
              "T\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSR format\n",
              "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
              "  - efficient row slicing\n",
              "  - fast matrix vector products\n",
              "\n",
              "Disadvantages of the CSR format\n",
              "  - slow column slicing operations (consider CSC)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical Format\n",
              "    - Within each row, indices are sorted by column.\n",
              "    - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csr_matrix\n",
              "&gt;&gt;&gt; csr_matrix((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "Duplicate entries are summed together:\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
              "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[9, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 4, 0]])\n",
              "\n",
              "As an example of how to construct a CSR matrix incrementally,\n",
              "the following snippet builds a term-document matrix from texts:\n",
              "\n",
              "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
              "&gt;&gt;&gt; indptr = [0]\n",
              "&gt;&gt;&gt; indices = []\n",
              "&gt;&gt;&gt; data = []\n",
              "&gt;&gt;&gt; vocabulary = {}\n",
              "&gt;&gt;&gt; for d in docs:\n",
              "...     for term in d:\n",
              "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
              "...         indices.append(index)\n",
              "...         data.append(1)\n",
              "...     indptr.append(len(indices))\n",
              "...\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
              "array([[2, 1, 0, 0],\n",
              "       [0, 1, 1, 1]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 370);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUICjJZ2N6px"
      },
      "source": [
        "* 疎な表現を通常の密な表現（NumPyのndarray）にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJYPyDPDNsIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66923e6-9f89-4107-84bc-baaa603d30f7"
      },
      "source": [
        "X_dense = X.toarray()\n",
        "X_dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
              "       [0, 2, 0, 0, 1, 0, 1, 1, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzbZQPHuOAIP"
      },
      "source": [
        "### 語彙を確認\n",
        "* 先頭の大文字は自動的に小文字に変換されていることが分かる。\n",
        "* ピリオドや疑問符は削除されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQAAI9LKN5vL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d272c818-88a4-4ccd-e429-d9c63a8f83fa"
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 9,\n",
              " 'document': 1,\n",
              " 'is': 4,\n",
              " 'the': 7,\n",
              " 'first': 2,\n",
              " 'second': 6,\n",
              " 'and': 0,\n",
              " 'third': 8,\n",
              " 'one': 5,\n",
              " 'where': 10,\n",
              " 'fourth': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC5TW6dgMhsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04071eb8-b4af-4726-bfb8-08d16db9253f"
      },
      "source": [
        "type(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 語彙を取得"
      ],
      "metadata": {
        "id": "fCeaLWQbxu2W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P1dFVlcN_Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467a61de-4d75-4186-e8bf-0bfcb3a48ee6"
      },
      "source": [
        "vocab = vectorizer.get_feature_names_out()\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'fourth', 'is', 'one', 'second', 'the',\n",
              "       'third', 'this', 'where'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4AeNQK2P1GW"
      },
      "source": [
        "### 新しいテキストをベクトルに変換\n",
        "* sklearnでよくやるように、transformメソッドを使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egmnVXnHPbkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9777be7-c37f-4e35-aca5-8e8f93341263"
      },
      "source": [
        "new_doc = [\"This is the new document.\"]\n",
        "new_vectors = vectorizer.transform(new_doc)\n",
        "new_vectors.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHWGA6W4Psto"
      },
      "source": [
        "* 新出の単語は無視される点に注意\n",
        "  * 問： 上の例題で、どれが新出単語か？\n",
        "* OoV (out-of-vocabulary) の問題\n",
        "  * この問題は、NLPの世界では、超重要な問題。\n",
        "  * 今は、サブワード(subword)の利用により、OoV問題を回避する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etJEdIKK5Ejo"
      },
      "source": [
        "## BoWモデル2: TF-IDF\n",
        "* テキストをベクトル化する古典的な手法。\n",
        "* TF-IDFは、TFとIDFの積である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZZghSTZ5Gi_"
      },
      "source": [
        "### TF (term frequency)\n",
        "* TFとは、各々の単語がテキストのなかで出現する回数。word countと同義。\n",
        "  * 出現回数を、そのテキストの長さで割ったものをTFと呼ぶこともある。\n",
        "  * テキストの長さとは、テキストに含まれるトークンの総数。\n",
        "* テキストのなかで頻出する単語ほどTFは大きくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7M88Lm1QwQF"
      },
      "source": [
        "### IDF (inverse document frequency)\n",
        "* IDFとは、DFの逆数。\n",
        "* DFとは、ある単語が含まれるテキストの数。\n",
        "  * ある単語が含まれるテキスト数を全テキスト数で割ったものをDFと呼ぶこともある。\n",
        "* テキスト集合のなかで稀少な単語ほどIDFは大きくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B13HQa1G5U_j"
      },
      "source": [
        "### TF-IDF (term frequency–inverse document frequency)\n",
        "* TF-IDFは、TFとIDFの積。\n",
        "* 積を求める前に、TFのルートもしくは対数をとったり、IDFのルートもしくは対数をとったりする。\n",
        "  * 大きめの値が、効きすぎないようにする。\n",
        "  * 対数をとるときは、ゼロの対数をとることにならないように、1を足したりする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0RtY0PtSq3D"
      },
      "source": [
        "### TF-IDFの式の例\n",
        "\n",
        "\\begin{align}\n",
        "x_{d,w} = \\frac{n_{d,w}}{n_d} \\cdot ( 1 + \\log\\frac{m}{m_w}) \\tag{1}\n",
        "\\end{align}\n",
        "\n",
        "where\n",
        "\n",
        " * $n_{d,w}$ is the frequency of the word $w$ in the document $d$,\n",
        " * $n_d$ is defined as $n_d \\equiv \\sum_w n_{d,w}$,\n",
        " * $m_w$ is the number of documents containing the word $w$, and\n",
        " * $m$ is the total number of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsLF9WdGHgFD"
      },
      "source": [
        "### TF-IDFの式のバリエーション\n",
        "\n",
        "* https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XfakOH8HqZ9"
      },
      "source": [
        "### 式の選び方\n",
        "* どの式の形がいいかは、downstream taskの性能で選ぶ。\n",
        "* どんな場合でもこれが一番良い、という式は、ない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_0aZB0TOnl"
      },
      "source": [
        "### scikit-learnのTfidfVectorizer\n",
        "* scikit-learnでTF-IDFの計算式がどうなっているかは下記を参照。\n",
        "  * https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygrAINVAOm2b"
      },
      "source": [
        "* デフォルトの設定を確認\n",
        "  * https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 次のパラメータは、ちゃんと考えて設定した方が良い。\n",
        "  * `max_df`, `min_df`, `stop_words`"
      ],
      "metadata": {
        "id": "93vNPEl10Mq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
      ],
      "metadata": {
        "id": "RiAFC8Yi0bjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZYEcdYaTV28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3192f905-d37a-42bf-db30-e5116b5dff6f"
      },
      "source": [
        "X = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.74846041, 0.47466356, 0.        , 0.24769914,\n",
              "        0.        , 0.        , 0.24769914, 0.        , 0.3029716 ,\n",
              "        0.        ],\n",
              "       [0.        , 0.74846041, 0.        , 0.        , 0.24769914,\n",
              "        0.        , 0.47466356, 0.24769914, 0.        , 0.3029716 ,\n",
              "        0.        ],\n",
              "       [0.52898651, 0.        , 0.        , 0.        , 0.2760471 ,\n",
              "        0.41705904, 0.        , 0.2760471 , 0.52898651, 0.33764523,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.56199026, 0.29326983,\n",
              "        0.44307958, 0.        , 0.29326983, 0.        , 0.        ,\n",
              "        0.56199026]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmsh54ziOr-m"
      },
      "source": [
        "* テキストベクトルはL2ノルムが1となるように長さを変更されている。\n",
        "  * TfidfVectorizer()のnormパラメータで変更可能。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSbn0uyUxOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b77602-7959-460f-a588-8b1bc035faad"
      },
      "source": [
        "import numpy as np\n",
        "np.linalg.norm(X, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 語彙の取得"
      ],
      "metadata": {
        "id": "6twQCv1f0nKw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPGd8r-pIAVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81385fc-4055-4803-83c1-fdec4c10ffcb"
      },
      "source": [
        "vocab = tfidf_vectorizer.get_feature_names_out()\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'fourth', 'is', 'one', 'second', 'the',\n",
              "       'third', 'this', 'where'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 新しいテキストをベクトル化\n",
        "  * 新出単語は無視される（OoV問題）。"
      ],
      "metadata": {
        "id": "2YFBHNR-0u2N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ-M-qZjTYsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbc3f4e-ccd0-4d93-9a89-2902cb6fbe45"
      },
      "source": [
        "new_vectors = tfidf_vectorizer.transform(new_doc).toarray()\n",
        "new_vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.6284927 , 0.        , 0.        , 0.41599288,\n",
              "        0.        , 0.        , 0.41599288, 0.        , 0.50881901,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--XKc4eATjf_"
      },
      "source": [
        "* 各単語のIDF\n",
        "  * IDFはそれぞれの単語について一意に決まる値。\n",
        "  * テキストごとに求まる値ではない。\n",
        "  * コーパスが変わると、IDFも変わる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugsq3YAtTfRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037f5ab8-ac93-4040-e72a-a12fe09bae71"
      },
      "source": [
        "tfidf_vectorizer.idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.        ,\n",
              "       1.51082562, 1.91629073, 1.        , 1.91629073, 1.22314355,\n",
              "       1.91629073])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoWモデル3: BM25\n",
        "* 末尾のAppendixで使い方を説明。"
      ],
      "metadata": {
        "id": "7VsnI-2Xc12f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8niqN06T-eX"
      },
      "source": [
        "## BoWの応用"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキスト間の類似度計算"
      ],
      "metadata": {
        "id": "21JYXOhm278R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 内積による類似度計算\n"
      ],
      "metadata": {
        "id": "0e8VWyEl2dQ7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP0KvdykThdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720a3ae3-fdff-4196-9f6a-e89612baff49"
      },
      "source": [
        "np.dot(X, new_vectors[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83064177, 0.83064177, 0.40146757, 0.24399632])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H1V8jSgO_Wq"
      },
      "source": [
        "* TfidfVectorizorのデフォルトの設定では、TF-IDFベクトルが長さ1にnormalizeされている。\n",
        "* そのため、内積がコサイン類似度に一致する。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(X, new_vectors)"
      ],
      "metadata": {
        "id": "3zN82p2f0-xP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5326e0-e364-4623-8136-fa801c664099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83064177],\n",
              "       [0.83064177],\n",
              "       [0.40146757],\n",
              "       [0.24399632]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI1ylF4nPT8d"
      },
      "source": [
        "* 問: テキストをベクトルとして表現する方法が分かった。これを使うと何ができるか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2caNa_-RQqIT"
      },
      "source": [
        "## 演習: 20 newsgroups データセット\n",
        "* テキスト分類手法の評価に使う、古典的なデータセット。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6b7-llzQpK9"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups = fetch_20newsgroups()\n",
        "y_true = newsgroups.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ExPmgkROvU"
      },
      "source": [
        "* 下記コードを参考にして、数値を全て「#NUMBER」という特殊な単語へ変換する。\n",
        " * https://scikit-learn.org/stable/auto_examples/bicluster/plot_bicluster_newsgroups.html#sphx-glr-auto-examples-bicluster-plot-bicluster-newsgroups-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFceOyuoQ04u"
      },
      "source": [
        "def number_normalizer(tokens):\n",
        "  return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
        "\n",
        "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
        "  def build_tokenizer(self):\n",
        "    tokenizer = super().build_tokenizer()\n",
        "    return lambda doc: list(number_normalizer(tokenizer(doc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XasWPbWRWVx"
      },
      "source": [
        "vectorizer = NumberNormalizingVectorizer(stop_words='english', min_df=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsKy592QRYoI"
      },
      "source": [
        "X = vectorizer.fit_transform(newsgroups.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hee6pWC3mzhx",
        "outputId": "81143ca0-5dea-4dc7-ae1f-7e5dd3a72a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 23427)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR41GfUJRb4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eadf379-e358-4fb9-f8d4-f1f35ff0f712"
      },
      "source": [
        "print(vectorizer.get_feature_names_out()[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#NUMBER' '_0' '_4' '_5' '_6' '_7u' '_8' '__' '___' '____' '_____'\n",
            " '______' '_______' '________' '_________' '__________' '___________'\n",
            " '____________' '_____________' '______________']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLwy2wdRi-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adf1306-ab99-4c3e-dc77-4b751b9b0ab1"
      },
      "source": [
        "vocab = vectorizer.get_feature_names_out()\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23427"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 密(dense)な配列に変換する。"
      ],
      "metadata": {
        "id": "qXR2H4po3YoG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkp_KASaRqHt"
      },
      "source": [
        "X = X.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 適当な二つのテキストの内積を求めてみる。"
      ],
      "metadata": {
        "id": "Kx-jfK2S3cRP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9U5NqcMRwW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cad79ee-00f1-4215-ace3-94805dc86e3e"
      },
      "source": [
        "np.dot(X[0], X[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021480506411432166"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 対応するクラスラベルを調べる。"
      ],
      "metadata": {
        "id": "IjtklhU63kgt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSvAGD5SR0ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e629d7a-661c-4bd2-c69d-5a162584fadf"
      },
      "source": [
        "y_true[0], y_true[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn_a7CFR9bC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7962136-9230-407d-b087-bc98411cc54b"
      },
      "source": [
        "newsgroups.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 演習: 簡単な情報検索\n",
        "* TF-IDFベクトルを使って、20 newsgroupsのどれか一つのテキストについて・・・\n",
        "* それと最も似ているテキストを10個返す関数を書こう。\n",
        "* 10個のうち、元のテキストと同じクラスに属するテキストがいくつあるかを調べよう。\n",
        "* 全てのテキストについて同じことを行なってみよう。そして・・・\n",
        "* 最も似ている上位10個のうち同じクラスのテキスト数の平均値を求めよう。"
      ],
      "metadata": {
        "id": "C_-Rj4mg3qiw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQa5w1jTcJdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix: BM25\n",
        "* 参考資料 https://huggingface.co/blog/xhluca/bm25s"
      ],
      "metadata": {
        "id": "gfYQjcF_bTCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bm25s"
      ],
      "metadata": {
        "id": "PEaUe8Nzal6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bm25s\n",
        "\n",
        "retriever = bm25s.BM25(corpus=newsgroups.data)\n",
        "retriever.index(bm25s.tokenize(newsgroups.data))"
      ],
      "metadata": {
        "id": "UcrOhVF6amQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = newsgroups.data[0]\n",
        "print(\"Query \" + \"=\"*60 + \"\\n\" + query)\n",
        "\n",
        "results, scores = retriever.retrieve(bm25s.tokenize(query), k=5)\n",
        "\n",
        "for i in range(results.shape[1]):\n",
        "  doc, score = results[0, i], scores[0, i]\n",
        "  print(f\"Rank {i+1} (score: {score:.2f})\" + \"-\"*40)\n",
        "  print(doc)"
      ],
      "metadata": {
        "id": "fp97WYcTay6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBRnjE0DbC47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}