{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/02_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-w8jUVl2szF"
      },
      "source": [
        "# テキスト分類\n",
        "* BoWでも良い性能を出せることが多い。\n",
        "  * LLMを使って文書分類するときは、BoW+SVMの性能と比較した方が良い。\n",
        "  * なぜなら、分類性能に大きな差がつかないことも、しばしばあるので。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU529kZR2szH"
      },
      "source": [
        "## spaCyのインストール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnIyf5Kb2szI"
      },
      "source": [
        "* 最小限のインストール\n",
        "  * 英語だけ扱えるようになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_97cAWK2szI"
      },
      "outputs": [],
      "source": [
        "!conda install -c conda-forge spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIIy7LnT2szI"
      },
      "source": [
        "* spaCyで日本語を扱えるようにする。\n",
        "  * sudachiという形態素解析器が使えるようになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3RW3h742szJ"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download ja_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg1JBgXU2szJ"
      },
      "source": [
        "## データセット\n",
        "* ライブドアニュースコーパスの本文部分を使う。\n",
        "  * 9値分類。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma1dUc8r2szJ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\n",
        "    \"shunk031/livedoor-news-corpus\",\n",
        "    train_ratio=0.8,\n",
        "    val_ratio=0.1,\n",
        "    test_ratio=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptuaJk9O2szJ",
        "outputId": "517cef5b-6176-4cfc-ed51-27b2f622465d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['url', 'date', 'title', 'content', 'category'],\n",
              "        num_rows: 5894\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['url', 'date', 'title', 'content', 'category'],\n",
              "        num_rows: 737\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['url', 'date', 'title', 'content', 'category'],\n",
              "        num_rows: 736\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTBvLjgm2szJ"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "  'movie-enter',\n",
        "  'it-life-hack',\n",
        "  'kaden-channel',\n",
        "  'topic-news',\n",
        "  'livedoor-homme',\n",
        "  'peachy',\n",
        "  'sports-watch',\n",
        "  'dokujo-tsushin',\n",
        "  'smax',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvsgSnty2szJ",
        "outputId": "9f6a969d-ebe2-4a31-e94b-d4dd464dd05d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'3日に放送された「サンデージャポン」（TBS系）番組内では、片山さつき議員と元衆議院議員で現在はタレント活動を行う杉村太蔵が、河本準一母の生活保護受給問題について議論し、その内容がネット掲示板やツイッターで話題になっている。  同番組で、河本を擁護する気はなく、制度改革にも賛成すると前置きした杉村だが、「なぜ国会議員が個人攻撃をするのか」と、今回の問題における片山議員の言動を問題視した。すると片山氏は「自分が最初に名前を出したのではない」と反論。しかし、杉村は「最初かどうかに関係なく議員は個人攻撃をするべきではない」と主張し、さらに「片山議員は名前が売りたいだけ」と強く非難した。  このやりとりを受け、ネット掲示板上の反応は「タイゾーも目立ちたいだけだろ」「お前こそ議員時はパフォーマンスだけだったくせに」「サンジャポみたけどタイゾーはただ怒鳴ってるだけだった」と、杉村への批判も多く見られたが、ツイッターでは「片山さつきより余程まともなことを言ってる」「片山さつきを応援してる人は2chが世論だと思ってそう」などと、杉村太蔵の主張を支持するユーザも目立ち、その賛否は五分五分といったところだった。  【関連記事】 ・片山さつき議員\\u3000杉村太蔵の批判にも冷静「問題を追及するのが仕事」  【関連情報】 ・杉村太蔵 「あなたは目立ちたいだけだ！個人攻撃は政治手法としておかしい」…生放送で片山議員を激しく批判（痛いニュース）'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"train\"][\"content\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuO5V5Jw2szJ"
      },
      "source": [
        "## 形態素解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmx5x_8Q2szK",
        "outputId": "dc46b33f-daba-493d-c72c-c2343a703913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 日 に 放送 する れる た 「 サンデー ジャポン 」 ( TBS 系 ) 番組 内 で は 、 片山 さつき 議員 と 元 衆議 院 議員 で 現在 は タレント 活動 を 行う 杉村 太蔵 が 、 河本 準一 母 の 生活 保護 受給 問題 に つく て 議論 する 、 その 内容 が ネット 掲示 板 や ツイッター で 話題 に なる て いる 。   同 番組 だ 、 河本 を 擁護 する 気 は ない 、 制度 改革 に も 賛成 する と 前置き する た 杉村 だ が 、 「 なぜ 国会 議員 が 個人 攻撃 を する の か 」 と 、 今回 の 問題 に おく り 片山 議員 の 言動 を 問題 視 する た 。 する と 片山 氏 は 「 自分 が 最初 に 名前 を 出す た の だ は ない 」 と 反論 。 しかし 、 杉村 は 「 最初 か どう か に 関係 ない 議員 は 個人 攻撃 を する べし だ は ない 」 と 主張 する 、 さらに 「 片山 議員 は 名前 が 売る たい だけ 」 と 強い 非難 する た 。   この やりとり を 受ける 、 ネット 掲示 板上 の 反応 は 「 タイゾー も 目立つ たい だけ だ 」 「 お前 こそ 議員 時 は パフォーマンス だけ だ た くせ に 」 「 サンジャポ みる た けど タイゾー は ただ 怒鳴る てる だけ だ た 」 と 、 杉村 へ の 批判 も 多い 見る られる た が 、 ツイッター で は 「 片山 さつき より 余程 まとも だ こと を 言う てる 」 「 片山 さつき を 応援 する てる 人 は 2 ch が 世論 だ と 思う て そう 」 など と 、 杉村 太蔵 の 主張 を 支持 する ユーザ も 目立つ 、 その 賛否 は 五 分 五 分 と いう た ところ だ た 。   【 関連 記事 】 ・ 片山 さつき 議員 　 杉村 太蔵 の 批判 に も 冷静 「 問題 を 追及 する の が 仕事 」   【 関連 情報 】 ・ 杉村 太蔵 「 あなた は 目立つ たい だけ だ ! 個人 攻撃 は 政治 手法 と する て おかしい 」 … 生 放送 で 片山 議員 を 激しい 批判 ( 痛い ニュース ) "
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"ja_core_news_sm\")\n",
        "doc = nlp(ds[\"train\"][\"content\"][0])\n",
        "for token in doc:\n",
        "  print(token.lemma_, end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWXMwlwz2szK"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "corpus_train = []\n",
        "for text in tqdm(ds[\"train\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_train.append(\" \".join([token.lemma_ for token in doc]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI3TGfvw2szK"
      },
      "outputs": [],
      "source": [
        "with open('livedoor-news-corpus_content_lemmatized.txt', 'w') as f:\n",
        "  f.write(\"\\n\".join(corpus_train) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mXoZHR42szK"
      },
      "outputs": [],
      "source": [
        "corpus_train = []\n",
        "with open('livedoor-news-corpus_content_lemmatized.txt', 'r') as f:\n",
        "  for text in f:\n",
        "    corpus_train.append(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEDViFJg2szK"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azmYC6HJ2szK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=10, max_df=0.2)\n",
        "X = vectorizer.fit_transform(corpus_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4deaBWAG2szK"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WoZ8RUO2szK"
      },
      "outputs": [],
      "source": [
        "corpus_val = []\n",
        "for text in tqdm(ds[\"validation\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_val.append(\" \".join([token.lemma_ for token in doc]))\n",
        "\n",
        "corpus_test = []\n",
        "for text in tqdm(ds[\"test\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_test.append(\" \".join([token.lemma_ for token in doc]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgTwGYuo2szK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "corpus = np.array(corpus_train + corpus_val)\n",
        "len(corpus)\n",
        "labels = np.array(ds[\"train\"][\"category\"] + ds[\"validation\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVmRwp8H2szK"
      },
      "source": [
        "## ハイパーパラメータのチューニング\n",
        "* SVMの正則化パラメータ`C`\n",
        "* TfidfVectorizerの`min_df`と`max_df`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrIiA8j82szK"
      },
      "source": [
        "### 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qim4TH6A2szK",
        "outputId": "a980a499-49b5-4cef-a93f-6cb72bf680c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t0.894 \t0.919 \t0.909 \t0.898 \t0.910 \n",
            "mean accuracy: 0.906 | C=1.00e-01 min_df=10 max_df=0.200\n",
            "\t0.910 \t0.931 \t0.928 \t0.931 \t0.928 \n",
            "mean accuracy: 0.926 | C=1.00e+00 min_df=10 max_df=0.200\n",
            "\t0.911 \t0.932 \t0.932 \t0.932 \t0.932 \n",
            "mean accuracy: 0.928 | C=1.00e+01 min_df=10 max_df=0.200\n",
            "\t0.910 \t0.930 \t0.931 \t0.928 \t0.930 \n",
            "mean accuracy: 0.926 | C=1.00e+02 min_df=10 max_df=0.200\n",
            "\t0.909 \t0.928 \t0.926 \t0.927 \t0.928 \n",
            "mean accuracy: 0.924 | C=1.00e+03 min_df=10 max_df=0.200\n",
            "\t0.895 \t0.917 \t0.913 \t0.904 \t0.905 \n",
            "mean accuracy: 0.907 | C=1.00e-01 min_df=10 max_df=0.300\n",
            "\t0.910 \t0.933 \t0.936 \t0.931 \t0.931 \n",
            "mean accuracy: 0.928 | C=1.00e+00 min_df=10 max_df=0.300\n",
            "\t0.913 \t0.933 \t0.932 \t0.933 \t0.934 \n",
            "mean accuracy: 0.929 | C=1.00e+01 min_df=10 max_df=0.300\n",
            "\t0.909 \t0.929 \t0.934 \t0.930 \t0.934 \n",
            "mean accuracy: 0.927 | C=1.00e+02 min_df=10 max_df=0.300\n",
            "\t0.909 \t0.930 \t0.929 \t0.926 \t0.934 \n",
            "mean accuracy: 0.926 | C=1.00e+03 min_df=10 max_df=0.300\n",
            "\t0.896 \t0.922 \t0.913 \t0.909 \t0.905 \n",
            "mean accuracy: 0.909 | C=1.00e-01 min_df=10 max_df=0.400\n",
            "\t0.918 \t0.935 \t0.934 \t0.932 \t0.932 \n",
            "mean accuracy: 0.930 | C=1.00e+00 min_df=10 max_df=0.400\n",
            "\t0.919 \t0.934 \t0.934 \t0.930 \t0.937 \n",
            "mean accuracy: 0.931 | C=1.00e+01 min_df=10 max_df=0.400\n",
            "\t0.916 \t0.931 \t0.933 \t0.931 \t0.936 \n",
            "mean accuracy: 0.929 | C=1.00e+02 min_df=10 max_df=0.400\n",
            "\t0.915 \t0.933 \t0.930 \t0.929 \t0.935 \n",
            "mean accuracy: 0.928 | C=1.00e+03 min_df=10 max_df=0.400\n",
            "\t0.890 \t0.917 \t0.908 \t0.901 \t0.911 \n",
            "mean accuracy: 0.905 | C=1.00e-01 min_df=20 max_df=0.200\n",
            "\t0.911 \t0.928 \t0.928 \t0.926 \t0.927 \n",
            "mean accuracy: 0.924 | C=1.00e+00 min_df=20 max_df=0.200\n",
            "\t0.915 \t0.928 \t0.929 \t0.925 \t0.926 \n",
            "mean accuracy: 0.925 | C=1.00e+01 min_df=20 max_df=0.200\n",
            "\t0.910 \t0.926 \t0.928 \t0.923 \t0.925 \n",
            "mean accuracy: 0.922 | C=1.00e+02 min_df=20 max_df=0.200\n",
            "\t0.912 \t0.927 \t0.924 \t0.922 \t0.924 \n",
            "mean accuracy: 0.922 | C=1.00e+03 min_df=20 max_df=0.200\n",
            "\t0.889 \t0.916 \t0.911 \t0.904 \t0.905 \n",
            "mean accuracy: 0.905 | C=1.00e-01 min_df=20 max_df=0.300\n",
            "\t0.913 \t0.928 \t0.934 \t0.937 \t0.928 \n",
            "mean accuracy: 0.928 | C=1.00e+00 min_df=20 max_df=0.300\n",
            "\t0.917 \t0.930 \t0.934 \t0.931 \t0.922 \n",
            "mean accuracy: 0.927 | C=1.00e+01 min_df=20 max_df=0.300\n",
            "\t0.912 \t0.930 \t0.926 \t0.927 \t0.923 \n",
            "mean accuracy: 0.924 | C=1.00e+02 min_df=20 max_df=0.300\n",
            "\t0.913 \t0.929 \t0.924 \t0.926 \t0.924 \n",
            "mean accuracy: 0.923 | C=1.00e+03 min_df=20 max_df=0.300\n",
            "\t0.894 \t0.920 \t0.913 \t0.910 \t0.908 \n",
            "mean accuracy: 0.909 | C=1.00e-01 min_df=20 max_df=0.400\n",
            "\t0.916 \t0.933 \t0.935 \t0.936 \t0.931 \n",
            "mean accuracy: 0.930 | C=1.00e+00 min_df=20 max_df=0.400\n",
            "\t0.922 \t0.933 \t0.935 \t0.934 \t0.928 \n",
            "mean accuracy: 0.930 | C=1.00e+01 min_df=20 max_df=0.400\n",
            "\t0.918 \t0.931 \t0.927 \t0.928 \t0.925 \n",
            "mean accuracy: 0.926 | C=1.00e+02 min_df=20 max_df=0.400\n",
            "\t0.918 \t0.929 \t0.927 \t0.928 \t0.927 \n",
            "mean accuracy: 0.926 | C=1.00e+03 min_df=20 max_df=0.400\n",
            "\t0.886 \t0.912 \t0.903 \t0.900 \t0.906 \n",
            "mean accuracy: 0.901 | C=1.00e-01 min_df=30 max_df=0.200\n",
            "\t0.909 \t0.922 \t0.923 \t0.924 \t0.930 \n",
            "mean accuracy: 0.921 | C=1.00e+00 min_df=30 max_df=0.200\n",
            "\t0.910 \t0.922 \t0.919 \t0.925 \t0.922 \n",
            "mean accuracy: 0.920 | C=1.00e+01 min_df=30 max_df=0.200\n",
            "\t0.913 \t0.920 \t0.919 \t0.919 \t0.928 \n",
            "mean accuracy: 0.920 | C=1.00e+02 min_df=30 max_df=0.200\n",
            "\t0.916 \t0.920 \t0.919 \t0.920 \t0.928 \n",
            "mean accuracy: 0.921 | C=1.00e+03 min_df=30 max_df=0.200\n",
            "\t0.891 \t0.913 \t0.910 \t0.905 \t0.907 \n",
            "mean accuracy: 0.905 | C=1.00e-01 min_df=30 max_df=0.300\n",
            "\t0.913 \t0.927 \t0.928 \t0.928 \t0.928 \n",
            "mean accuracy: 0.925 | C=1.00e+00 min_df=30 max_df=0.300\n",
            "\t0.913 \t0.925 \t0.925 \t0.929 \t0.926 \n",
            "mean accuracy: 0.924 | C=1.00e+01 min_df=30 max_df=0.300\n",
            "\t0.915 \t0.924 \t0.924 \t0.928 \t0.925 \n",
            "mean accuracy: 0.923 | C=1.00e+02 min_df=30 max_df=0.300\n",
            "\t0.916 \t0.930 \t0.925 \t0.924 \t0.925 \n",
            "mean accuracy: 0.924 | C=1.00e+03 min_df=30 max_df=0.300\n",
            "\t0.895 \t0.916 \t0.911 \t0.906 \t0.911 \n",
            "mean accuracy: 0.908 | C=1.00e-01 min_df=30 max_df=0.400\n",
            "\t0.919 \t0.931 \t0.932 \t0.930 \t0.933 \n",
            "mean accuracy: 0.929 | C=1.00e+00 min_df=30 max_df=0.400\n",
            "\t0.917 \t0.930 \t0.925 \t0.929 \t0.932 \n",
            "mean accuracy: 0.927 | C=1.00e+01 min_df=30 max_df=0.400\n",
            "\t0.918 \t0.929 \t0.923 \t0.929 \t0.926 \n",
            "mean accuracy: 0.925 | C=1.00e+02 min_df=30 max_df=0.400\n",
            "\t0.919 \t0.932 \t0.924 \t0.930 \t0.930 \n",
            "mean accuracy: 0.927 | C=1.00e+03 min_df=30 max_df=0.400\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [10, 20, 30]:\n",
        "  for max_df in [0.2, 0.3, 0.4]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in 10. ** np.arange(-1, 4):\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrxAcU4l2szK"
      },
      "source": [
        "### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmQ-zwmG2szK",
        "outputId": "a19ae23f-4339-4fbc-e5b2-0451322a4fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t0.894 \t0.916 \t0.912 \t0.901 \t0.904 \n",
            "mean accuracy: 0.906 | C=1.00e-01 min_df=5 max_df=0.300\n",
            "\t0.916 \t0.934 \t0.931 \t0.931 \t0.931 \n",
            "mean accuracy: 0.928 | C=1.00e+00 min_df=5 max_df=0.300\n",
            "\t0.915 \t0.936 \t0.931 \t0.931 \t0.932 \n",
            "mean accuracy: 0.929 | C=1.00e+01 min_df=5 max_df=0.300\n",
            "\t0.913 \t0.937 \t0.931 \t0.932 \t0.934 \n",
            "mean accuracy: 0.929 | C=1.00e+02 min_df=5 max_df=0.300\n",
            "\t0.910 \t0.932 \t0.928 \t0.929 \t0.931 \n",
            "mean accuracy: 0.926 | C=1.00e+03 min_df=5 max_df=0.300\n",
            "\t0.896 \t0.915 \t0.913 \t0.905 \t0.908 \n",
            "mean accuracy: 0.907 | C=1.00e-01 min_df=5 max_df=0.400\n",
            "\t0.914 \t0.937 \t0.934 \t0.931 \t0.932 \n",
            "mean accuracy: 0.930 | C=1.00e+00 min_df=5 max_df=0.400\n",
            "\t0.920 \t0.937 \t0.934 \t0.934 \t0.937 \n",
            "mean accuracy: 0.932 | C=1.00e+01 min_df=5 max_df=0.400\n",
            "\t0.921 \t0.934 \t0.931 \t0.934 \t0.937 \n",
            "mean accuracy: 0.931 | C=1.00e+02 min_df=5 max_df=0.400\n",
            "\t0.916 \t0.934 \t0.931 \t0.931 \t0.935 \n",
            "mean accuracy: 0.929 | C=1.00e+03 min_df=5 max_df=0.400\n",
            "\t0.903 \t0.919 \t0.918 \t0.905 \t0.907 \n",
            "mean accuracy: 0.910 | C=1.00e-01 min_df=5 max_df=0.500\n",
            "\t0.918 \t0.939 \t0.939 \t0.935 \t0.937 \n",
            "mean accuracy: 0.933 | C=1.00e+00 min_df=5 max_df=0.500\n",
            "\t0.922 \t0.940 \t0.938 \t0.937 \t0.937 \n",
            "mean accuracy: 0.935 | C=1.00e+01 min_df=5 max_df=0.500\n",
            "\t0.921 \t0.938 \t0.937 \t0.934 \t0.938 \n",
            "mean accuracy: 0.934 | C=1.00e+02 min_df=5 max_df=0.500\n",
            "\t0.916 \t0.937 \t0.934 \t0.936 \t0.936 \n",
            "mean accuracy: 0.932 | C=1.00e+03 min_df=5 max_df=0.500\n",
            "\t0.895 \t0.917 \t0.913 \t0.904 \t0.905 \n",
            "mean accuracy: 0.907 | C=1.00e-01 min_df=10 max_df=0.300\n",
            "\t0.910 \t0.933 \t0.936 \t0.931 \t0.931 \n",
            "mean accuracy: 0.928 | C=1.00e+00 min_df=10 max_df=0.300\n",
            "\t0.913 \t0.933 \t0.932 \t0.933 \t0.934 \n",
            "mean accuracy: 0.929 | C=1.00e+01 min_df=10 max_df=0.300\n",
            "\t0.909 \t0.929 \t0.934 \t0.930 \t0.934 \n",
            "mean accuracy: 0.927 | C=1.00e+02 min_df=10 max_df=0.300\n",
            "\t0.909 \t0.930 \t0.929 \t0.926 \t0.934 \n",
            "mean accuracy: 0.926 | C=1.00e+03 min_df=10 max_df=0.300\n",
            "\t0.896 \t0.922 \t0.913 \t0.909 \t0.905 \n",
            "mean accuracy: 0.909 | C=1.00e-01 min_df=10 max_df=0.400\n",
            "\t0.918 \t0.935 \t0.934 \t0.932 \t0.932 \n",
            "mean accuracy: 0.930 | C=1.00e+00 min_df=10 max_df=0.400\n",
            "\t0.919 \t0.934 \t0.934 \t0.930 \t0.937 \n",
            "mean accuracy: 0.931 | C=1.00e+01 min_df=10 max_df=0.400\n",
            "\t0.916 \t0.931 \t0.933 \t0.931 \t0.936 \n",
            "mean accuracy: 0.929 | C=1.00e+02 min_df=10 max_df=0.400\n",
            "\t0.915 \t0.933 \t0.930 \t0.929 \t0.935 \n",
            "mean accuracy: 0.928 | C=1.00e+03 min_df=10 max_df=0.400\n",
            "\t0.902 \t0.922 \t0.915 \t0.910 \t0.909 \n",
            "mean accuracy: 0.912 | C=1.00e-01 min_df=10 max_df=0.500\n",
            "\t0.922 \t0.940 \t0.935 \t0.933 \t0.938 \n",
            "mean accuracy: 0.933 | C=1.00e+00 min_df=10 max_df=0.500\n",
            "\t0.921 \t0.939 \t0.938 \t0.932 \t0.939 \n",
            "mean accuracy: 0.934 | C=1.00e+01 min_df=10 max_df=0.500\n",
            "\t0.919 \t0.935 \t0.932 \t0.934 \t0.938 \n",
            "mean accuracy: 0.932 | C=1.00e+02 min_df=10 max_df=0.500\n",
            "\t0.916 \t0.937 \t0.931 \t0.931 \t0.934 \n",
            "mean accuracy: 0.930 | C=1.00e+03 min_df=10 max_df=0.500\n",
            "\t0.891 \t0.919 \t0.913 \t0.905 \t0.904 \n",
            "mean accuracy: 0.906 | C=1.00e-01 min_df=15 max_df=0.300\n",
            "\t0.913 \t0.933 \t0.935 \t0.932 \t0.931 \n",
            "mean accuracy: 0.929 | C=1.00e+00 min_df=15 max_df=0.300\n",
            "\t0.913 \t0.934 \t0.934 \t0.934 \t0.930 \n",
            "mean accuracy: 0.929 | C=1.00e+01 min_df=15 max_df=0.300\n",
            "\t0.911 \t0.928 \t0.931 \t0.931 \t0.926 \n",
            "mean accuracy: 0.925 | C=1.00e+02 min_df=15 max_df=0.300\n",
            "\t0.912 \t0.928 \t0.932 \t0.927 \t0.929 \n",
            "mean accuracy: 0.926 | C=1.00e+03 min_df=15 max_df=0.300\n",
            "\t0.894 \t0.925 \t0.913 \t0.910 \t0.906 \n",
            "mean accuracy: 0.909 | C=1.00e-01 min_df=15 max_df=0.400\n",
            "\t0.919 \t0.934 \t0.935 \t0.937 \t0.931 \n",
            "mean accuracy: 0.931 | C=1.00e+00 min_df=15 max_df=0.400\n",
            "\t0.919 \t0.938 \t0.937 \t0.936 \t0.929 \n",
            "mean accuracy: 0.932 | C=1.00e+01 min_df=15 max_df=0.400\n",
            "\t0.918 \t0.932 \t0.936 \t0.934 \t0.931 \n",
            "mean accuracy: 0.930 | C=1.00e+02 min_df=15 max_df=0.400\n",
            "\t0.916 \t0.932 \t0.931 \t0.931 \t0.932 \n",
            "mean accuracy: 0.929 | C=1.00e+03 min_df=15 max_df=0.400\n",
            "\t0.901 \t0.925 \t0.914 \t0.913 \t0.909 \n",
            "mean accuracy: 0.912 | C=1.00e-01 min_df=15 max_df=0.500\n",
            "\t0.922 \t0.937 \t0.940 \t0.937 \t0.934 \n",
            "mean accuracy: 0.934 | C=1.00e+00 min_df=15 max_df=0.500\n",
            "\t0.924 \t0.939 \t0.939 \t0.937 \t0.935 \n",
            "mean accuracy: 0.935 | C=1.00e+01 min_df=15 max_df=0.500\n",
            "\t0.925 \t0.936 \t0.933 \t0.936 \t0.936 \n",
            "mean accuracy: 0.933 | C=1.00e+02 min_df=15 max_df=0.500\n",
            "\t0.921 \t0.935 \t0.933 \t0.936 \t0.934 \n",
            "mean accuracy: 0.932 | C=1.00e+03 min_df=15 max_df=0.500\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [5, 10, 15]:\n",
        "  for max_df in [0.3, 0.4, 0.5]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in 10. ** np.arange(-1, 4):\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp8zxTaZ2szK",
        "outputId": "00c2fdc8-ce35-4ce0-c960-848ce62a329a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t0.924 \t0.939 \t0.939 \t0.937 \t0.935 \n",
            "mean accuracy: 0.935 | C=1.00e+01 min_df=15 max_df=0.500\n",
            "\t0.929 \t0.940 \t0.941 \t0.942 \t0.943 \n",
            "mean accuracy: 0.939 | C=1.00e+01 min_df=15 max_df=0.700\n",
            "\t0.934 \t0.940 \t0.943 \t0.943 \t0.941 \n",
            "mean accuracy: 0.940 | C=1.00e+01 min_df=15 max_df=1.000\n",
            "\t0.924 \t0.937 \t0.933 \t0.932 \t0.936 \n",
            "mean accuracy: 0.932 | C=1.00e+01 min_df=20 max_df=0.500\n",
            "\t0.928 \t0.938 \t0.937 \t0.941 \t0.941 \n",
            "mean accuracy: 0.937 | C=1.00e+01 min_df=20 max_df=0.700\n",
            "\t0.929 \t0.943 \t0.939 \t0.944 \t0.943 \n",
            "mean accuracy: 0.940 | C=1.00e+01 min_df=20 max_df=1.000\n",
            "\t0.923 \t0.935 \t0.925 \t0.934 \t0.936 \n",
            "mean accuracy: 0.931 | C=1.00e+01 min_df=30 max_df=0.500\n",
            "\t0.927 \t0.940 \t0.932 \t0.942 \t0.943 \n",
            "mean accuracy: 0.937 | C=1.00e+01 min_df=30 max_df=0.700\n",
            "\t0.924 \t0.942 \t0.934 \t0.944 \t0.937 \n",
            "mean accuracy: 0.936 | C=1.00e+01 min_df=30 max_df=1.000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [15, 20, 30]:\n",
        "  for max_df in [0.5, 0.7, 1.0]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in [10.0]:\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QShaXKTL2szK",
        "outputId": "cceaae55-5bc3-49fa-ac7b-5aee40e9ca78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.947\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=20)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "clf = LinearSVC(C=10.0, dual=False, max_iter=1000, random_state=123)\n",
        "clf.fit(X, labels)\n",
        "X_test = vectorizer.transform(corpus_test)\n",
        "score = clf.score(X_test, ds[\"test\"][\"category\"])\n",
        "print(f\"{score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題\n",
        "* この分類性能を改良できるかどうか、試行錯誤してみてください。\n",
        "  * 注意：データセットの分割の仕方は変えないように。"
      ],
      "metadata": {
        "id": "wqdke7FI28vr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}