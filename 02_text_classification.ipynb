{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/02_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-w8jUVl2szF"
      },
      "source": [
        "# テキスト分類\n",
        "* BoWでも良い性能を出せることが多い。\n",
        "  * LLMを使って文書分類するときは、BoW+SVMの性能と比較した方が良い。\n",
        "  * なぜなら、分類性能に大きな差がつかないことも、しばしばあるので。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU529kZR2szH"
      },
      "source": [
        "## spaCyのインストール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnIyf5Kb2szI"
      },
      "source": [
        "* 最小限のインストール\n",
        "  * 英語だけ扱えるようになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_97cAWK2szI"
      },
      "outputs": [],
      "source": [
        "#!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIIy7LnT2szI"
      },
      "source": [
        "* spaCyで日本語を扱えるようにする。\n",
        "  * sudachiという形態素解析器が使えるようになる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3RW3h742szJ"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download ja_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg1JBgXU2szJ"
      },
      "source": [
        "## データセット\n",
        "* ライブドアニュースコーパスの本文部分を使う。\n",
        "  * 9値分類。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma1dUc8r2szJ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\n",
        "    \"shunk031/livedoor-news-corpus\",\n",
        "    train_ratio=0.8,\n",
        "    val_ratio=0.1,\n",
        "    test_ratio=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptuaJk9O2szJ"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTBvLjgm2szJ"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "  'movie-enter',\n",
        "  'it-life-hack',\n",
        "  'kaden-channel',\n",
        "  'topic-news',\n",
        "  'livedoor-homme',\n",
        "  'peachy',\n",
        "  'sports-watch',\n",
        "  'dokujo-tsushin',\n",
        "  'smax',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvsgSnty2szJ"
      },
      "outputs": [],
      "source": [
        "ds[\"train\"][\"content\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuO5V5Jw2szJ"
      },
      "source": [
        "## 形態素解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmx5x_8Q2szK"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"ja_core_news_sm\")\n",
        "doc = nlp(ds[\"train\"][\"content\"][0])\n",
        "for token in doc:\n",
        "  print(token.lemma_, end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWXMwlwz2szK"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "corpus_train = []\n",
        "for text in tqdm(ds[\"train\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_train.append(\" \".join([token.lemma_ for token in doc]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI3TGfvw2szK"
      },
      "outputs": [],
      "source": [
        "with open('livedoor-news-corpus_content_lemmatized.txt', 'w') as f:\n",
        "  f.write(\"\\n\".join(corpus_train) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mXoZHR42szK"
      },
      "outputs": [],
      "source": [
        "corpus_train = []\n",
        "with open('livedoor-news-corpus_content_lemmatized.txt', 'r') as f:\n",
        "  for text in f:\n",
        "    corpus_train.append(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEDViFJg2szK"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azmYC6HJ2szK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=10, max_df=0.2)\n",
        "X = vectorizer.fit_transform(corpus_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4deaBWAG2szK"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WoZ8RUO2szK"
      },
      "outputs": [],
      "source": [
        "corpus_val = []\n",
        "for text in tqdm(ds[\"validation\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_val.append(\" \".join([token.lemma_ for token in doc]))\n",
        "\n",
        "corpus_test = []\n",
        "for text in tqdm(ds[\"test\"][\"content\"]):\n",
        "  doc = nlp(text)\n",
        "  corpus_test.append(\" \".join([token.lemma_ for token in doc]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgTwGYuo2szK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "corpus = np.array(corpus_train + corpus_val)\n",
        "len(corpus)\n",
        "labels = np.array(ds[\"train\"][\"category\"] + ds[\"validation\"][\"category\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVmRwp8H2szK"
      },
      "source": [
        "## ハイパーパラメータのチューニング\n",
        "* SVMの正則化パラメータ`C`\n",
        "* TfidfVectorizerの`min_df`と`max_df`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrIiA8j82szK"
      },
      "source": [
        "### 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qim4TH6A2szK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [10, 20, 30]:\n",
        "  for max_df in [0.2, 0.3, 0.4]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in 10. ** np.arange(-1, 4):\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrxAcU4l2szK"
      },
      "source": [
        "### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmQ-zwmG2szK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [5, 10, 15]:\n",
        "  for max_df in [0.3, 0.4, 0.5]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in 10. ** np.arange(-1, 4):\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp8zxTaZ2szK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "for min_df in [15, 20, 30]:\n",
        "  for max_df in [0.5, 0.7, 1.0]:\n",
        "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
        "    for C in [10.0]:\n",
        "      scores = []\n",
        "      skf_split = skf.split(corpus, labels)\n",
        "      for train_index, val_index in skf_split:\n",
        "        X_train = vectorizer.fit_transform(corpus[train_index])\n",
        "        clf = LinearSVC(C=C, dual=False, max_iter=1000, random_state=123)\n",
        "        clf.fit(X_train, labels[train_index])\n",
        "        X_val = vectorizer.transform(corpus[val_index])\n",
        "        score = clf.score(X_val, labels[val_index])\n",
        "        print(f\"\\t{score:.3f}\", end=\" \")\n",
        "        scores.append(score)\n",
        "      print(f\"\\nmean accuracy: {np.array(scores).mean():.3f}\", end=\"\")\n",
        "      print(f\" | C={C:.2e} min_df={min_df} max_df={max_df:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QShaXKTL2szK"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=20)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "clf = LinearSVC(C=10.0, dual=False, max_iter=1000, random_state=123)\n",
        "clf.fit(X, labels)\n",
        "X_test = vectorizer.transform(corpus_test)\n",
        "score = clf.score(X_test, ds[\"test\"][\"category\"])\n",
        "print(f\"{score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題\n",
        "* この分類性能を改良できるかどうか、試行錯誤してみてください。\n",
        "  * 注意：データセットの分割の仕方は変えないように。"
      ],
      "metadata": {
        "id": "wqdke7FI28vr"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}