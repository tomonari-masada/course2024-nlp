{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/EDA_with_multilingual_e5_large_instruct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvTBVPUmHH-f"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from transformers.modeling_outputs import ModelOutput\n",
        "\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtDjHIjWHH-g"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\n",
        "    \"shunk031/livedoor-news-corpus\",\n",
        "    train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "num_categories = len(set(dataset[\"train\"][\"category\"]))\n",
        "max_seq_length = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp-j-eL2HH-g"
      },
      "source": [
        "* https://huggingface.co/intfloat/multilingual-e5-large-instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opvTLmdxHH-h",
        "outputId": "755868e3-3d21-46db-8985-8ec7484e75cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/masada/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at intfloat/multilingual-e5-large-instruct and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_id = \"intfloat/multilingual-e5-large-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "pretrained = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_categories,\n",
        ").to(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTEm5UAnHH-i",
        "outputId": "4a1efa89-9afc-4540-c482-79a4a60c7f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): XLMRobertaClassificationHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=1024, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXUmA7PlHH-i",
        "outputId": "ab8e810e-ca86-4e13-f110-dd2050095822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XLMRobertaConfig {\n",
              "  \"_name_or_path\": \"intfloat/multilingual-e5-large-instruct\",\n",
              "  \"architectures\": [\n",
              "    \"XLMRobertaModel\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 1024,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\",\n",
              "    \"3\": \"LABEL_3\",\n",
              "    \"4\": \"LABEL_4\",\n",
              "    \"5\": \"LABEL_5\",\n",
              "    \"6\": \"LABEL_6\",\n",
              "    \"7\": \"LABEL_7\",\n",
              "    \"8\": \"LABEL_8\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 4096,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2,\n",
              "    \"LABEL_3\": 3,\n",
              "    \"LABEL_4\": 4,\n",
              "    \"LABEL_5\": 5,\n",
              "    \"LABEL_6\": 6,\n",
              "    \"LABEL_7\": 7,\n",
              "    \"LABEL_8\": 8\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"xlm-roberta\",\n",
              "  \"num_attention_heads\": 16,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.40.0\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250002\n",
              "}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrained.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP-e5RD8HH-i"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, tokenizer, corpus, labels, batch_size=4):\n",
        "    model.eval()\n",
        "    num_correct_answers, num_answers = 0, 0\n",
        "    for i in tqdm(range(0, len(corpus), batch_size)):\n",
        "        texts = corpus[i:i+batch_size]\n",
        "        encodings = tokenizer(texts, padding=True, return_tensors=\"pt\")\n",
        "        encodings = encodings.to(model.device)\n",
        "        category = torch.tensor(labels[i:i+batch_size]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encodings)\n",
        "        predicted = outputs.logits.argmax(-1)\n",
        "        num_correct_answers += (predicted == category).sum()\n",
        "        num_answers += len(texts)\n",
        "    model.train()\n",
        "    return (num_correct_answers / num_answers).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3DM77qoHH-i"
      },
      "outputs": [],
      "source": [
        "def average_pool(last_hidden_states, attention_mask):\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uopw_blHH-i"
      },
      "outputs": [],
      "source": [
        "def embed(model, tokenizer, corpus, batch_size=4):\n",
        "    model.eval()\n",
        "    pooled_hidden_states = []\n",
        "    for i in tqdm(range(0, len(corpus), batch_size)):\n",
        "        texts = corpus[i:i+batch_size]\n",
        "        encodings = tokenizer(texts, padding=True, return_tensors=\"pt\")\n",
        "        encodings = encodings.to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.roberta(**encodings)\n",
        "        pooled_hidden_state = average_pool(\n",
        "            outputs.last_hidden_state,\n",
        "            encodings['attention_mask'],\n",
        "        )\n",
        "        pooled_hidden_state = pooled_hidden_state.float().cpu().numpy()\n",
        "        pooled_hidden_states.append(pooled_hidden_state)\n",
        "    model.train()\n",
        "    return np.concatenate(pooled_hidden_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHSafcDOHH-i",
        "outputId": "28e1909a-d78b-4563-b164-6159c879033c",
        "colab": {
          "referenced_widgets": [
            "35753b64e8f64024987b43a8511b33f8",
            "e2ce29cb76b440e189108b34a075e0d7",
            "3ffa05901aaf4e6d8671307ab2846e66"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35753b64e8f64024987b43a8511b33f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1474 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2ce29cb76b440e189108b34a075e0d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/185 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ffa05901aaf4e6d8671307ab2846e66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/184 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embeddings = {}\n",
        "for key in dataset:\n",
        "    embeddings[key] = embed(pretrained, tokenizer, dataset[key][\"title\"])\n",
        "    embeddings[key] = normalize(embeddings[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCHRAG_KHH-j",
        "outputId": "de9440a1-8ca3-4002-9ff7-63b24bd42cad",
        "colab": {
          "referenced_widgets": [
            "493ace26cb3f4771b1e232390ef9d751",
            "bd4c7310eafa45429c2cf78371e262e8",
            "d18de5dba35b41f0b419b000b0d12c05"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "493ace26cb3f4771b1e232390ef9d751",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5894 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd4c7310eafa45429c2cf78371e262e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/737 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d18de5dba35b41f0b419b000b0d12c05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/736 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_pos_tags = [\"NOUN\", \"VERB\", \"PROPN\"]\n",
        "\n",
        "nlp = spacy.load(\"ja_core_news_sm\")\n",
        "corpus = {}\n",
        "for key in dataset:\n",
        "    corpus[key] = []\n",
        "    for text in tqdm(dataset[key][\"title\"]):\n",
        "        corpus[key].append(\" \".join(\n",
        "            [token.lemma_\n",
        "             for token in nlp(text) if token.pos_ in label_pos_tags\n",
        "            ]\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlZ12KcdHH-j",
        "outputId": "0574357c-edec-40c8-d9eb-4a111a75de1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'トレンド マイクロ サービス safesync 無料 体験 横浜 スタジアム 貸切 権 デジカメ 当てる !'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSUqoMfsHH-j"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=10, max_df=0.1, lowercase=False)\n",
        "vectorizer.fit(corpus[\"train\"])\n",
        "vocab = np.array(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UyM91vHHH-j",
        "outputId": "4ff11475-bbc0-4fd3-f5b0-b0b4f5327f36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1人', '1日', '2人', 'AQUOS', 'Android', 'CM', 'CPU', 'DVD', 'Excel',\n",
              "       'Facebook', 'Fi', 'GHz', 'GX', 'Google', 'HD', 'HT', 'HTC', 'ICS',\n",
              "       'IS', 'IT', 'In', 'KDDI', 'LAN', 'Mac', 'Mobile', 'NHK', 'NTT',\n",
              "       'No', 'OK', 'OS', 'Office', 'PC', 'Play', 'REPORT', 'SC', 'SH',\n",
              "       'SII', 'SNS', 'SO', 'SPORTS', 'SX', 'TV', 'Twitter', 'UP', 'USB',\n",
              "       'Ubuntu', 'VS', 'Vol', 'Wi', 'Windows', 'Word', 'W杯', 'akb',\n",
              "       'android', 'arrows', 'au', 'by', 'cafe', 'eluga', 'for', 'galaxy',\n",
              "       'hulu', 'iOS', 'iPhone', 'iii', 'ipad', 'isw', 'jojo', 'lte',\n",
              "       'medias', 'mm', 'note', 'nottv', 'optimus', 'pantone', 'peachy',\n",
              "       'phone', 'presented', 'regza', 'salon', 'siii', 'sim', 'tab',\n",
              "       'touch', 'ultrabook', 'watch', 'web', 'wimax', 'xi', 'xperia',\n",
              "       'あらわれる', 'あり', 'ある', 'いう', 'いく', 'いける', 'いる', 'おく', 'お気に入り', 'かける',\n",
              "       'くさる', 'くす', 'くる', 'くれる', 'こと', 'さん', 'しまう', 'すぎる', 'する', 'たち',\n",
              "       'ため', 'ちゃん', 'つく', 'つける', 'できる', 'とき', 'とも', 'どっち', 'なし', 'なでしこ',\n",
              "       'なる', 'なれる', 'にゅう', 'ねこ', 'はじめる', 'ひとり', 'ぶり', 'まとめ', 'まとめる', 'まま',\n",
              "       'みる', 'みんな', 'もの', 'もらう', 'やめる', 'やる', 'ゆるい', 'よう', 'よめ', 'よる',\n",
              "       'らくらく', 'わかる', 'アイテム', 'アイドル', 'アカデミー', 'アクション', 'アクセス', 'アップ',\n",
              "       'アップデート', 'アップル', 'アナ', 'アナタ', 'アニメ', 'アプリ', 'アベンジャーズ', 'アメリカ',\n",
              "       'アリ', 'イケショップ', 'イケメン', 'イベント', 'イメージ', 'インタビュー', 'インターネット', 'インチ',\n",
              "       'インテル', 'イー', 'ウラ', 'エリカ', 'エンター', 'オススメ', 'オトコ', 'オトナ', 'オフィス',\n",
              "       'オリジナル', 'オンナ', 'オンライン', 'オープン', 'カバー', 'カフェ', 'カメラ', 'カード', 'ガイド',\n",
              "       'ガール', 'ガールズ', 'キム', 'キャラ', 'キャラクター', 'キャンペーン', 'キーボード', 'クアッドコア',\n",
              "       'クラウド', 'クリスマス', 'グッズ', 'ケア', 'ケーキ', 'ケース', 'ケータイ', 'ゲット', 'ゲーム',\n",
              "       'コスメ', 'コミック', 'コメント', 'コラボ', 'コラム', 'コレ', 'コレクション', 'コンテンツ',\n",
              "       'コンパクト', 'ゴルフ', 'サイト', 'サイフ', 'サッカー', 'サポート', 'サロン', 'サービス',\n",
              "       'システム', 'シャープ', 'ショップ', 'ショー', 'シリーズ', 'ジャパン', 'スイーツ', 'スタイル',\n",
              "       'スター', 'スタート', 'ストア', 'ストーリー', 'スピード', 'スペシャル', 'スペック', 'スポット',\n",
              "       'スポーツ', 'スマホ', 'スマートフォン', 'スーツ', 'スーパー', 'セキュリティ', 'セクシー', 'セット',\n",
              "       'センター', 'ソニー', 'ソフト', 'ソフトウェア', 'ソフトバンク', 'ソーシャル', 'タイプ', 'タイム',\n",
              "       'タッチ', 'タブレット', 'ダイエット', 'ダウンロード', 'ダメ', 'ダルビッシュ', 'ダーク', 'チェック',\n",
              "       'チャンス', 'チーム', 'ツイッター', 'ツイート', 'テクニック', 'テスト', 'テレビ', 'ディスプレイ',\n",
              "       'ディズニー', 'デザイン', 'デジ', 'デジカメ', 'デジタル', 'デバイス', 'デビュー', 'デュアルコア',\n",
              "       'データ', 'デート', 'トップ', 'トラブル', 'トレンド', 'トーク', 'ドキドキ', 'ドコモ', 'ドライブ',\n",
              "       'ドラマ', 'ナイト', 'ニコニコ', 'ニュー', 'ニュース', 'ネット', 'ノム', 'ノート', 'ハイ',\n",
              "       'ハリウッド', 'バッテリー', 'バトル', 'バレンタイン', 'バンド', 'バージョン', 'パソコン',\n",
              "       'パナソニック', 'パワー', 'ヒロイン', 'ビジネス', 'ビジネスマン', 'ビデオ', 'ビューティ',\n",
              "       'ビューティー', 'ピンク', 'ファイル', 'ファッション', 'ファン', 'フジテレビ', 'フラッシュバック',\n",
              "       'ブック', 'ブラウザ', 'ブラック', 'ブランド', 'ブログ', 'ブース', 'ブーム', 'プラチナ',\n",
              "       'プレイヤー', 'プレゼント', 'プレミア', 'プレーヤー', 'プロ', 'プロジェクト', 'ベスト', 'ベルセルク',\n",
              "       'ページ', 'ホテル', 'ホント', 'ホーム', 'ボディ', 'ボール', 'ポイント', 'ポスター', 'マザー',\n",
              "       'マン', 'マンガ', 'マーク', 'ムービー', 'メイク', 'メディア', 'メンバー', 'メーカー', 'メール',\n",
              "       'モテる', 'モデル', 'モバイル', 'モバステ', 'モード', 'ユーザー', 'ライフ', 'ライフスタイル',\n",
              "       'ランキング', 'リアル', 'リラックス', 'リリース', 'リーダー', 'ルーター', 'レア', 'レシピ',\n",
              "       'レビュー', 'レビューアー', 'レポート', 'ロゴ', 'ロック', 'ロンドン', 'ワイヤレス', 'ワケ', 'ワザ',\n",
              "       'ワン', 'ワンセグ', '一部', '上がる', '上げる', '上映', '上陸', '世代', '世界', '両論',\n",
              "       '中国', '中島', '主演', '主題', '乗る', '予告', '予定', '予約', '事件', '事前', '事情',\n",
              "       '事故', '五輪', '交際', '人事', '人気', '人生', '人間', '人類', '今夏', '今年', '今度',\n",
              "       '今週', '仕事', '付き', '付く', '付ける', '代表', '以上', '企業', '企画', '会える', '会社',\n",
              "       '会議', '伝統', '体験', '作る', '作品', '使い方', '使う', '使える', '価値', '価格', '便利',\n",
              "       '保護', '俳優', '候補', '健康', '働く', '優勝', '優子', '充電', '先行', '入り', '入る',\n",
              "       '入れる', '入力', '入門', '全国', '全部', '公式', '公開', '共有', '具合', '写真', '出す',\n",
              "       '出る', '出会い', '出展', '出演', '分かる', '切る', '利用', '刺激', '前田', '劇場', '効く',\n",
              "       '効果', '動画', '募集', '卒業', '原因', '原発', '参加', '友達', '反応', '取る', '受ける',\n",
              "       '受賞', '合う', '合わせる', '吉田', '名前', '向け', '告白', '周年', '味方', '呼ぶ', '商品',\n",
              "       '問題', '回線', '図鑑', '国内', '国際', '圭佑', '報道', '売れる', '売れ筋', '変える',\n",
              "       '変わる', '変化', '変更', '大丈夫', '大人', '大島', '大阪', '天才', '奇跡', '契約', '女優',\n",
              "       '女子', '女性', '姉妹', '婚活', '子ども', '子供', '存在', '学ぶ', '実力', '実態', '実施',\n",
              "       '実現', '実践', '宣言', '家庭', '家族', '家電', '容量', '対する', '対応', '対決', '対策',\n",
              "       '専用', '少女', '展示', '岡田', '巨人', '市場', '年収', '広がる', '座談', '引く', '引退',\n",
              "       '当たる', '影響', '役立つ', '彼氏', '待望', '得る', '復帰', '復活', '徹底', '必要', '必見',\n",
              "       '必須', '応援', '怒り', '怒る', '思う', '恋人', '恋愛', '恐怖', '悩み', '悩む', '情報',\n",
              "       '意味', '意識', '愛す', '感ずる', '感動', '感覚', '成功', '成長', '批判', '批評', '投手',\n",
              "       '披露', '担当', '招待', '持つ', '挑戦', '振る', '採用', '掲示', '掴める', '描く', '提供',\n",
              "       '提案', '搭載', '携帯', '撮る', '撮影', '操作', '支援', '改善', '放射', '放送', '放題',\n",
              "       '教える', '敦子', '文字', '斎藤', '料理', '料金', '新作', '新型', '新聞', '方法', '日本',\n",
              "       '明かす', '星野', '映像', '映画', '時代', '時間', '暴露', '更新', '書籍', '替える', '最大',\n",
              "       '最強', '最後', '最新', '最終', '最近', '月額', '期待', '期間', '未来', '本当', '本日',\n",
              "       '本格', '本田', '本音', '来る', '来日', '東京', '東北', '松井', '柔道', '株式', '楽しむ',\n",
              "       '楽しめる', '楽天', '横浜', '橋下', '機種', '機能', '次ぐ', '殺到', '母親', '毎日', '比較',\n",
              "       '気分', '気持ち', '求める', '決定', '波紋', '泣く', '注意', '注目', '活動', '活用', '海外',\n",
              "       '液晶', '測定', '満載', '激怒', '炎上', '無料', '無線', '物議', '特集', '状態', '狙う',\n",
              "       '独女', '獲得', '理由', '生活', '田中', '男子', '男性', '画像', '画面', '番組', '疑問',\n",
              "       '癒し', '癒す', '発売', '発生', '発表', '発覚', '発言', '登場', '登録', '監督', '目指す',\n",
              "       '相手', '真司', '真央', '知る', '石井', '研究', '社会', '社長', '秘密', '秘訣', '移籍',\n",
              "       '突破', '端末', '笑う', '管理', '節電', '紹介', '紺子', '終了', '経験', '結婚', '結果',\n",
              "       '絶対', '絶賛', '続々', '続く', '続ける', '続出', '編集', '練習', '美人', '美女', '美容',\n",
              "       '美肌', '考える', '聞く', '職場', '自分', '自動車', '自宅', '自殺', '自転車', '芸能',\n",
              "       '苦言', '落合', '虎の巻', '行く', '行動', '行為', '衝撃', '表示', '被害', '被災', '裏技',\n",
              "       '製品', '複数', '見える', '見せる', '見る', '規模', '視聴', '観る', '解決', '解消', '解禁',\n",
              "       '解説', '言う', '言及', '言葉', '記事', '記念', '記録', '設定', '試す', '試写', '試合',\n",
              "       '話題', '誕生', '語る', '説教', '読み', '読む', '調査', '講座', '謝罪', '豪華', '負ける',\n",
              "       '販売', '買う', '賛否', '購入', '贈る', '赤外', '起こす', '起動', '超える', '転職', '軽量',\n",
              "       '辛口', '込む', '返る', '迫る', '追加', '通信', '通話', '速報', '連動', '連発', '連続',\n",
              "       '連載', '逮捕', '週末', '週間', '進化', '運命', '過ぎる', '過ごす', '過去', '違い', '違う',\n",
              "       '選ぶ', '選手', '部屋', '部門', '配信', '野球', '鑑賞', '長友', '開催', '開始', '開幕',\n",
              "       '開発', '関係', '関西', '関連', '防塵', '防水', '限定', '隠す', '離婚', '電力', '電子',\n",
              "       '電気', '電池', '電源', '電話', '震災', '非難', '韓国', '韓流', '音声', '音楽', '風呂',\n",
              "       '飛ぶ', '食べる', '飲む', '香川', '騒動', '騒然', '驚き', '驚愕', '高橋', '高級', '魅力'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJCJNDx3HH-j",
        "outputId": "edfd66fe-3e8d-4ee0-bd03-2f9fa852f33d",
        "colab": {
          "referenced_widgets": [
            "9e2fed465858407790815852ca72da45"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e2fed465858407790815852ca72da45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/213 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocab_embeddings = embed(pretrained, tokenizer, list(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evGO9c-MHH-l",
        "outputId": "c4bba614-61ee-47b2-caf9-e0d60aaefa58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "850"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3PFYVOdHH-l"
      },
      "outputs": [],
      "source": [
        "n_clusters = 30\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=123)\n",
        "kmeans.fit(embeddings[\"train\"])\n",
        "centers = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xMOn3NFHH-l",
        "outputId": "0a0a2228-61e8-4bf3-df73-15aeb81643a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[68, 79, 84, 101, 103, 132, 135, 136, 137, 157, 160, 162, 163, 170, 175, 176, 200, 216, 217, 227, 227, 240, 254, 273, 285, 290, 296, 306, 339, 386]\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
        "size_dict = dict(zip(unique, counts))\n",
        "print(sorted([item[1] for item in size_dict.items()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xlif4VXHH-l",
        "outputId": "9b93adb7-cd19-43c7-9e99-5c6b32597b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "インテル パソコン シャープ デジ パナソニック 搭載 デュアルコア ソニー モバステ クアッドコア コレ はじめる 機種 トップ サイフ キーボード ニコニコ ホーム 楽天 超える\n",
            "コレ すぎる しまう 騒動 負ける なる ダメ たち 感ずる ワケ どっち アナタ 込む さん 物議 騒然 ツイッター する なでしこ 超える\n",
            "アナタ なでしこ 真央 エリカ コレ 優子 オンナ モテる 超える たち 愛す ヒロイン さん くれる みる アナ ドキドキ しまう 真司 イケメン\n",
            "モテる しまう アナタ 愛す 超える なれる オンナ 込む コレ 彼氏 週間 お気に入り トップ なでしこ くす イケショップ 感ずる ベスト イケメン 今週\n",
            "イケショップ モバステ ケータイ ドコモ スマホ シャープ 楽天 スマートフォン バッテリー コレ タブレット 携帯 ソニー ソフトバンク 端末 充電 アップル 搭載 モバイル パナソニック\n",
            "コレ なでしこ くれる イケショップ アナタ バレンタイン らくらく ホーム お気に入り 愛す しまう にゅう ベルセルク 癒す よめ エリカ 超える 過ごす ゲット トップ\n",
            "コレ アナタ しまう 超える なる たち くれる なでしこ 込む おく する よる なれる どっち さん みる ウラ くす 虎の巻 感ずる\n",
            "コレ 選手 負ける なでしこ ワケ 圭佑 観る どっち アナタ 超える ツイッター なる しまう 狙う たち プレーヤー みる W杯 見る よる\n",
            "虎の巻 裏技 はじめる まとめる トップ 使い方 コレ ワザ しまう フラッシュバック まとめ 入れる サイフ 込む 付ける 隠す する ツイッター 使う ニコニコ\n",
            "虎の巻 ハリウッド 上映 アベンジャーズ ムービー アナタ 映画 コレ 超える 観る 必見 ディズニー フジテレビ フラッシュバック 登場 復活 ワンセグ 主演 新作 なでしこ\n",
            "ニコニコ ツイッター ツイート コレ ネット はじめる トップ しまう サイト する ホーム アナタ 楽天 ブログ インターネット サイフ どっち みる 超える モバステ\n",
            "コレ アナタ なでしこ しまう 負ける 泣く 真央 ワケ たち 超える なる すぎる エリカ 虎の巻 さん オンナ 真司 込む フジテレビ 感ずる\n",
            "どっち アナタ モテる しまう オンナ コレ たち くれる なれる 彼氏 なる みる 込む する さん なでしこ 悩む 愛す くる いる\n",
            "ソフトバンク ドコモ NTT 楽天 モバステ ケータイ シャープ モバイル パナソニック 携帯 スマホ ニコニコ スマートフォン ソニー ホーム 放題 ワンセグ キャンペーン ネット トップ\n",
            "イケショップ ビューティ 美肌 コレ アナタ ビューティー なでしこ モテる らくらく しまう くれる トップ くす オススメ よめ オンナ シャープ にゅう エリカ なれる\n",
            "ドコモ ソフトバンク アップデート NTT スマートフォン ケータイ スマホ モバイル モバステ 端末 ソニー 携帯 搭載 パナソニック 機種 バージョン シャープ ダウンロード 更新 デジ\n",
            "ドコモ ソフトバンク スマートフォン スマホ ケータイ ソニー モバイル 携帯 端末 モバステ タブレット パナソニック 機種 シャープ NTT デジ インテル 楽天 HTC 搭載\n",
            "負ける コレ なでしこ 選手 どっち 優勝 なる W杯 しまう ワケ 圭佑 すぎる アナタ 超える たち ダメ ジャパン 虎の巻 返る 込む\n",
            "コレ アナタ ニコニコ 超える しまう どっち なでしこ すぎる ツイッター ワケ なる たち 負ける なれる さん ツイート にゅう みる よる ワンセグ\n",
            "ドコモ スマートフォン スマホ ケータイ ソフトバンク 携帯 モバイル 端末 モバステ 機種 デジ ソニー パナソニック デジカメ シャープ タブレット 搭載 楽天 インテル スペック\n",
            "コレ 圭佑 負ける なでしこ アナタ どっち しまう 超える なる ワケ なれる たち 虎の巻 選手 込む 狙う よる さん 岡田 くれる\n",
            "虎の巻 アナタ オンナ ヒロイン ワンセグ コレ モテる 愛す 観る ドキドキ なでしこ エリカ 超える ムービー ハリウッド ストーリー 映画 バレンタイン フラッシュバック アベンジャーズ\n",
            "アベンジャーズ 虎の巻 コレ 超える アナタ フラッシュバック ハリウッド 復活 ディズニー 登場 最強 巨人 サイフ イー 新作 なでしこ たち ドキドキ エリカ ベルセルク\n",
            "アプリ スマホ ニコニコ ドコモ スマートフォン モバイル 楽天 モバステ ソフトバンク ダウンロード 携帯 タブレット ケータイ アップル オススメ お気に入り 使える はじめる シャープ ツイッター\n",
            "パナソニック シャープ モバステ 楽天 売れ筋 イケショップ ソニー コレ ホーム 家電 売れる トップ デジ インテル アナタ 機種 超える オススメ らくらく ベルセルク\n",
            "オンナ モテる アナタ しまう 彼氏 コレ なでしこ オトコ たち 愛す 優子 ひとり オトナ くれる なれる ヒロイン エリカ みる 超える どっち\n",
            "ドコモ スマホ ケータイ ソフトバンク モバステ スマートフォン 携帯 モバイル アップル 端末 ニコニコ シャープ コレ どっち ソニー 楽天 タブレット しまう デジ 機種\n",
            "デジカメ 撮る カメラ デジ 撮影 パナソニック ソニー 写真 ビデオ コレ ニコニコ デジタル モバステ ワンセグ 超える 映像 シャープ フラッシュバック イケショップ みる\n",
            "アナタ トップ しまう コレ ビジネスマン する 込む 超える やる 転職 どっち 負ける たち なでしこ 出す 続ける なれる なる インタビュー サイフ\n",
            "アプリ ニコニコ スマホ コレ アップル モバステ タッチ ドコモ にゅう アナタ ツイッター しまう 試す ワンセグ 楽天 スマートフォン イケショップ なでしこ 超える モバイル\n"
          ]
        }
      ],
      "source": [
        "topic_words = []\n",
        "similarities = cosine_similarity(vocab_embeddings, centers)\n",
        "for i in range(similarities.shape[-1]):\n",
        "    indices = np.argsort(- similarities[:,i])\n",
        "    topic_words.append(\" \".join(list(vocab[indices[:20]])))\n",
        "print(\"\\n\".join(topic_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTaMaM2kHH-l"
      },
      "outputs": [],
      "source": [
        "X_train = vectorizer.transform(corpus[\"train\"]).toarray()\n",
        "vocab_embeddings = np.dot((X_train / X_train.sum(0)).T, embeddings[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcPA96LWHH-m",
        "outputId": "6dfc637e-898c-4f85-c129-ca7b5b4a8869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PC デジ パソコン 登場 新型 ノート 製品 シリーズ 使える 機能 HD ultrabook 液晶 Windows 使う ディスプレイ データ 発売 対応 販売\n",
            "批判 殺到 非難 物議 続出 次ぐ 発言 ネット 賛否 騒動 怒り 掲示 激怒 コメント 波紋 問題 受ける 疑問 炎上 ユーザー\n",
            "さん 披露 美女 ある いく いる こと インタビュー くる 見る ちゃん 美人 出演 女優 注目 すぎる 少女 人気 する デビュー\n",
            "週間 ランキング ライフスタイル 登録 お気に入り 記事 ビューティー 恋愛 行動 方法 ビューティ 彼氏 効く 作る なれる みんな つける 女子 なる する\n",
            "ケース イケショップ レア 専用 カバー スマホ バッテリー チェック 使える for iPhone 充電 グッズ アイテム 容量 機能 使う 紹介 登場 売れ筋\n",
            "気分 楽しむ プレゼント 入れる 行く 本格 人気 癒す ため 大人 なる くれる 贈る 期間 誕生 今年 特集 注目 作る 見る\n",
            "ある いう する こと いる なる つく 出る 思う いく やる もの 見る 取る さん くる 時代 くれる 変わる 出す\n",
            "watch SPORTS 選手 試合 監督 プロ 代表 星野 チーム 野球 巨人 語る なでしこ 本田 サッカー 開幕 岡田 ノム スポーツ アナ\n",
            "虎の巻 得る ワザ 知る Word ファイル Excel テクニック 便利 入力 管理 表示 役立つ 操作 活用 裏技 使う 方法 使い方 Facebook\n",
            "映画 作品 主演 上映 公開 国際 ストーリー プレミア 描く 映像 アカデミー 解禁 まとめ 感動 受賞 決定 ハリウッド 編集 超える 予告\n",
            "情報 話題 利用 サービス 使う わかる みる サイト なる よる できる つく メディア web あり ユーザー ニュース 公式 使える する\n",
            "さん 発言 対する 騒然 暴露 出演 ファン コメント いく 出る いる 騒動 告白 明かす 続出 受ける akb 関係 次ぐ 報道\n",
            "男性 いる もの 事情 する 本当 なる しまう 思う ある こと アリ 女性 とき 聞く 結婚 いう 自分 求める たち\n",
            "開始 実施 サービス 通信 キャンペーン 端末 利用 向け モバイル ドコモ 購入 回線 対応 料金 スマホ ソフトバンク NTT au ケータイ 発表\n",
            "入れる 美容 アイテム 目指す 作る 美人 ゲット なれる 美肌 ケア ため 効果 なる 人気 楽しむ 注目 つける 取る メイク 生活\n",
            "ソフトウェア 更新 具合 提供 開始 起動 NTT phone ドコモ バージョン SII 向け Android SH SC KDDI モード OS AQUOS isw\n",
            "搭載 予定 インチ スマートフォン Android 対応 ドコモ 向け ICS NTT 開始 phone サイフ ワンセグ 機種 Mobile CPU 発表 事前 赤外\n",
            "代表 五輪 選手 日本 試合 サッカー チーム SPORTS watch なでしこ 監督 ファン 報道 W杯 明かす いく 優勝 語る ダメ ジャパン\n",
            "話題 出る する くる ちゃん なる 人気 ネット いる 出す すぎる さん ある つく 見る いう やる 出演 受ける 込む\n",
            "スマートフォン レポート 対応 スマホ スペック 全部 ハイ 入り 搭載 optimus サイフ galaxy 画面 モバイル ドコモ 向け 試す モデル SH 防水\n",
            "選手 語る プロ さん 監督 言う 明かす いく チーム 代表 ファン watch SPORTS いう ある 野球 試合 日本 報道 言及\n",
            "映画 オトナ まとめ 読み 週末 恋人 編集 ストーリー 描く 女子 主演 批評 作品 見る 女優 すぎる ドラマ DVD かける 少女\n",
            "公開 解禁 映像 予告 世界 最強 描く 決定 込む スター 誕生 上陸 主演 挑戦 映画 ナイト プレミア 衝撃 すぎる 新作\n",
            "アプリ android オススメ for 機能 iPhone 使う 使える 情報 画面 スマホ iOS 専用 アップ 無料 リリース まとめる 向け 操作 端末\n",
            "売れ筋 チェック 製品 パナソニック 発売 家電 登場 付き 実現 シリーズ シャープ 販売 電気 メーカー 商品 アップ 価格 機能 紹介 最新\n",
            "女子 たち 独女 しまう 事情 恋愛 女性 いる こと 思う なる する 男性 Vol アリ 合う 自分 ある 見る 本音\n",
            "携帯 スマホ 話題 使う 利用 電話 ニュース デジ 端末 iPhone 使える 市場 ケータイ アップル 発表 通信 機能 わかる 変更 みる\n",
            "カメラ 撮影 写真 ビデオ 撮る salon デジタル 動画 ムービー デジカメ 連動 紹介 みる チェック 登場 ソニー 付き モデル レポート 最新\n",
            "会社 仕事 Vol 部屋 聞く 説教 辛口 ビジネス やる 研究 教える 年収 採用 つく 社会 考える 続ける 自分 転職 いる\n",
            "アプリ iPhone android チャンス 掴める ゲーム 使う for 無料 使える できる アナタ みる ipad オススメ 情報 楽しめる 操作 必須 感覚\n"
          ]
        }
      ],
      "source": [
        "topic_words = []\n",
        "similarities = cosine_similarity(vocab_embeddings, centers)\n",
        "for i in range(similarities.shape[-1]):\n",
        "    indices = np.argsort(- similarities[:,i])\n",
        "    topic_words.append(\" \".join(list(vocab[indices[:20]])))\n",
        "print(\"\\n\".join(topic_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDRLCcziHH-m"
      },
      "outputs": [],
      "source": [
        "class MyNetForClassification(nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super().__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.config = self.pretrained.config\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids, category=None,\n",
        "        attention_mask=None,\n",
        "        output_attentions=None, output_hidden_states=None,\n",
        "        return_dict=None, inputs_embeds=None, labels=None,\n",
        "    ):\n",
        "        outputs = self.pretrained(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(outputs.logits, category)\n",
        "        return ModelOutput(\n",
        "            loss=loss,\n",
        "            logits=outputs.logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "model = MyNetForClassification(pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaVR0ddFHH-m"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    output_dir=\"outputs\",\n",
        "    label_names=[\"category\"],\n",
        "    max_steps=500,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100,\n",
        "    save_steps=100,\n",
        "    learning_rate=5e-5,\n",
        "    optim_target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcgGT2O5HH-m",
        "outputId": "09be874d-a887-4ab7-ef72-673728fd5843"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=max_seq_length,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    dataset_text_field=\"title\",\n",
        ")\n",
        "trainer.train_dataset = trainer.train_dataset.add_column(\n",
        "    \"category\", dataset[\"train\"][\"category\"],\n",
        ")\n",
        "trainer.eval_dataset = trainer.eval_dataset.add_column(\n",
        "    \"category\", dataset[\"validation\"][\"category\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4y0_ZG2HH-m",
        "outputId": "7c28846e-cf2e-4144-f8be-67d424ff9482"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 27/500 00:06 < 01:55, 4.10 it/s, Epoch 0.14/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1860\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1861\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1862\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1863\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1864\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3138\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3138\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3141\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mMyNetForClassification.forward\u001b[0;34m(self, input_ids, category, attention_mask, output_attentions, output_hidden_states, return_dict, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_ids, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     11\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inputs_embeds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m ):\n\u001b[0;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained(\n\u001b[1;32m     14\u001b[0m         input_ids,\n\u001b[1;32m     15\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m     16\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m     17\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m     18\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fct(outputs\u001b[38;5;241m.\u001b[39mlogits, category)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1201\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1201\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[1;32m   1202\u001b[0m     input_ids,\n\u001b[1;32m   1203\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1204\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1205\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1206\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1207\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1208\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1209\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1210\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1211\u001b[0m )\n\u001b[1;32m   1212\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1213\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:830\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    821\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    823\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    824\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    825\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    829\u001b[0m )\n\u001b[0;32m--> 830\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    831\u001b[0m     embedding_output,\n\u001b[1;32m    832\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    833\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    834\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    835\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    836\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    837\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    838\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    839\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    840\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    841\u001b[0m )\n\u001b[1;32m    842\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    843\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:518\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    507\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    508\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    509\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m         output_attentions,\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    519\u001b[0m         hidden_states,\n\u001b[1;32m    520\u001b[0m         attention_mask,\n\u001b[1;32m    521\u001b[0m         layer_head_mask,\n\u001b[1;32m    522\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    523\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    524\u001b[0m         past_key_value,\n\u001b[1;32m    525\u001b[0m         output_attentions,\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    528\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:407\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    397\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    408\u001b[0m         hidden_states,\n\u001b[1;32m    409\u001b[0m         attention_mask,\n\u001b[1;32m    410\u001b[0m         head_mask,\n\u001b[1;32m    411\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    412\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    414\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:343\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    326\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    334\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    335\u001b[0m         hidden_states,\n\u001b[1;32m    336\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m         output_attentions,\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 343\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    344\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:292\u001b[0m, in \u001b[0;36mXLMRobertaSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 292\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    293\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    294\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRYG5RvOHH-m"
      },
      "outputs": [],
      "source": [
        "batch_dict = tokenizer(dataset[\"validation\"][\"title\"][:10], max_length=512, padding=True, truncation=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH3zF4nNHH-m"
      },
      "outputs": [],
      "source": [
        "outputs = pretrained(**batch_dict.to(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NjWibKmHH-m",
        "outputId": "8349f2fa-4ffe-495a-c64e-7fbdb33d4a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 0, 4, 2, 1, 0, 7, 2, 6, 1], device='cuda:0')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.logits.argmax(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlTzAV-OHH-m",
        "outputId": "794c735f-fb58-4628-ca43-9e5f4f594cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 0, 4, 2, 1, 0, 7, 2, 6, 2]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"validation\"][\"category\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJUMiXqCHH-n",
        "outputId": "25eab035-ea6d-4dcf-af21-bb6662c3a1f0",
        "colab": {
          "referenced_widgets": [
            "325c7634b2bb4409ac5bc5ac93500cad"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "325c7634b2bb4409ac5bc5ac93500cad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/185 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.9158751964569092"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy(pretrained, tokenizer, dataset[\"validation\"][\"title\"], dataset[\"validation\"][\"category\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr4sR05mHH-n",
        "outputId": "13c18126-aa4e-4163-db27-08595f38a781",
        "colab": {
          "referenced_widgets": [
            "5098e6dac94d4f6888bcc80fdacf4d0a",
            "368d08b7abcf4a9e8884c6124fb61874",
            "46a916beaf9444cda0980e31624e9a51"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5098e6dac94d4f6888bcc80fdacf4d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1474 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "368d08b7abcf4a9e8884c6124fb61874",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/185 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a916beaf9444cda0980e31624e9a51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/184 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embeddings = {}\n",
        "for key in dataset:\n",
        "    embeddings[key] = embed(pretrained, tokenizer, dataset[key][\"title\"])\n",
        "    embeddings[key] = normalize(embeddings[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KznzWA2mHH-n",
        "outputId": "21ae2492-4985-4049-8747-c32a28f084f2",
        "colab": {
          "referenced_widgets": [
            "1caf6b337b514446972b3fb3bc0628d3",
            "cdd9ff72d60d4dac93a99e1f790505d2",
            "bcf3788ebdff4ba3a31f5bf72fe18aa0"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1caf6b337b514446972b3fb3bc0628d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5894 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdd9ff72d60d4dac93a99e1f790505d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/737 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf3788ebdff4ba3a31f5bf72fe18aa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/736 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "label_pos_tags = [\"NOUN\", \"VERB\", \"PROPN\"]\n",
        "\n",
        "nlp = spacy.load(\"ja_core_news_sm\")\n",
        "corpus = {}\n",
        "for key in dataset:\n",
        "    corpus[key] = []\n",
        "    for text in tqdm(dataset[key][\"title\"]):\n",
        "        corpus[key].append(\" \".join(\n",
        "            [token.lemma_\n",
        "             for token in nlp(text) if token.pos_ in label_pos_tags\n",
        "            ]\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUkZUtNFHH-n"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=10, max_df=0.1, lowercase=False)\n",
        "vectorizer.fit(corpus[\"train\"])\n",
        "vocab = np.array(vectorizer.get_feature_names_out())\n",
        "X = {}\n",
        "for key in dataset:\n",
        "    X[key] = vectorizer.transform(corpus[key]).toarray()\n",
        "vocab_embeddings = np.dot((X[\"train\"] / X[\"train\"].sum(0)).T, embeddings[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDJKorBLHH-n"
      },
      "outputs": [],
      "source": [
        "n_clusters = 30\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=123)\n",
        "kmeans.fit(embeddings[\"train\"])\n",
        "centers = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1uFO59uHH-n",
        "outputId": "461ca7f9-436c-44ce-b852-eb0ef2999d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[57, 59, 79, 91, 95, 98, 100, 102, 111, 115, 125, 126, 146, 150, 151, 168, 169, 175, 218, 220, 225, 239, 259, 264, 285, 301, 333, 388, 491, 554]\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
        "size_dict = dict(zip(unique, counts))\n",
        "print(sorted([item[1] for item in size_dict.items()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "311g_af-HH-o",
        "outputId": "e5e882e8-60bf-480b-aed5-71e5a0a8b6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PC ultrabook ファイル ソフト 虎の巻 Mac 得る フラッシュバック マザー ワザ ニコニコ Excel 募集 レビューアー Word Ubuntu ノート ロゴ 会議 デジ\n",
            "上陸 プレミア DVD ナイト ダーク 解禁 主演 ポスター 映像 ストーリー スター ハリウッド アカデミー 主題 描く 受賞 予告 ベルセルク 映画 来日\n",
            "続出 非難 物議 次ぐ 騒然 中島 殺到 賛否 両論 発言 橋下 批判 掲示 母親 反応 怒り 波紋 暴露 疑問 騒動\n",
            "イー インチ スペック lte らくらく スマートフォン 向け wimax galaxy Android Wi Fi siii ドコモ SX 開始 GX AQUOS プラチナ phone\n",
            "伝統 大人 学ぶ アイテム 過ごす 気分 デート プロジェクト ファッション 入れる 愛す 選ぶ 食べる 効く ムービー ライフ なれる パワー 楽しむ 秘訣\n",
            "watch SPORTS 星野 斎藤 ダルビッシュ 巨人 ノム 開幕 本田 長友 試合 W杯 圭佑 岡田 移籍 落合 代表 なでしこ 選手 チーム\n",
            "売れ筋 アップル 家電 話題 パナソニック チェック インターネット 売れる 発生 今度 電気 ソニー hulu 原因 節電 電池 デジカメ salon プレーヤー 未来\n",
            "独女 オトナ コミック 悩み ゆるい presented cafe オンナ by よめ あらわれる くさる ひとり はじめる たち しまう 風呂 アリ 結婚 女子\n",
            "ビデオ hulu salon パナソニック 連載 家電 連動 節電 デジカメ 電気 ソニー インターネット 未来 売れ筋 USB プレーヤー 売れる メーカー アップル チェック\n",
            "ビジネスマン 年収 説教 辛口 部屋 図鑑 ウラ 株式 人事 スーツ プレイヤー 活動 転職 ゴルフ ビジネス オトコ 研究 刺激 解決 コラム\n",
            "ポスター アベンジャーズ 予告 ハリウッド ベルセルク 来日 ダーク 人類 解禁 映像 ナイト 公開 劇場 エンター 主題 スター 読み 対決 週末 批評\n",
            "プレゼント 終了 バレンタイン スイーツ メイク peachy ケーキ 登録 コスメ 気分 美肌 ビューティ 週間 ビューティー ランキング セット お気に入り UP トレンド ガール\n",
            "ガール 招待 ケーキ バレンタイン インタビュー コレクション 気分 ガールズ ビューティ ホテル プレゼント 試写 終了 効く ランキング 週間 贈る メイク ライフスタイル スイーツ\n",
            "NTT ICS SC 画面 xi 提供 arrows isw 赤外 SO デュアルコア Mobile ソフトウェア SH phone 具合 更新 IS optimus HT\n",
            "俳優 エリカ 主演 主題 来日 受賞 ポスター 超える ハリウッド ヒロイン 優子 バトル 奇跡 女優 家族 上陸 解禁 プレミア ベルセルク 大島\n",
            "気分 バレンタイン スイーツ peachy ガールズ 伝統 コスメ トレンド ビューティ コレクション プレゼント ライフスタイル ビューティー デート 週間 メイク 効く 登録 ガール ケーキ\n",
            "コスメ スイーツ peachy 気分 美肌 メイク トレンド バレンタイン UP ビューティー プレゼント 登録 お気に入り クリスマス 大人 食べる 週間 美容 ビューティ 伝統\n",
            "女子 婚活 恋愛 事情 運命 行動 アリ モテる 女性 変える 働く 美容 男性 大人 たち オンナ 本音 ダイエット 彼氏 学ぶ\n",
            "掲示 次ぐ 物議 非難 殺到 賛否 続出 両論 橋下 韓流 ネット 韓国 騒然 反応 ユーザー 母親 NHK 批判 逮捕 疑問\n",
            "得る にゅう 紺子 知る ワザ くす 虎の巻 会議 社長 チャンス ニコニコ レア ロゴ レビューアー ソフト 募集 フラッシュバック イケショップ Excel ファイル\n",
            "オンナ 独女 たち しまう ひとり アリ 悩み 結婚 オトナ 事情 男性 女子 ゆるい cafe コミック presented モテる by くさる よめ\n",
            "真司 松井 香川 報道 サッカー 真央 言及 アナ 投手 野球 田中 引退 移籍 落合 なでしこ 選手 交際 代表 謝罪 怒る\n",
            "ゴルフ スーツ ビジネスマン コラム 刺激 部屋 年収 説教 辛口 図鑑 株式 特集 活動 ビジネス オトコ 転職 プレイヤー 研究 人事 生活\n",
            "ビジネス オトコ 転職 続ける 刺激 必見 仕事 ビジネスマン トーク コラム 図鑑 解決 活動 リラックス 年収 部屋 スペシャル ゴルフ 社会 Vol\n",
            "週間 ランキング ライフスタイル ビューティ ビューティー 登録 ガールズ お気に入り コレクション コスメ スイーツ バレンタイン peachy 気分 プレゼント トレンド メイク 美肌 終了 ケーキ\n",
            "物議 掲示 次ぐ 殺到 続出 非難 賛否 橋下 両論 騒然 ネット 反応 韓流 母親 批判 NHK 中島 発言 疑問 自殺\n",
            "エンター ハリウッド 週末 読み 解禁 ダーク ポスター 予告 ナイト ベルセルク 劇場 映像 アベンジャーズ 主題 批評 主演 公開 まとめ 来日 人類\n",
            "インタビュー No 俳優 奇跡 セクシー 試写 招待 イメージ デビュー かける プレミア よう 負ける 女優 高級 誕生 豪華 絶対 描く 観る\n",
            "なでしこ 代表 試合 選手 長友 チーム 圭佑 本田 柔道 ノム ダルビッシュ 落合 斎藤 W杯 開幕 移籍 投手 巨人 引退 ロンドン\n",
            "イケショップ レア 掴める チャンス デジ 募集 管理 ソフト モバステ レビューアー 容量 ニコニコ ダウンロード 虎の巻 ultrabook ファイル ノート クラウド 得る ドライブ\n"
          ]
        }
      ],
      "source": [
        "topic_words = []\n",
        "similarities = cosine_similarity(vocab_embeddings, centers)\n",
        "for i in range(similarities.shape[-1]):\n",
        "    indices = np.argsort(- similarities[:,i])\n",
        "    topic_words.append(\" \".join(list(vocab[indices[:20]])))\n",
        "print(\"\\n\".join(topic_words))\n",
        "#with open(\"topic_words.txt\", \"w\") as f:\n",
        "#    f.write(\"\\n\".join(topic_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P50j4-oHH-o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}