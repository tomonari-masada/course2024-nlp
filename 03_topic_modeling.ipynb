{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-nlp/blob/main/03_topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmIZbjYUNv9m"
      },
      "source": [
        "# トピックモデル\n",
        "* bag-of-wordsの範囲内でテキストデータの高度な分析を行う。\n",
        "* 潜在的ディリクレ配分法(LDA; latent Dirichlet allocation)を使う。\n",
        "* scikit-learnにある実装を使う。\n",
        "  * gensimのLdaModelは非推奨。（理由は、passesのデフォルトの値が1だから。）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMHFkESgNv9o"
      },
      "source": [
        "**以下に示すようなチューニングをしてはじめて、LDAがその能力を発揮してくれます。**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh01qzsPNv9o"
      },
      "source": [
        "## データセット\n",
        "* Hugging Faceにある`CShorten/ML-ArXiv-Papers`を使う。\n",
        "  * https://huggingface.co/datasets/CShorten/ML-ArXiv-Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evODt8mPNv9p"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"CShorten/ML-ArXiv-Papers\")\n",
        "ds = ds[\"train\"].train_test_split(test_size=0.1, seed=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCHjvSJfNv9q",
        "outputId": "fcde5136-33ac-4c85-d4c1-e864e9ed81dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
              "        num_rows: 105832\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
              "        num_rows: 11760\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-af7gyGBNv9q",
        "outputId": "6f081a63-eed7-4029-e4c6-69757c4d968b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Wind ramp event prediction with parallelized Gradient Boosted Regression\\n  Trees',\n",
              " 'Common Phone: A Multilingual Dataset for Robust Acoustic Modelling',\n",
              " 'Adiabatic Persistent Contrastive Divergence Learning',\n",
              " 'Decentralized Local Stochastic Extra-Gradient for Variational\\n  Inequalities',\n",
              " 'Fuzzy Dynamical Genetic Programming in XCSF',\n",
              " 'Probabilistic Neural Network Training for Semi-Supervised Classifiers',\n",
              " 'The Traveling Observer Model: Multi-task Learning Through Spatial\\n  Variable Embeddings',\n",
              " 'Online Continual Learning with Natural Distribution Shifts: An Empirical\\n  Study with Visual Data',\n",
              " 'Inferring clonal evolution of tumors from single nucleotide somatic\\n  mutations',\n",
              " 'Using a Binary Classification Model to Predict the Likelihood of\\n  Enrolment to the Undergraduate Program of a Philippine University',\n",
              " 'Rapid Structural Pruning of Neural Networks with Set-based Task-Adaptive\\n  Meta-Pruning',\n",
              " 'AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging',\n",
              " 'LiRA: Learning Visual Speech Representations from Audio through\\n  Self-supervision',\n",
              " 'Hierarchical Models as Marginals of Hierarchical Models',\n",
              " 'Gray Learning from Non-IID Data with Out-of-distribution Samples',\n",
              " 'LEMON: Explainable Entity Matching',\n",
              " 'HURRA! Human readable router anomaly detection',\n",
              " 'Learning Curves for Deep Neural Networks: A Gaussian Field Theory\\n  Perspective',\n",
              " 'Statistical and machine learning ensemble modelling to forecast sea\\n  surface temperature',\n",
              " 'Non-Cooperative Inverse Reinforcement Learning']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"train\"][\"title\"][:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXXmP9yGNv9q"
      },
      "source": [
        "## 単語の出現回数を数える"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSPu7c7zNv9q"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)\n",
        "X_train = vectorizer.fit_transform(ds[\"train\"][\"title\"])\n",
        "X_test = vectorizer.transform(ds[\"test\"][\"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdIbeVv3Nv9r",
        "outputId": "1f39665c-10b7-4431-d6c5-bb19c2acea31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105832, 5308)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1L7q1fLNv9r",
        "outputId": "cca1016d-c162-4c73-a744-bde2bf390517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11760, 5308)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMmKRrVTNv9r"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJrUQQWyNv9r"
      },
      "source": [
        "* とりあえずLDAの変分推論を動かしてみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpTfGYefNv9r",
        "outputId": "a64fbdd6-98f0-445b-8259-4d95fd159461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 10, perplexity: 2198.5085\n",
            "iteration: 2 of max_iter: 10, perplexity: 1848.8412\n",
            "iteration: 3 of max_iter: 10, perplexity: 1647.0992\n",
            "iteration: 4 of max_iter: 10, perplexity: 1517.0774\n",
            "iteration: 5 of max_iter: 10, perplexity: 1437.1730\n",
            "iteration: 6 of max_iter: 10, perplexity: 1389.1073\n",
            "iteration: 7 of max_iter: 10, perplexity: 1359.7666\n",
            "iteration: 8 of max_iter: 10, perplexity: 1339.7824\n",
            "iteration: 9 of max_iter: 10, perplexity: 1325.9726\n",
            "iteration: 10 of max_iter: 10, perplexity: 1316.1240\n",
            "2985.28\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(\n",
        "  n_components=20,\n",
        "  evaluate_every=1,\n",
        "  verbose=1,\n",
        "  random_state=123,\n",
        ")\n",
        "lda.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf7N87EBNv9r",
        "outputId": "191e688d-6440-4b80-d8fd-3ec7bf568b8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1316.124040359834"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda.perplexity(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK_Fv9_pNv9r"
      },
      "source": [
        "## ハイパーパラメータのチューニング\n",
        "* perplexityの値が最小になるようにチューニングする。\n",
        "  * トピック数(`n_components`)は、自分の都合で決めても良いかも。\n",
        "* トピック数に合わせて、`doc_topic_prior`と`topic_word_prior`の両方をチューニングする。\n",
        "  * トピック数が変わると、最も良い`doc_topic_prior`と`topic_word_prior`の値も、変わる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Tg509-Nv9s"
      },
      "source": [
        "### 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8Pr2OvYNv9s",
        "outputId": "fa96f695-cb79-4b69-ee3e-daf5c84f0dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 20, perplexity: 3015.0258\n",
            "iteration: 2 of max_iter: 20, perplexity: 2365.6630\n",
            "iteration: 3 of max_iter: 20, perplexity: 1963.0553\n",
            "iteration: 4 of max_iter: 20, perplexity: 1710.8841\n",
            "iteration: 5 of max_iter: 20, perplexity: 1554.1238\n",
            "iteration: 6 of max_iter: 20, perplexity: 1453.7942\n",
            "iteration: 7 of max_iter: 20, perplexity: 1386.5439\n",
            "iteration: 8 of max_iter: 20, perplexity: 1340.1355\n",
            "iteration: 9 of max_iter: 20, perplexity: 1307.6926\n",
            "iteration: 10 of max_iter: 20, perplexity: 1284.4908\n",
            "iteration: 11 of max_iter: 20, perplexity: 1267.2861\n",
            "iteration: 12 of max_iter: 20, perplexity: 1254.3886\n",
            "iteration: 13 of max_iter: 20, perplexity: 1244.6055\n",
            "iteration: 14 of max_iter: 20, perplexity: 1237.3350\n",
            "iteration: 15 of max_iter: 20, perplexity: 1231.7562\n",
            "iteration: 16 of max_iter: 20, perplexity: 1227.3495\n",
            "iteration: 17 of max_iter: 20, perplexity: 1223.8334\n",
            "iteration: 18 of max_iter: 20, perplexity: 1220.9968\n",
            "iteration: 19 of max_iter: 20, perplexity: 1218.7509\n",
            "iteration: 20 of max_iter: 20, perplexity: 1216.8762\n",
            "-- test perplexity: 2126.61\n",
            "---- 20 topics, alpha=0.2000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 3252.2871\n",
            "iteration: 2 of max_iter: 20, perplexity: 2503.1371\n",
            "iteration: 3 of max_iter: 20, perplexity: 2040.6991\n",
            "iteration: 4 of max_iter: 20, perplexity: 1754.0498\n",
            "iteration: 5 of max_iter: 20, perplexity: 1577.2957\n",
            "iteration: 6 of max_iter: 20, perplexity: 1465.1008\n",
            "iteration: 7 of max_iter: 20, perplexity: 1390.2432\n",
            "iteration: 8 of max_iter: 20, perplexity: 1338.7863\n",
            "iteration: 9 of max_iter: 20, perplexity: 1303.2583\n",
            "iteration: 10 of max_iter: 20, perplexity: 1278.0304\n",
            "iteration: 11 of max_iter: 20, perplexity: 1259.0415\n",
            "iteration: 12 of max_iter: 20, perplexity: 1244.8541\n",
            "iteration: 13 of max_iter: 20, perplexity: 1234.0983\n",
            "iteration: 14 of max_iter: 20, perplexity: 1226.0742\n",
            "iteration: 15 of max_iter: 20, perplexity: 1220.0237\n",
            "iteration: 16 of max_iter: 20, perplexity: 1215.3395\n",
            "iteration: 17 of max_iter: 20, perplexity: 1211.5709\n",
            "iteration: 18 of max_iter: 20, perplexity: 1208.4407\n",
            "iteration: 19 of max_iter: 20, perplexity: 1205.9571\n",
            "iteration: 20 of max_iter: 20, perplexity: 1203.9594\n",
            "-- test perplexity: 1978.34\n",
            "---- 20 topics, alpha=0.2000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3484.2004\n",
            "iteration: 2 of max_iter: 20, perplexity: 2637.6154\n",
            "iteration: 3 of max_iter: 20, perplexity: 2122.3725\n",
            "iteration: 4 of max_iter: 20, perplexity: 1804.2320\n",
            "iteration: 5 of max_iter: 20, perplexity: 1609.4444\n",
            "iteration: 6 of max_iter: 20, perplexity: 1486.4239\n",
            "iteration: 7 of max_iter: 20, perplexity: 1404.8656\n",
            "iteration: 8 of max_iter: 20, perplexity: 1349.0224\n",
            "iteration: 9 of max_iter: 20, perplexity: 1310.6253\n",
            "iteration: 10 of max_iter: 20, perplexity: 1283.1929\n",
            "iteration: 11 of max_iter: 20, perplexity: 1262.5509\n",
            "iteration: 12 of max_iter: 20, perplexity: 1247.2934\n",
            "iteration: 13 of max_iter: 20, perplexity: 1235.6182\n",
            "iteration: 14 of max_iter: 20, perplexity: 1227.0993\n",
            "iteration: 15 of max_iter: 20, perplexity: 1220.6269\n",
            "iteration: 16 of max_iter: 20, perplexity: 1215.5417\n",
            "iteration: 17 of max_iter: 20, perplexity: 1211.4938\n",
            "iteration: 18 of max_iter: 20, perplexity: 1208.2010\n",
            "iteration: 19 of max_iter: 20, perplexity: 1205.3976\n",
            "iteration: 20 of max_iter: 20, perplexity: 1203.1591\n",
            "-- test perplexity: 1984.02\n",
            "---- 20 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2538.3816\n",
            "iteration: 2 of max_iter: 20, perplexity: 2062.8521\n",
            "iteration: 3 of max_iter: 20, perplexity: 1779.6184\n",
            "iteration: 4 of max_iter: 20, perplexity: 1596.7442\n",
            "iteration: 5 of max_iter: 20, perplexity: 1483.0702\n",
            "iteration: 6 of max_iter: 20, perplexity: 1411.8755\n",
            "iteration: 7 of max_iter: 20, perplexity: 1364.8877\n",
            "iteration: 8 of max_iter: 20, perplexity: 1331.6952\n",
            "iteration: 9 of max_iter: 20, perplexity: 1308.2712\n",
            "iteration: 10 of max_iter: 20, perplexity: 1291.7038\n",
            "iteration: 11 of max_iter: 20, perplexity: 1279.9403\n",
            "iteration: 12 of max_iter: 20, perplexity: 1271.0471\n",
            "iteration: 13 of max_iter: 20, perplexity: 1263.7418\n",
            "iteration: 14 of max_iter: 20, perplexity: 1258.2689\n",
            "iteration: 15 of max_iter: 20, perplexity: 1254.4398\n",
            "iteration: 16 of max_iter: 20, perplexity: 1251.5642\n",
            "iteration: 17 of max_iter: 20, perplexity: 1249.3868\n",
            "iteration: 18 of max_iter: 20, perplexity: 1247.6283\n",
            "iteration: 19 of max_iter: 20, perplexity: 1246.0649\n",
            "iteration: 20 of max_iter: 20, perplexity: 1244.5645\n",
            "-- test perplexity: 2359.61\n",
            "---- 20 topics, alpha=0.1000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 2731.0328\n",
            "iteration: 2 of max_iter: 20, perplexity: 2181.5547\n",
            "iteration: 3 of max_iter: 20, perplexity: 1853.8441\n",
            "iteration: 4 of max_iter: 20, perplexity: 1642.4514\n",
            "iteration: 5 of max_iter: 20, perplexity: 1511.2224\n",
            "iteration: 6 of max_iter: 20, perplexity: 1429.0065\n",
            "iteration: 7 of max_iter: 20, perplexity: 1374.8056\n",
            "iteration: 8 of max_iter: 20, perplexity: 1336.6289\n",
            "iteration: 9 of max_iter: 20, perplexity: 1309.7087\n",
            "iteration: 10 of max_iter: 20, perplexity: 1290.6364\n",
            "iteration: 11 of max_iter: 20, perplexity: 1276.8888\n",
            "iteration: 12 of max_iter: 20, perplexity: 1266.5159\n",
            "iteration: 13 of max_iter: 20, perplexity: 1258.4141\n",
            "iteration: 14 of max_iter: 20, perplexity: 1252.1745\n",
            "iteration: 15 of max_iter: 20, perplexity: 1247.5223\n",
            "iteration: 16 of max_iter: 20, perplexity: 1244.0855\n",
            "iteration: 17 of max_iter: 20, perplexity: 1241.3018\n",
            "iteration: 18 of max_iter: 20, perplexity: 1239.1937\n",
            "iteration: 19 of max_iter: 20, perplexity: 1237.5211\n",
            "iteration: 20 of max_iter: 20, perplexity: 1235.9170\n",
            "-- test perplexity: 2254.67\n",
            "---- 20 topics, alpha=0.1000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2906.3492\n",
            "iteration: 2 of max_iter: 20, perplexity: 2295.1750\n",
            "iteration: 3 of max_iter: 20, perplexity: 1929.5066\n",
            "iteration: 4 of max_iter: 20, perplexity: 1693.1641\n",
            "iteration: 5 of max_iter: 20, perplexity: 1546.2758\n",
            "iteration: 6 of max_iter: 20, perplexity: 1453.9742\n",
            "iteration: 7 of max_iter: 20, perplexity: 1393.5363\n",
            "iteration: 8 of max_iter: 20, perplexity: 1351.0022\n",
            "iteration: 9 of max_iter: 20, perplexity: 1321.0088\n",
            "iteration: 10 of max_iter: 20, perplexity: 1299.4802\n",
            "iteration: 11 of max_iter: 20, perplexity: 1283.6400\n",
            "iteration: 12 of max_iter: 20, perplexity: 1271.9830\n",
            "iteration: 13 of max_iter: 20, perplexity: 1262.9391\n",
            "iteration: 14 of max_iter: 20, perplexity: 1256.0722\n",
            "iteration: 15 of max_iter: 20, perplexity: 1251.0092\n",
            "iteration: 16 of max_iter: 20, perplexity: 1247.0727\n",
            "iteration: 17 of max_iter: 20, perplexity: 1243.7562\n",
            "iteration: 18 of max_iter: 20, perplexity: 1241.2389\n",
            "iteration: 19 of max_iter: 20, perplexity: 1239.1778\n",
            "iteration: 20 of max_iter: 20, perplexity: 1237.2835\n",
            "-- test perplexity: 2301.96\n",
            "---- 20 topics, alpha=0.1000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2198.5085\n",
            "iteration: 2 of max_iter: 20, perplexity: 1848.8412\n",
            "iteration: 3 of max_iter: 20, perplexity: 1647.0992\n",
            "iteration: 4 of max_iter: 20, perplexity: 1517.0774\n",
            "iteration: 5 of max_iter: 20, perplexity: 1437.1730\n",
            "iteration: 6 of max_iter: 20, perplexity: 1389.1073\n",
            "iteration: 7 of max_iter: 20, perplexity: 1359.7666\n",
            "iteration: 8 of max_iter: 20, perplexity: 1339.7824\n",
            "iteration: 9 of max_iter: 20, perplexity: 1325.9726\n",
            "iteration: 10 of max_iter: 20, perplexity: 1316.1240\n",
            "iteration: 11 of max_iter: 20, perplexity: 1309.6320\n",
            "iteration: 12 of max_iter: 20, perplexity: 1304.9019\n",
            "iteration: 13 of max_iter: 20, perplexity: 1301.2550\n",
            "iteration: 14 of max_iter: 20, perplexity: 1299.2953\n",
            "iteration: 15 of max_iter: 20, perplexity: 1297.7856\n",
            "iteration: 16 of max_iter: 20, perplexity: 1296.7709\n",
            "iteration: 17 of max_iter: 20, perplexity: 1296.0357\n",
            "iteration: 18 of max_iter: 20, perplexity: 1295.5206\n",
            "iteration: 19 of max_iter: 20, perplexity: 1295.1354\n",
            "iteration: 20 of max_iter: 20, perplexity: 1295.3187\n",
            "-- test perplexity: 2575.43\n",
            "---- 20 topics, alpha=0.0500, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 2368.4771\n",
            "iteration: 2 of max_iter: 20, perplexity: 1955.6743\n",
            "iteration: 3 of max_iter: 20, perplexity: 1717.8721\n",
            "iteration: 4 of max_iter: 20, perplexity: 1564.3862\n",
            "iteration: 5 of max_iter: 20, perplexity: 1468.3251\n",
            "iteration: 6 of max_iter: 20, perplexity: 1409.4661\n",
            "iteration: 7 of max_iter: 20, perplexity: 1373.2561\n",
            "iteration: 8 of max_iter: 20, perplexity: 1348.0783\n",
            "iteration: 9 of max_iter: 20, perplexity: 1329.5699\n",
            "iteration: 10 of max_iter: 20, perplexity: 1316.6905\n",
            "iteration: 11 of max_iter: 20, perplexity: 1307.6480\n",
            "iteration: 12 of max_iter: 20, perplexity: 1300.9087\n",
            "iteration: 13 of max_iter: 20, perplexity: 1296.0017\n",
            "iteration: 14 of max_iter: 20, perplexity: 1292.7610\n",
            "iteration: 15 of max_iter: 20, perplexity: 1290.6116\n",
            "iteration: 16 of max_iter: 20, perplexity: 1289.3309\n",
            "iteration: 17 of max_iter: 20, perplexity: 1288.0856\n",
            "iteration: 18 of max_iter: 20, perplexity: 1287.0612\n",
            "iteration: 19 of max_iter: 20, perplexity: 1286.0992\n",
            "iteration: 20 of max_iter: 20, perplexity: 1285.6222\n",
            "-- test perplexity: 2493.40\n",
            "---- 20 topics, alpha=0.0500, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2522.6958\n",
            "iteration: 2 of max_iter: 20, perplexity: 2056.9846\n",
            "iteration: 3 of max_iter: 20, perplexity: 1789.3532\n",
            "iteration: 4 of max_iter: 20, perplexity: 1614.3187\n",
            "iteration: 5 of max_iter: 20, perplexity: 1504.1008\n",
            "iteration: 6 of max_iter: 20, perplexity: 1436.6359\n",
            "iteration: 7 of max_iter: 20, perplexity: 1394.2003\n",
            "iteration: 8 of max_iter: 20, perplexity: 1364.9892\n",
            "iteration: 9 of max_iter: 20, perplexity: 1343.5823\n",
            "iteration: 10 of max_iter: 20, perplexity: 1328.7791\n",
            "iteration: 11 of max_iter: 20, perplexity: 1317.9733\n",
            "iteration: 12 of max_iter: 20, perplexity: 1310.1019\n",
            "iteration: 13 of max_iter: 20, perplexity: 1304.4153\n",
            "iteration: 14 of max_iter: 20, perplexity: 1300.2575\n",
            "iteration: 15 of max_iter: 20, perplexity: 1297.1848\n",
            "iteration: 16 of max_iter: 20, perplexity: 1295.2877\n",
            "iteration: 17 of max_iter: 20, perplexity: 1293.5997\n",
            "iteration: 18 of max_iter: 20, perplexity: 1292.5452\n",
            "iteration: 19 of max_iter: 20, perplexity: 1291.4005\n",
            "iteration: 20 of max_iter: 20, perplexity: 1290.6696\n",
            "-- test perplexity: 2582.13\n",
            "---- 20 topics, alpha=0.0500, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3912.9164\n",
            "iteration: 2 of max_iter: 20, perplexity: 2819.0244\n",
            "iteration: 3 of max_iter: 20, perplexity: 2184.9744\n",
            "iteration: 4 of max_iter: 20, perplexity: 1818.7529\n",
            "iteration: 5 of max_iter: 20, perplexity: 1607.1487\n",
            "iteration: 6 of max_iter: 20, perplexity: 1478.4233\n",
            "iteration: 7 of max_iter: 20, perplexity: 1397.5363\n",
            "iteration: 8 of max_iter: 20, perplexity: 1346.6828\n",
            "iteration: 9 of max_iter: 20, perplexity: 1313.2773\n",
            "iteration: 10 of max_iter: 20, perplexity: 1291.1907\n",
            "iteration: 11 of max_iter: 20, perplexity: 1276.0172\n",
            "iteration: 12 of max_iter: 20, perplexity: 1264.1930\n",
            "iteration: 13 of max_iter: 20, perplexity: 1255.3398\n",
            "iteration: 14 of max_iter: 20, perplexity: 1249.3368\n",
            "iteration: 15 of max_iter: 20, perplexity: 1245.0479\n",
            "iteration: 16 of max_iter: 20, perplexity: 1241.8688\n",
            "iteration: 17 of max_iter: 20, perplexity: 1239.5511\n",
            "iteration: 18 of max_iter: 20, perplexity: 1237.8376\n",
            "iteration: 19 of max_iter: 20, perplexity: 1236.5622\n",
            "iteration: 20 of max_iter: 20, perplexity: 1235.5407\n",
            "-- test perplexity: 2324.42\n",
            "---- 30 topics, alpha=0.2000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 4323.2350\n",
            "iteration: 2 of max_iter: 20, perplexity: 3014.8283\n",
            "iteration: 3 of max_iter: 20, perplexity: 2277.5078\n",
            "iteration: 4 of max_iter: 20, perplexity: 1857.8985\n",
            "iteration: 5 of max_iter: 20, perplexity: 1618.9213\n",
            "iteration: 6 of max_iter: 20, perplexity: 1475.3759\n",
            "iteration: 7 of max_iter: 20, perplexity: 1385.9669\n",
            "iteration: 8 of max_iter: 20, perplexity: 1329.9989\n",
            "iteration: 9 of max_iter: 20, perplexity: 1293.4198\n",
            "iteration: 10 of max_iter: 20, perplexity: 1269.1899\n",
            "iteration: 11 of max_iter: 20, perplexity: 1252.5542\n",
            "iteration: 12 of max_iter: 20, perplexity: 1239.9309\n",
            "iteration: 13 of max_iter: 20, perplexity: 1230.1866\n",
            "iteration: 14 of max_iter: 20, perplexity: 1223.6500\n",
            "iteration: 15 of max_iter: 20, perplexity: 1219.1686\n",
            "iteration: 16 of max_iter: 20, perplexity: 1215.8067\n",
            "iteration: 17 of max_iter: 20, perplexity: 1213.2695\n",
            "iteration: 18 of max_iter: 20, perplexity: 1211.4372\n",
            "iteration: 19 of max_iter: 20, perplexity: 1210.0214\n",
            "iteration: 20 of max_iter: 20, perplexity: 1208.8058\n",
            "-- test perplexity: 2004.23\n",
            "---- 30 topics, alpha=0.2000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 4752.9366\n",
            "iteration: 2 of max_iter: 20, perplexity: 3216.5343\n",
            "iteration: 3 of max_iter: 20, perplexity: 2384.1470\n",
            "iteration: 4 of max_iter: 20, perplexity: 1913.7865\n",
            "iteration: 5 of max_iter: 20, perplexity: 1648.6328\n",
            "iteration: 6 of max_iter: 20, perplexity: 1490.7126\n",
            "iteration: 7 of max_iter: 20, perplexity: 1393.4750\n",
            "iteration: 8 of max_iter: 20, perplexity: 1332.9736\n",
            "iteration: 9 of max_iter: 20, perplexity: 1293.6137\n",
            "iteration: 10 of max_iter: 20, perplexity: 1267.8066\n",
            "iteration: 11 of max_iter: 20, perplexity: 1249.8159\n",
            "iteration: 12 of max_iter: 20, perplexity: 1236.3655\n",
            "iteration: 13 of max_iter: 20, perplexity: 1226.1701\n",
            "iteration: 14 of max_iter: 20, perplexity: 1218.9078\n",
            "iteration: 15 of max_iter: 20, perplexity: 1214.0400\n",
            "iteration: 16 of max_iter: 20, perplexity: 1210.2323\n",
            "iteration: 17 of max_iter: 20, perplexity: 1207.4859\n",
            "iteration: 18 of max_iter: 20, perplexity: 1205.4914\n",
            "iteration: 19 of max_iter: 20, perplexity: 1203.9408\n",
            "iteration: 20 of max_iter: 20, perplexity: 1202.6226\n",
            "-- test perplexity: 1942.17\n",
            "---- 30 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3200.9845\n",
            "iteration: 2 of max_iter: 20, perplexity: 2419.1633\n",
            "iteration: 3 of max_iter: 20, perplexity: 1978.8868\n",
            "iteration: 4 of max_iter: 20, perplexity: 1719.3346\n",
            "iteration: 5 of max_iter: 20, perplexity: 1566.7000\n",
            "iteration: 6 of max_iter: 20, perplexity: 1472.7022\n",
            "iteration: 7 of max_iter: 20, perplexity: 1411.8258\n",
            "iteration: 8 of max_iter: 20, perplexity: 1370.8064\n",
            "iteration: 9 of max_iter: 20, perplexity: 1342.6925\n",
            "iteration: 10 of max_iter: 20, perplexity: 1323.4889\n",
            "iteration: 11 of max_iter: 20, perplexity: 1309.9912\n",
            "iteration: 12 of max_iter: 20, perplexity: 1300.6048\n",
            "iteration: 13 of max_iter: 20, perplexity: 1294.2668\n",
            "iteration: 14 of max_iter: 20, perplexity: 1289.4630\n",
            "iteration: 15 of max_iter: 20, perplexity: 1285.8801\n",
            "iteration: 16 of max_iter: 20, perplexity: 1282.3580\n",
            "iteration: 17 of max_iter: 20, perplexity: 1279.0731\n",
            "iteration: 18 of max_iter: 20, perplexity: 1276.7474\n",
            "iteration: 19 of max_iter: 20, perplexity: 1274.8940\n",
            "iteration: 20 of max_iter: 20, perplexity: 1273.2491\n",
            "-- test perplexity: 2547.78\n",
            "---- 30 topics, alpha=0.1000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 3511.5232\n",
            "iteration: 2 of max_iter: 20, perplexity: 2585.0235\n",
            "iteration: 3 of max_iter: 20, perplexity: 2068.4338\n",
            "iteration: 4 of max_iter: 20, perplexity: 1764.7204\n",
            "iteration: 5 of max_iter: 20, perplexity: 1587.4053\n",
            "iteration: 6 of max_iter: 20, perplexity: 1478.4678\n",
            "iteration: 7 of max_iter: 20, perplexity: 1408.2524\n",
            "iteration: 8 of max_iter: 20, perplexity: 1361.3775\n",
            "iteration: 9 of max_iter: 20, perplexity: 1329.6938\n",
            "iteration: 10 of max_iter: 20, perplexity: 1308.2079\n",
            "iteration: 11 of max_iter: 20, perplexity: 1292.8984\n",
            "iteration: 12 of max_iter: 20, perplexity: 1282.3228\n",
            "iteration: 13 of max_iter: 20, perplexity: 1274.8698\n",
            "iteration: 14 of max_iter: 20, perplexity: 1269.1238\n",
            "iteration: 15 of max_iter: 20, perplexity: 1264.5625\n",
            "iteration: 16 of max_iter: 20, perplexity: 1260.8716\n",
            "iteration: 17 of max_iter: 20, perplexity: 1257.5076\n",
            "iteration: 18 of max_iter: 20, perplexity: 1254.7236\n",
            "iteration: 19 of max_iter: 20, perplexity: 1252.3625\n",
            "iteration: 20 of max_iter: 20, perplexity: 1250.6138\n",
            "-- test perplexity: 2244.74\n",
            "---- 30 topics, alpha=0.1000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3803.8826\n",
            "iteration: 2 of max_iter: 20, perplexity: 2750.9631\n",
            "iteration: 3 of max_iter: 20, perplexity: 2167.0311\n",
            "iteration: 4 of max_iter: 20, perplexity: 1822.4899\n",
            "iteration: 5 of max_iter: 20, perplexity: 1622.2709\n",
            "iteration: 6 of max_iter: 20, perplexity: 1499.7413\n",
            "iteration: 7 of max_iter: 20, perplexity: 1421.4206\n",
            "iteration: 8 of max_iter: 20, perplexity: 1369.4160\n",
            "iteration: 9 of max_iter: 20, perplexity: 1334.2569\n",
            "iteration: 10 of max_iter: 20, perplexity: 1310.4294\n",
            "iteration: 11 of max_iter: 20, perplexity: 1294.0242\n",
            "iteration: 12 of max_iter: 20, perplexity: 1282.5282\n",
            "iteration: 13 of max_iter: 20, perplexity: 1274.1064\n",
            "iteration: 14 of max_iter: 20, perplexity: 1267.5532\n",
            "iteration: 15 of max_iter: 20, perplexity: 1262.1673\n",
            "iteration: 16 of max_iter: 20, perplexity: 1257.7746\n",
            "iteration: 17 of max_iter: 20, perplexity: 1254.0808\n",
            "iteration: 18 of max_iter: 20, perplexity: 1251.0352\n",
            "iteration: 19 of max_iter: 20, perplexity: 1248.6520\n",
            "iteration: 20 of max_iter: 20, perplexity: 1246.6304\n",
            "-- test perplexity: 2207.14\n",
            "---- 30 topics, alpha=0.1000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2667.3102\n",
            "iteration: 2 of max_iter: 20, perplexity: 2103.5317\n",
            "iteration: 3 of max_iter: 20, perplexity: 1795.9065\n",
            "iteration: 4 of max_iter: 20, perplexity: 1615.3904\n",
            "iteration: 5 of max_iter: 20, perplexity: 1513.4683\n",
            "iteration: 6 of max_iter: 20, perplexity: 1453.4630\n",
            "iteration: 7 of max_iter: 20, perplexity: 1415.5349\n",
            "iteration: 8 of max_iter: 20, perplexity: 1392.1832\n",
            "iteration: 9 of max_iter: 20, perplexity: 1377.3487\n",
            "iteration: 10 of max_iter: 20, perplexity: 1367.4684\n",
            "iteration: 11 of max_iter: 20, perplexity: 1361.2152\n",
            "iteration: 12 of max_iter: 20, perplexity: 1357.7686\n",
            "iteration: 13 of max_iter: 20, perplexity: 1355.3474\n",
            "iteration: 14 of max_iter: 20, perplexity: 1353.6431\n",
            "iteration: 15 of max_iter: 20, perplexity: 1351.7866\n",
            "iteration: 16 of max_iter: 20, perplexity: 1350.2713\n",
            "iteration: 17 of max_iter: 20, perplexity: 1349.2590\n",
            "iteration: 18 of max_iter: 20, perplexity: 1348.9100\n",
            "iteration: 19 of max_iter: 20, perplexity: 1348.9482\n",
            "-- test perplexity: 2866.22\n",
            "---- 30 topics, alpha=0.0500, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 2932.7442\n",
            "iteration: 2 of max_iter: 20, perplexity: 2248.9226\n",
            "iteration: 3 of max_iter: 20, perplexity: 1881.0211\n",
            "iteration: 4 of max_iter: 20, perplexity: 1663.7394\n",
            "iteration: 5 of max_iter: 20, perplexity: 1538.0845\n",
            "iteration: 6 of max_iter: 20, perplexity: 1463.8801\n",
            "iteration: 7 of max_iter: 20, perplexity: 1417.5981\n",
            "iteration: 8 of max_iter: 20, perplexity: 1388.4327\n",
            "iteration: 9 of max_iter: 20, perplexity: 1368.7019\n",
            "iteration: 10 of max_iter: 20, perplexity: 1355.1438\n",
            "iteration: 11 of max_iter: 20, perplexity: 1347.2518\n",
            "iteration: 12 of max_iter: 20, perplexity: 1342.3878\n",
            "iteration: 13 of max_iter: 20, perplexity: 1339.0073\n",
            "iteration: 14 of max_iter: 20, perplexity: 1336.5994\n",
            "iteration: 15 of max_iter: 20, perplexity: 1334.2735\n",
            "iteration: 16 of max_iter: 20, perplexity: 1332.3110\n",
            "iteration: 17 of max_iter: 20, perplexity: 1330.9103\n",
            "iteration: 18 of max_iter: 20, perplexity: 1329.6430\n",
            "iteration: 19 of max_iter: 20, perplexity: 1328.8034\n",
            "iteration: 20 of max_iter: 20, perplexity: 1328.1512\n",
            "-- test perplexity: 2548.40\n",
            "---- 30 topics, alpha=0.0500, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3181.7858\n",
            "iteration: 2 of max_iter: 20, perplexity: 2392.6221\n",
            "iteration: 3 of max_iter: 20, perplexity: 1972.7245\n",
            "iteration: 4 of max_iter: 20, perplexity: 1721.4048\n",
            "iteration: 5 of max_iter: 20, perplexity: 1575.4603\n",
            "iteration: 6 of max_iter: 20, perplexity: 1489.1259\n",
            "iteration: 7 of max_iter: 20, perplexity: 1434.4979\n",
            "iteration: 8 of max_iter: 20, perplexity: 1399.6497\n",
            "iteration: 9 of max_iter: 20, perplexity: 1376.2482\n",
            "iteration: 10 of max_iter: 20, perplexity: 1360.7292\n",
            "iteration: 11 of max_iter: 20, perplexity: 1350.5776\n",
            "iteration: 12 of max_iter: 20, perplexity: 1344.2248\n",
            "iteration: 13 of max_iter: 20, perplexity: 1339.8171\n",
            "iteration: 14 of max_iter: 20, perplexity: 1336.6283\n",
            "iteration: 15 of max_iter: 20, perplexity: 1334.1311\n",
            "iteration: 16 of max_iter: 20, perplexity: 1332.0204\n",
            "iteration: 17 of max_iter: 20, perplexity: 1330.1743\n",
            "iteration: 18 of max_iter: 20, perplexity: 1328.9774\n",
            "iteration: 19 of max_iter: 20, perplexity: 1327.8123\n",
            "iteration: 20 of max_iter: 20, perplexity: 1326.9556\n",
            "-- test perplexity: 2548.69\n",
            "---- 30 topics, alpha=0.0500, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 4826.0024\n",
            "iteration: 2 of max_iter: 20, perplexity: 3251.6391\n",
            "iteration: 3 of max_iter: 20, perplexity: 2372.3946\n",
            "iteration: 4 of max_iter: 20, perplexity: 1894.1355\n",
            "iteration: 5 of max_iter: 20, perplexity: 1633.6302\n",
            "iteration: 6 of max_iter: 20, perplexity: 1488.0736\n",
            "iteration: 7 of max_iter: 20, perplexity: 1402.7673\n",
            "iteration: 8 of max_iter: 20, perplexity: 1350.6434\n",
            "iteration: 9 of max_iter: 20, perplexity: 1317.3383\n",
            "iteration: 10 of max_iter: 20, perplexity: 1296.2486\n",
            "iteration: 11 of max_iter: 20, perplexity: 1282.7404\n",
            "iteration: 12 of max_iter: 20, perplexity: 1274.1527\n",
            "iteration: 13 of max_iter: 20, perplexity: 1268.6452\n",
            "iteration: 14 of max_iter: 20, perplexity: 1264.7382\n",
            "iteration: 15 of max_iter: 20, perplexity: 1261.7407\n",
            "iteration: 16 of max_iter: 20, perplexity: 1259.2771\n",
            "iteration: 17 of max_iter: 20, perplexity: 1257.4799\n",
            "iteration: 18 of max_iter: 20, perplexity: 1255.9931\n",
            "iteration: 19 of max_iter: 20, perplexity: 1254.8869\n",
            "iteration: 20 of max_iter: 20, perplexity: 1254.0549\n",
            "-- test perplexity: 2532.11\n",
            "---- 40 topics, alpha=0.2000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 5448.2747\n",
            "iteration: 2 of max_iter: 20, perplexity: 3504.4208\n",
            "iteration: 3 of max_iter: 20, perplexity: 2472.9940\n",
            "iteration: 4 of max_iter: 20, perplexity: 1923.6057\n",
            "iteration: 5 of max_iter: 20, perplexity: 1630.7434\n",
            "iteration: 6 of max_iter: 20, perplexity: 1469.2020\n",
            "iteration: 7 of max_iter: 20, perplexity: 1375.4671\n",
            "iteration: 8 of max_iter: 20, perplexity: 1318.5533\n",
            "iteration: 9 of max_iter: 20, perplexity: 1282.7659\n",
            "iteration: 10 of max_iter: 20, perplexity: 1260.6863\n",
            "iteration: 11 of max_iter: 20, perplexity: 1246.5058\n",
            "iteration: 12 of max_iter: 20, perplexity: 1237.5908\n",
            "iteration: 13 of max_iter: 20, perplexity: 1231.8729\n",
            "iteration: 14 of max_iter: 20, perplexity: 1228.1322\n",
            "iteration: 15 of max_iter: 20, perplexity: 1225.1101\n",
            "iteration: 16 of max_iter: 20, perplexity: 1222.9096\n",
            "iteration: 17 of max_iter: 20, perplexity: 1221.2715\n",
            "iteration: 18 of max_iter: 20, perplexity: 1220.0872\n",
            "iteration: 19 of max_iter: 20, perplexity: 1219.2485\n",
            "iteration: 20 of max_iter: 20, perplexity: 1218.5880\n",
            "-- test perplexity: 2063.38\n",
            "---- 40 topics, alpha=0.2000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 6138.3878\n",
            "iteration: 2 of max_iter: 20, perplexity: 3775.9710\n",
            "iteration: 3 of max_iter: 20, perplexity: 2598.9228\n",
            "iteration: 4 of max_iter: 20, perplexity: 1980.0717\n",
            "iteration: 5 of max_iter: 20, perplexity: 1654.4832\n",
            "iteration: 6 of max_iter: 20, perplexity: 1477.2112\n",
            "iteration: 7 of max_iter: 20, perplexity: 1375.5040\n",
            "iteration: 8 of max_iter: 20, perplexity: 1314.5315\n",
            "iteration: 9 of max_iter: 20, perplexity: 1276.1766\n",
            "iteration: 10 of max_iter: 20, perplexity: 1252.5585\n",
            "iteration: 11 of max_iter: 20, perplexity: 1237.7568\n",
            "iteration: 12 of max_iter: 20, perplexity: 1228.5318\n",
            "iteration: 13 of max_iter: 20, perplexity: 1222.6315\n",
            "iteration: 14 of max_iter: 20, perplexity: 1218.6583\n",
            "iteration: 15 of max_iter: 20, perplexity: 1215.6281\n",
            "iteration: 16 of max_iter: 20, perplexity: 1213.1294\n",
            "iteration: 17 of max_iter: 20, perplexity: 1211.2879\n",
            "iteration: 18 of max_iter: 20, perplexity: 1209.8712\n",
            "iteration: 19 of max_iter: 20, perplexity: 1208.9169\n",
            "iteration: 20 of max_iter: 20, perplexity: 1208.1727\n",
            "-- test perplexity: 1944.63\n",
            "---- 40 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3881.9458\n",
            "iteration: 2 of max_iter: 20, perplexity: 2784.6928\n",
            "iteration: 3 of max_iter: 20, perplexity: 2181.2276\n",
            "iteration: 4 of max_iter: 20, perplexity: 1830.3767\n",
            "iteration: 5 of max_iter: 20, perplexity: 1629.4897\n",
            "iteration: 6 of max_iter: 20, perplexity: 1509.4983\n",
            "iteration: 7 of max_iter: 20, perplexity: 1437.6377\n",
            "iteration: 8 of max_iter: 20, perplexity: 1394.0805\n",
            "iteration: 9 of max_iter: 20, perplexity: 1367.1448\n",
            "iteration: 10 of max_iter: 20, perplexity: 1348.0771\n",
            "iteration: 11 of max_iter: 20, perplexity: 1335.3692\n",
            "iteration: 12 of max_iter: 20, perplexity: 1326.3646\n",
            "iteration: 13 of max_iter: 20, perplexity: 1320.2467\n",
            "iteration: 14 of max_iter: 20, perplexity: 1315.7758\n",
            "iteration: 15 of max_iter: 20, perplexity: 1312.3508\n",
            "iteration: 16 of max_iter: 20, perplexity: 1309.8420\n",
            "iteration: 17 of max_iter: 20, perplexity: 1307.8256\n",
            "iteration: 18 of max_iter: 20, perplexity: 1306.0592\n",
            "iteration: 19 of max_iter: 20, perplexity: 1304.7637\n",
            "iteration: 20 of max_iter: 20, perplexity: 1303.5037\n",
            "-- test perplexity: 2788.86\n",
            "---- 40 topics, alpha=0.1000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 4326.1387\n",
            "iteration: 2 of max_iter: 20, perplexity: 2998.2213\n",
            "iteration: 3 of max_iter: 20, perplexity: 2284.0788\n",
            "iteration: 4 of max_iter: 20, perplexity: 1872.6477\n",
            "iteration: 5 of max_iter: 20, perplexity: 1639.6963\n",
            "iteration: 6 of max_iter: 20, perplexity: 1502.3046\n",
            "iteration: 7 of max_iter: 20, perplexity: 1420.3183\n",
            "iteration: 8 of max_iter: 20, perplexity: 1371.0472\n",
            "iteration: 9 of max_iter: 20, perplexity: 1339.7798\n",
            "iteration: 10 of max_iter: 20, perplexity: 1318.8528\n",
            "iteration: 11 of max_iter: 20, perplexity: 1304.2862\n",
            "iteration: 12 of max_iter: 20, perplexity: 1294.2830\n",
            "iteration: 13 of max_iter: 20, perplexity: 1287.1787\n",
            "iteration: 14 of max_iter: 20, perplexity: 1282.0172\n",
            "iteration: 15 of max_iter: 20, perplexity: 1278.2124\n",
            "iteration: 16 of max_iter: 20, perplexity: 1275.2828\n",
            "iteration: 17 of max_iter: 20, perplexity: 1273.3188\n",
            "iteration: 18 of max_iter: 20, perplexity: 1271.4804\n",
            "iteration: 19 of max_iter: 20, perplexity: 1270.2364\n",
            "iteration: 20 of max_iter: 20, perplexity: 1269.1392\n",
            "-- test perplexity: 2304.90\n",
            "---- 40 topics, alpha=0.1000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 4755.1411\n",
            "iteration: 2 of max_iter: 20, perplexity: 3219.7602\n",
            "iteration: 3 of max_iter: 20, perplexity: 2404.4792\n",
            "iteration: 4 of max_iter: 20, perplexity: 1935.4776\n",
            "iteration: 5 of max_iter: 20, perplexity: 1672.2568\n",
            "iteration: 6 of max_iter: 20, perplexity: 1518.3577\n",
            "iteration: 7 of max_iter: 20, perplexity: 1426.5787\n",
            "iteration: 8 of max_iter: 20, perplexity: 1371.5888\n",
            "iteration: 9 of max_iter: 20, perplexity: 1336.9662\n",
            "iteration: 10 of max_iter: 20, perplexity: 1314.0035\n",
            "iteration: 11 of max_iter: 20, perplexity: 1298.2410\n",
            "iteration: 12 of max_iter: 20, perplexity: 1287.4074\n",
            "iteration: 13 of max_iter: 20, perplexity: 1279.9196\n",
            "iteration: 14 of max_iter: 20, perplexity: 1274.1206\n",
            "iteration: 15 of max_iter: 20, perplexity: 1269.9133\n",
            "iteration: 16 of max_iter: 20, perplexity: 1266.7426\n",
            "iteration: 17 of max_iter: 20, perplexity: 1264.4551\n",
            "iteration: 18 of max_iter: 20, perplexity: 1262.7334\n",
            "iteration: 19 of max_iter: 20, perplexity: 1261.3327\n",
            "iteration: 20 of max_iter: 20, perplexity: 1260.1752\n",
            "-- test perplexity: 2199.22\n",
            "---- 40 topics, alpha=0.1000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3141.4202\n",
            "iteration: 2 of max_iter: 20, perplexity: 2370.6438\n",
            "iteration: 3 of max_iter: 20, perplexity: 1966.2629\n",
            "iteration: 4 of max_iter: 20, perplexity: 1729.6317\n",
            "iteration: 5 of max_iter: 20, perplexity: 1593.6666\n",
            "iteration: 6 of max_iter: 20, perplexity: 1515.3078\n",
            "iteration: 7 of max_iter: 20, perplexity: 1467.6773\n",
            "iteration: 8 of max_iter: 20, perplexity: 1439.5117\n",
            "iteration: 9 of max_iter: 20, perplexity: 1423.4683\n",
            "iteration: 10 of max_iter: 20, perplexity: 1414.2354\n",
            "iteration: 11 of max_iter: 20, perplexity: 1409.4233\n",
            "iteration: 12 of max_iter: 20, perplexity: 1405.7658\n",
            "iteration: 13 of max_iter: 20, perplexity: 1402.4592\n",
            "iteration: 14 of max_iter: 20, perplexity: 1399.1912\n",
            "iteration: 15 of max_iter: 20, perplexity: 1396.8794\n",
            "iteration: 16 of max_iter: 20, perplexity: 1395.2571\n",
            "iteration: 17 of max_iter: 20, perplexity: 1394.2995\n",
            "iteration: 18 of max_iter: 20, perplexity: 1393.9511\n",
            "iteration: 19 of max_iter: 20, perplexity: 1393.7423\n",
            "iteration: 20 of max_iter: 20, perplexity: 1393.5643\n",
            "-- test perplexity: 3096.62\n",
            "---- 40 topics, alpha=0.0500, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 3510.9141\n",
            "iteration: 2 of max_iter: 20, perplexity: 2553.8356\n",
            "iteration: 3 of max_iter: 20, perplexity: 2063.7437\n",
            "iteration: 4 of max_iter: 20, perplexity: 1776.0843\n",
            "iteration: 5 of max_iter: 20, perplexity: 1610.9500\n",
            "iteration: 6 of max_iter: 20, perplexity: 1514.4564\n",
            "iteration: 7 of max_iter: 20, perplexity: 1456.0124\n",
            "iteration: 8 of max_iter: 20, perplexity: 1421.3133\n",
            "iteration: 9 of max_iter: 20, perplexity: 1400.9890\n",
            "iteration: 10 of max_iter: 20, perplexity: 1388.9815\n",
            "iteration: 11 of max_iter: 20, perplexity: 1381.0830\n",
            "iteration: 12 of max_iter: 20, perplexity: 1375.7297\n",
            "iteration: 13 of max_iter: 20, perplexity: 1370.8904\n",
            "iteration: 14 of max_iter: 20, perplexity: 1367.4687\n",
            "iteration: 15 of max_iter: 20, perplexity: 1364.7375\n",
            "iteration: 16 of max_iter: 20, perplexity: 1362.6600\n",
            "iteration: 17 of max_iter: 20, perplexity: 1361.4614\n",
            "iteration: 18 of max_iter: 20, perplexity: 1360.3704\n",
            "iteration: 19 of max_iter: 20, perplexity: 1359.4304\n",
            "iteration: 20 of max_iter: 20, perplexity: 1358.6879\n",
            "-- test perplexity: 2592.56\n",
            "---- 40 topics, alpha=0.0500, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3866.1944\n",
            "iteration: 2 of max_iter: 20, perplexity: 2740.9455\n",
            "iteration: 3 of max_iter: 20, perplexity: 2175.6662\n",
            "iteration: 4 of max_iter: 20, perplexity: 1840.6817\n",
            "iteration: 5 of max_iter: 20, perplexity: 1647.8182\n",
            "iteration: 6 of max_iter: 20, perplexity: 1534.9965\n",
            "iteration: 7 of max_iter: 20, perplexity: 1466.6872\n",
            "iteration: 8 of max_iter: 20, perplexity: 1425.8452\n",
            "iteration: 9 of max_iter: 20, perplexity: 1401.7004\n",
            "iteration: 10 of max_iter: 20, perplexity: 1387.0669\n",
            "iteration: 11 of max_iter: 20, perplexity: 1377.3884\n",
            "iteration: 12 of max_iter: 20, perplexity: 1370.8380\n",
            "iteration: 13 of max_iter: 20, perplexity: 1365.8742\n",
            "iteration: 14 of max_iter: 20, perplexity: 1361.5843\n",
            "iteration: 15 of max_iter: 20, perplexity: 1358.2381\n",
            "iteration: 16 of max_iter: 20, perplexity: 1355.6886\n",
            "iteration: 17 of max_iter: 20, perplexity: 1354.0222\n",
            "iteration: 18 of max_iter: 20, perplexity: 1353.0059\n",
            "iteration: 19 of max_iter: 20, perplexity: 1352.1286\n",
            "iteration: 20 of max_iter: 20, perplexity: 1351.2246\n",
            "-- test perplexity: 2500.38\n",
            "---- 40 topics, alpha=0.0500, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 5717.6372\n",
            "iteration: 2 of max_iter: 20, perplexity: 3613.3467\n",
            "iteration: 3 of max_iter: 20, perplexity: 2502.9476\n",
            "iteration: 4 of max_iter: 20, perplexity: 1932.5152\n",
            "iteration: 5 of max_iter: 20, perplexity: 1636.6241\n",
            "iteration: 6 of max_iter: 20, perplexity: 1480.3719\n",
            "iteration: 7 of max_iter: 20, perplexity: 1392.7464\n",
            "iteration: 8 of max_iter: 20, perplexity: 1339.2730\n",
            "iteration: 9 of max_iter: 20, perplexity: 1309.4307\n",
            "iteration: 10 of max_iter: 20, perplexity: 1293.1747\n",
            "iteration: 11 of max_iter: 20, perplexity: 1283.7780\n",
            "iteration: 12 of max_iter: 20, perplexity: 1277.7610\n",
            "iteration: 13 of max_iter: 20, perplexity: 1273.9213\n",
            "iteration: 14 of max_iter: 20, perplexity: 1271.2199\n",
            "iteration: 15 of max_iter: 20, perplexity: 1269.1876\n",
            "iteration: 16 of max_iter: 20, perplexity: 1267.7670\n",
            "iteration: 17 of max_iter: 20, perplexity: 1266.9839\n",
            "iteration: 18 of max_iter: 20, perplexity: 1266.5529\n",
            "iteration: 19 of max_iter: 20, perplexity: 1266.2283\n",
            "iteration: 20 of max_iter: 20, perplexity: 1265.9551\n",
            "-- test perplexity: 2786.15\n",
            "---- 50 topics, alpha=0.2000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 6586.3597\n",
            "iteration: 2 of max_iter: 20, perplexity: 3915.1075\n",
            "iteration: 3 of max_iter: 20, perplexity: 2604.9817\n",
            "iteration: 4 of max_iter: 20, perplexity: 1950.1940\n",
            "iteration: 5 of max_iter: 20, perplexity: 1620.1751\n",
            "iteration: 6 of max_iter: 20, perplexity: 1449.1844\n",
            "iteration: 7 of max_iter: 20, perplexity: 1354.6393\n",
            "iteration: 8 of max_iter: 20, perplexity: 1296.8616\n",
            "iteration: 9 of max_iter: 20, perplexity: 1264.6239\n",
            "iteration: 10 of max_iter: 20, perplexity: 1246.8151\n",
            "iteration: 11 of max_iter: 20, perplexity: 1236.7217\n",
            "iteration: 12 of max_iter: 20, perplexity: 1230.7512\n",
            "iteration: 13 of max_iter: 20, perplexity: 1227.1015\n",
            "iteration: 14 of max_iter: 20, perplexity: 1223.8973\n",
            "iteration: 15 of max_iter: 20, perplexity: 1221.5420\n",
            "iteration: 16 of max_iter: 20, perplexity: 1220.2153\n",
            "iteration: 17 of max_iter: 20, perplexity: 1219.5059\n",
            "iteration: 18 of max_iter: 20, perplexity: 1219.0391\n",
            "iteration: 19 of max_iter: 20, perplexity: 1218.6801\n",
            "iteration: 20 of max_iter: 20, perplexity: 1218.3827\n",
            "-- test perplexity: 2141.66\n",
            "---- 50 topics, alpha=0.2000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 7598.6117\n",
            "iteration: 2 of max_iter: 20, perplexity: 4251.6884\n",
            "iteration: 3 of max_iter: 20, perplexity: 2743.5996\n",
            "iteration: 4 of max_iter: 20, perplexity: 2003.9611\n",
            "iteration: 5 of max_iter: 20, perplexity: 1638.0457\n",
            "iteration: 6 of max_iter: 20, perplexity: 1451.3132\n",
            "iteration: 7 of max_iter: 20, perplexity: 1349.3326\n",
            "iteration: 8 of max_iter: 20, perplexity: 1288.2521\n",
            "iteration: 9 of max_iter: 20, perplexity: 1253.7616\n",
            "iteration: 10 of max_iter: 20, perplexity: 1234.9213\n",
            "iteration: 11 of max_iter: 20, perplexity: 1224.0899\n",
            "iteration: 12 of max_iter: 20, perplexity: 1217.6731\n",
            "iteration: 13 of max_iter: 20, perplexity: 1213.5230\n",
            "iteration: 14 of max_iter: 20, perplexity: 1210.0872\n",
            "iteration: 15 of max_iter: 20, perplexity: 1207.7352\n",
            "iteration: 16 of max_iter: 20, perplexity: 1206.3082\n",
            "iteration: 17 of max_iter: 20, perplexity: 1205.4126\n",
            "iteration: 18 of max_iter: 20, perplexity: 1204.8018\n",
            "iteration: 19 of max_iter: 20, perplexity: 1204.2683\n",
            "iteration: 20 of max_iter: 20, perplexity: 1203.8219\n",
            "-- test perplexity: 1968.72\n",
            "---- 50 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 4578.9622\n",
            "iteration: 2 of max_iter: 20, perplexity: 3112.3893\n",
            "iteration: 3 of max_iter: 20, perplexity: 2335.6178\n",
            "iteration: 4 of max_iter: 20, perplexity: 1909.5498\n",
            "iteration: 5 of max_iter: 20, perplexity: 1672.9386\n",
            "iteration: 6 of max_iter: 20, perplexity: 1535.3492\n",
            "iteration: 7 of max_iter: 20, perplexity: 1454.4043\n",
            "iteration: 8 of max_iter: 20, perplexity: 1407.1791\n",
            "iteration: 9 of max_iter: 20, perplexity: 1378.3714\n",
            "iteration: 10 of max_iter: 20, perplexity: 1360.3990\n",
            "iteration: 11 of max_iter: 20, perplexity: 1347.9466\n",
            "iteration: 12 of max_iter: 20, perplexity: 1338.1841\n",
            "iteration: 13 of max_iter: 20, perplexity: 1331.9068\n",
            "iteration: 14 of max_iter: 20, perplexity: 1327.2615\n",
            "iteration: 15 of max_iter: 20, perplexity: 1324.6752\n",
            "iteration: 16 of max_iter: 20, perplexity: 1322.6763\n",
            "iteration: 17 of max_iter: 20, perplexity: 1321.3286\n",
            "iteration: 18 of max_iter: 20, perplexity: 1320.1118\n",
            "iteration: 19 of max_iter: 20, perplexity: 1319.2967\n",
            "iteration: 20 of max_iter: 20, perplexity: 1318.7035\n",
            "-- test perplexity: 3017.43\n",
            "---- 50 topics, alpha=0.1000, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 5170.1681\n",
            "iteration: 2 of max_iter: 20, perplexity: 3367.7485\n",
            "iteration: 3 of max_iter: 20, perplexity: 2442.4045\n",
            "iteration: 4 of max_iter: 20, perplexity: 1941.4440\n",
            "iteration: 5 of max_iter: 20, perplexity: 1669.2377\n",
            "iteration: 6 of max_iter: 20, perplexity: 1514.6920\n",
            "iteration: 7 of max_iter: 20, perplexity: 1424.4627\n",
            "iteration: 8 of max_iter: 20, perplexity: 1370.9296\n",
            "iteration: 9 of max_iter: 20, perplexity: 1338.5456\n",
            "iteration: 10 of max_iter: 20, perplexity: 1319.3461\n",
            "iteration: 11 of max_iter: 20, perplexity: 1306.5213\n",
            "iteration: 12 of max_iter: 20, perplexity: 1296.8282\n",
            "iteration: 13 of max_iter: 20, perplexity: 1289.4021\n",
            "iteration: 14 of max_iter: 20, perplexity: 1284.3693\n",
            "iteration: 15 of max_iter: 20, perplexity: 1280.9893\n",
            "iteration: 16 of max_iter: 20, perplexity: 1278.6527\n",
            "iteration: 17 of max_iter: 20, perplexity: 1277.0945\n",
            "iteration: 18 of max_iter: 20, perplexity: 1275.7401\n",
            "iteration: 19 of max_iter: 20, perplexity: 1274.9167\n",
            "iteration: 20 of max_iter: 20, perplexity: 1274.2292\n",
            "-- test perplexity: 2358.97\n",
            "---- 50 topics, alpha=0.1000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 5755.5893\n",
            "iteration: 2 of max_iter: 20, perplexity: 3642.0431\n",
            "iteration: 3 of max_iter: 20, perplexity: 2577.3611\n",
            "iteration: 4 of max_iter: 20, perplexity: 2004.9572\n",
            "iteration: 5 of max_iter: 20, perplexity: 1697.6092\n",
            "iteration: 6 of max_iter: 20, perplexity: 1524.7186\n",
            "iteration: 7 of max_iter: 20, perplexity: 1424.6345\n",
            "iteration: 8 of max_iter: 20, perplexity: 1365.7084\n",
            "iteration: 9 of max_iter: 20, perplexity: 1329.9855\n",
            "iteration: 10 of max_iter: 20, perplexity: 1308.6780\n",
            "iteration: 11 of max_iter: 20, perplexity: 1294.3160\n",
            "iteration: 12 of max_iter: 20, perplexity: 1283.6223\n",
            "iteration: 13 of max_iter: 20, perplexity: 1275.9815\n",
            "iteration: 14 of max_iter: 20, perplexity: 1270.7271\n",
            "iteration: 15 of max_iter: 20, perplexity: 1267.1120\n",
            "iteration: 16 of max_iter: 20, perplexity: 1264.4159\n",
            "iteration: 17 of max_iter: 20, perplexity: 1262.2101\n",
            "iteration: 18 of max_iter: 20, perplexity: 1260.6887\n",
            "iteration: 19 of max_iter: 20, perplexity: 1259.6540\n",
            "iteration: 20 of max_iter: 20, perplexity: 1258.7806\n",
            "-- test perplexity: 2186.25\n",
            "---- 50 topics, alpha=0.1000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3623.9496\n",
            "iteration: 2 of max_iter: 20, perplexity: 2614.2783\n",
            "iteration: 3 of max_iter: 20, perplexity: 2090.6925\n",
            "iteration: 4 of max_iter: 20, perplexity: 1798.3869\n",
            "iteration: 5 of max_iter: 20, perplexity: 1637.9676\n",
            "iteration: 6 of max_iter: 20, perplexity: 1541.4410\n",
            "iteration: 7 of max_iter: 20, perplexity: 1485.7961\n",
            "iteration: 8 of max_iter: 20, perplexity: 1455.1119\n",
            "iteration: 9 of max_iter: 20, perplexity: 1438.4826\n",
            "iteration: 10 of max_iter: 20, perplexity: 1428.4677\n",
            "iteration: 11 of max_iter: 20, perplexity: 1422.0681\n",
            "iteration: 12 of max_iter: 20, perplexity: 1417.2531\n",
            "iteration: 13 of max_iter: 20, perplexity: 1413.9122\n",
            "iteration: 14 of max_iter: 20, perplexity: 1411.9949\n",
            "iteration: 15 of max_iter: 20, perplexity: 1410.2613\n",
            "iteration: 16 of max_iter: 20, perplexity: 1409.0740\n",
            "iteration: 17 of max_iter: 20, perplexity: 1407.7819\n",
            "iteration: 18 of max_iter: 20, perplexity: 1406.8855\n",
            "iteration: 19 of max_iter: 20, perplexity: 1406.3179\n",
            "iteration: 20 of max_iter: 20, perplexity: 1405.5839\n",
            "-- test perplexity: 3351.02\n",
            "---- 50 topics, alpha=0.0500, eta=0.0500\n",
            "iteration: 1 of max_iter: 20, perplexity: 4105.7878\n",
            "iteration: 2 of max_iter: 20, perplexity: 2831.9769\n",
            "iteration: 3 of max_iter: 20, perplexity: 2193.9200\n",
            "iteration: 4 of max_iter: 20, perplexity: 1837.3825\n",
            "iteration: 5 of max_iter: 20, perplexity: 1642.5312\n",
            "iteration: 6 of max_iter: 20, perplexity: 1525.7581\n",
            "iteration: 7 of max_iter: 20, perplexity: 1458.1121\n",
            "iteration: 8 of max_iter: 20, perplexity: 1420.4295\n",
            "iteration: 9 of max_iter: 20, perplexity: 1399.4197\n",
            "iteration: 10 of max_iter: 20, perplexity: 1385.6300\n",
            "iteration: 11 of max_iter: 20, perplexity: 1376.8500\n",
            "iteration: 12 of max_iter: 20, perplexity: 1371.3665\n",
            "iteration: 13 of max_iter: 20, perplexity: 1367.7842\n",
            "iteration: 14 of max_iter: 20, perplexity: 1365.5344\n",
            "iteration: 15 of max_iter: 20, perplexity: 1363.8592\n",
            "iteration: 16 of max_iter: 20, perplexity: 1362.6860\n",
            "iteration: 17 of max_iter: 20, perplexity: 1361.3963\n",
            "iteration: 18 of max_iter: 20, perplexity: 1359.9257\n",
            "iteration: 19 of max_iter: 20, perplexity: 1358.5397\n",
            "iteration: 20 of max_iter: 20, perplexity: 1357.4190\n",
            "-- test perplexity: 2642.43\n",
            "---- 50 topics, alpha=0.0500, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 4580.4839\n",
            "iteration: 2 of max_iter: 20, perplexity: 3061.9025\n",
            "iteration: 3 of max_iter: 20, perplexity: 2318.8952\n",
            "iteration: 4 of max_iter: 20, perplexity: 1902.5960\n",
            "iteration: 5 of max_iter: 20, perplexity: 1675.8077\n",
            "iteration: 6 of max_iter: 20, perplexity: 1540.6303\n",
            "iteration: 7 of max_iter: 20, perplexity: 1463.3453\n",
            "iteration: 8 of max_iter: 20, perplexity: 1420.1478\n",
            "iteration: 9 of max_iter: 20, perplexity: 1394.8375\n",
            "iteration: 10 of max_iter: 20, perplexity: 1378.9420\n",
            "iteration: 11 of max_iter: 20, perplexity: 1368.9652\n",
            "iteration: 12 of max_iter: 20, perplexity: 1362.1349\n",
            "iteration: 13 of max_iter: 20, perplexity: 1357.1588\n",
            "iteration: 14 of max_iter: 20, perplexity: 1353.6945\n",
            "iteration: 15 of max_iter: 20, perplexity: 1350.9054\n",
            "iteration: 16 of max_iter: 20, perplexity: 1348.5136\n",
            "iteration: 17 of max_iter: 20, perplexity: 1346.8828\n",
            "iteration: 18 of max_iter: 20, perplexity: 1345.5047\n",
            "iteration: 19 of max_iter: 20, perplexity: 1344.3447\n",
            "iteration: 20 of max_iter: 20, perplexity: 1343.2764\n",
            "-- test perplexity: 2470.87\n",
            "---- 50 topics, alpha=0.0500, eta=0.0100\n"
          ]
        }
      ],
      "source": [
        "for n_components in [20, 30, 40, 50]:\n",
        "  for doc_topic_prior in [0.2, 0.1, 0.05]:\n",
        "    for topic_word_prior in [0.05, 0.02, 0.01]:\n",
        "      lda = LatentDirichletAllocation(\n",
        "        n_components=n_components,\n",
        "        doc_topic_prior=doc_topic_prior,\n",
        "        topic_word_prior=topic_word_prior,\n",
        "        max_iter=20,\n",
        "        evaluate_every=1,\n",
        "        verbose=1,\n",
        "        random_state=123,\n",
        "      )\n",
        "      lda.fit(X_train)\n",
        "      print(f\"-- test perplexity: {lda.perplexity(X_test):.2f}\")\n",
        "      print(f\"---- {n_components} topics, alpha={doc_topic_prior:.4f}, eta={topic_word_prior:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lmrt5iXNv9s"
      },
      "source": [
        "### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNrCAd2RNv9s",
        "outputId": "720279fb-e2ed-4512-8757-ffe3e6ba550d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 20, perplexity: 4627.6715\n",
            "iteration: 2 of max_iter: 20, perplexity: 3237.7093\n",
            "iteration: 3 of max_iter: 20, perplexity: 2350.2718\n",
            "iteration: 4 of max_iter: 20, perplexity: 1878.1427\n",
            "iteration: 5 of max_iter: 20, perplexity: 1612.6079\n",
            "iteration: 6 of max_iter: 20, perplexity: 1456.4463\n",
            "iteration: 7 of max_iter: 20, perplexity: 1360.0351\n",
            "iteration: 8 of max_iter: 20, perplexity: 1298.7921\n",
            "iteration: 9 of max_iter: 20, perplexity: 1258.6076\n",
            "iteration: 10 of max_iter: 20, perplexity: 1231.6621\n",
            "iteration: 11 of max_iter: 20, perplexity: 1212.9790\n",
            "iteration: 12 of max_iter: 20, perplexity: 1199.7908\n",
            "iteration: 13 of max_iter: 20, perplexity: 1190.2813\n",
            "iteration: 14 of max_iter: 20, perplexity: 1183.0117\n",
            "iteration: 15 of max_iter: 20, perplexity: 1177.4912\n",
            "iteration: 16 of max_iter: 20, perplexity: 1173.4027\n",
            "iteration: 17 of max_iter: 20, perplexity: 1170.3885\n",
            "iteration: 18 of max_iter: 20, perplexity: 1168.0815\n",
            "iteration: 19 of max_iter: 20, perplexity: 1166.2770\n",
            "iteration: 20 of max_iter: 20, perplexity: 1164.8526\n",
            "-- test perplexity: 1698.24\n",
            "---- 20 topics, alpha=0.4000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 5082.7855\n",
            "iteration: 2 of max_iter: 20, perplexity: 3514.8449\n",
            "iteration: 3 of max_iter: 20, perplexity: 2483.1700\n",
            "iteration: 4 of max_iter: 20, perplexity: 1951.7215\n",
            "iteration: 5 of max_iter: 20, perplexity: 1655.8742\n",
            "iteration: 6 of max_iter: 20, perplexity: 1483.1785\n",
            "iteration: 7 of max_iter: 20, perplexity: 1377.1724\n",
            "iteration: 8 of max_iter: 20, perplexity: 1310.1108\n",
            "iteration: 9 of max_iter: 20, perplexity: 1266.3385\n",
            "iteration: 10 of max_iter: 20, perplexity: 1237.1859\n",
            "iteration: 11 of max_iter: 20, perplexity: 1217.0823\n",
            "iteration: 12 of max_iter: 20, perplexity: 1202.9167\n",
            "iteration: 13 of max_iter: 20, perplexity: 1192.7777\n",
            "iteration: 14 of max_iter: 20, perplexity: 1185.0554\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.1988\n",
            "iteration: 16 of max_iter: 20, perplexity: 1174.8157\n",
            "iteration: 17 of max_iter: 20, perplexity: 1171.5908\n",
            "iteration: 18 of max_iter: 20, perplexity: 1169.1378\n",
            "iteration: 19 of max_iter: 20, perplexity: 1167.2297\n",
            "iteration: 20 of max_iter: 20, perplexity: 1165.7255\n",
            "-- test perplexity: 1717.77\n",
            "---- 20 topics, alpha=0.4000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 5773.3339\n",
            "iteration: 2 of max_iter: 20, perplexity: 3952.0493\n",
            "iteration: 3 of max_iter: 20, perplexity: 2688.5169\n",
            "iteration: 4 of max_iter: 20, perplexity: 2065.3274\n",
            "iteration: 5 of max_iter: 20, perplexity: 1723.4952\n",
            "iteration: 6 of max_iter: 20, perplexity: 1526.0036\n",
            "iteration: 7 of max_iter: 20, perplexity: 1405.8015\n",
            "iteration: 8 of max_iter: 20, perplexity: 1330.1536\n",
            "iteration: 9 of max_iter: 20, perplexity: 1281.0973\n",
            "iteration: 10 of max_iter: 20, perplexity: 1248.6755\n",
            "iteration: 11 of max_iter: 20, perplexity: 1226.5010\n",
            "iteration: 12 of max_iter: 20, perplexity: 1210.8871\n",
            "iteration: 13 of max_iter: 20, perplexity: 1199.8323\n",
            "iteration: 14 of max_iter: 20, perplexity: 1191.4391\n",
            "iteration: 15 of max_iter: 20, perplexity: 1185.1033\n",
            "iteration: 16 of max_iter: 20, perplexity: 1180.3372\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.7881\n",
            "iteration: 18 of max_iter: 20, perplexity: 1174.1088\n",
            "iteration: 19 of max_iter: 20, perplexity: 1172.0211\n",
            "iteration: 20 of max_iter: 20, perplexity: 1170.3787\n",
            "-- test perplexity: 1785.71\n",
            "---- 20 topics, alpha=0.4000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 3978.4609\n",
            "iteration: 2 of max_iter: 20, perplexity: 2808.3205\n",
            "iteration: 3 of max_iter: 20, perplexity: 2179.3176\n",
            "iteration: 4 of max_iter: 20, perplexity: 1803.7360\n",
            "iteration: 5 of max_iter: 20, perplexity: 1585.0726\n",
            "iteration: 6 of max_iter: 20, perplexity: 1453.5504\n",
            "iteration: 7 of max_iter: 20, perplexity: 1369.5699\n",
            "iteration: 8 of max_iter: 20, perplexity: 1313.5223\n",
            "iteration: 9 of max_iter: 20, perplexity: 1274.3657\n",
            "iteration: 10 of max_iter: 20, perplexity: 1246.9986\n",
            "iteration: 11 of max_iter: 20, perplexity: 1227.5260\n",
            "iteration: 12 of max_iter: 20, perplexity: 1213.4441\n",
            "iteration: 13 of max_iter: 20, perplexity: 1203.4526\n",
            "iteration: 14 of max_iter: 20, perplexity: 1196.0039\n",
            "iteration: 15 of max_iter: 20, perplexity: 1190.3344\n",
            "iteration: 16 of max_iter: 20, perplexity: 1185.6821\n",
            "iteration: 17 of max_iter: 20, perplexity: 1181.8016\n",
            "iteration: 18 of max_iter: 20, perplexity: 1178.5713\n",
            "iteration: 19 of max_iter: 20, perplexity: 1175.8175\n",
            "iteration: 20 of max_iter: 20, perplexity: 1173.5634\n",
            "-- test perplexity: 1766.57\n",
            "---- 20 topics, alpha=0.3000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 4356.2253\n",
            "iteration: 2 of max_iter: 20, perplexity: 2986.2381\n",
            "iteration: 3 of max_iter: 20, perplexity: 2283.2534\n",
            "iteration: 4 of max_iter: 20, perplexity: 1864.5456\n",
            "iteration: 5 of max_iter: 20, perplexity: 1622.7796\n",
            "iteration: 6 of max_iter: 20, perplexity: 1478.2439\n",
            "iteration: 7 of max_iter: 20, perplexity: 1386.2735\n",
            "iteration: 8 of max_iter: 20, perplexity: 1325.3721\n",
            "iteration: 9 of max_iter: 20, perplexity: 1283.1172\n",
            "iteration: 10 of max_iter: 20, perplexity: 1253.7568\n",
            "iteration: 11 of max_iter: 20, perplexity: 1232.9724\n",
            "iteration: 12 of max_iter: 20, perplexity: 1217.8592\n",
            "iteration: 13 of max_iter: 20, perplexity: 1207.1623\n",
            "iteration: 14 of max_iter: 20, perplexity: 1199.1095\n",
            "iteration: 15 of max_iter: 20, perplexity: 1192.9229\n",
            "iteration: 16 of max_iter: 20, perplexity: 1187.8322\n",
            "iteration: 17 of max_iter: 20, perplexity: 1183.6120\n",
            "iteration: 18 of max_iter: 20, perplexity: 1180.2301\n",
            "iteration: 19 of max_iter: 20, perplexity: 1177.2919\n",
            "iteration: 20 of max_iter: 20, perplexity: 1174.8970\n",
            "-- test perplexity: 1794.59\n",
            "---- 20 topics, alpha=0.3000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 4938.1543\n",
            "iteration: 2 of max_iter: 20, perplexity: 3257.1403\n",
            "iteration: 3 of max_iter: 20, perplexity: 2442.6778\n",
            "iteration: 4 of max_iter: 20, perplexity: 1958.3892\n",
            "iteration: 5 of max_iter: 20, perplexity: 1681.7807\n",
            "iteration: 6 of max_iter: 20, perplexity: 1517.9389\n",
            "iteration: 7 of max_iter: 20, perplexity: 1414.1947\n",
            "iteration: 8 of max_iter: 20, perplexity: 1346.0808\n",
            "iteration: 9 of max_iter: 20, perplexity: 1299.1263\n",
            "iteration: 10 of max_iter: 20, perplexity: 1266.7031\n",
            "iteration: 11 of max_iter: 20, perplexity: 1243.8760\n",
            "iteration: 12 of max_iter: 20, perplexity: 1227.2601\n",
            "iteration: 13 of max_iter: 20, perplexity: 1215.4778\n",
            "iteration: 14 of max_iter: 20, perplexity: 1206.6776\n",
            "iteration: 15 of max_iter: 20, perplexity: 1199.8659\n",
            "iteration: 16 of max_iter: 20, perplexity: 1194.3349\n",
            "iteration: 17 of max_iter: 20, perplexity: 1189.7293\n",
            "iteration: 18 of max_iter: 20, perplexity: 1186.0872\n",
            "iteration: 19 of max_iter: 20, perplexity: 1182.9997\n",
            "iteration: 20 of max_iter: 20, perplexity: 1180.4271\n",
            "-- test perplexity: 1878.41\n",
            "---- 20 topics, alpha=0.3000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 3484.2004\n",
            "iteration: 2 of max_iter: 20, perplexity: 2637.6154\n",
            "iteration: 3 of max_iter: 20, perplexity: 2122.3725\n",
            "iteration: 4 of max_iter: 20, perplexity: 1804.2320\n",
            "iteration: 5 of max_iter: 20, perplexity: 1609.4444\n",
            "iteration: 6 of max_iter: 20, perplexity: 1486.4239\n",
            "iteration: 7 of max_iter: 20, perplexity: 1404.8656\n",
            "iteration: 8 of max_iter: 20, perplexity: 1349.0224\n",
            "iteration: 9 of max_iter: 20, perplexity: 1310.6253\n",
            "iteration: 10 of max_iter: 20, perplexity: 1283.1929\n",
            "iteration: 11 of max_iter: 20, perplexity: 1262.5509\n",
            "iteration: 12 of max_iter: 20, perplexity: 1247.2934\n",
            "iteration: 13 of max_iter: 20, perplexity: 1235.6182\n",
            "iteration: 14 of max_iter: 20, perplexity: 1227.0993\n",
            "iteration: 15 of max_iter: 20, perplexity: 1220.6269\n",
            "iteration: 16 of max_iter: 20, perplexity: 1215.5417\n",
            "iteration: 17 of max_iter: 20, perplexity: 1211.4938\n",
            "iteration: 18 of max_iter: 20, perplexity: 1208.2010\n",
            "iteration: 19 of max_iter: 20, perplexity: 1205.3976\n",
            "iteration: 20 of max_iter: 20, perplexity: 1203.1591\n",
            "-- test perplexity: 1984.02\n",
            "---- 20 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3765.1777\n",
            "iteration: 2 of max_iter: 20, perplexity: 2793.8204\n",
            "iteration: 3 of max_iter: 20, perplexity: 2219.0599\n",
            "iteration: 4 of max_iter: 20, perplexity: 1865.3183\n",
            "iteration: 5 of max_iter: 20, perplexity: 1650.1488\n",
            "iteration: 6 of max_iter: 20, perplexity: 1514.8651\n",
            "iteration: 7 of max_iter: 20, perplexity: 1425.7135\n",
            "iteration: 8 of max_iter: 20, perplexity: 1364.7975\n",
            "iteration: 9 of max_iter: 20, perplexity: 1322.9997\n",
            "iteration: 10 of max_iter: 20, perplexity: 1293.2406\n",
            "iteration: 11 of max_iter: 20, perplexity: 1270.9342\n",
            "iteration: 12 of max_iter: 20, perplexity: 1254.3543\n",
            "iteration: 13 of max_iter: 20, perplexity: 1241.8875\n",
            "iteration: 14 of max_iter: 20, perplexity: 1232.6549\n",
            "iteration: 15 of max_iter: 20, perplexity: 1225.6107\n",
            "iteration: 16 of max_iter: 20, perplexity: 1219.9845\n",
            "iteration: 17 of max_iter: 20, perplexity: 1215.4572\n",
            "iteration: 18 of max_iter: 20, perplexity: 1211.7499\n",
            "iteration: 19 of max_iter: 20, perplexity: 1208.8321\n",
            "iteration: 20 of max_iter: 20, perplexity: 1206.4320\n",
            "-- test perplexity: 2047.86\n",
            "---- 20 topics, alpha=0.2000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 4218.4200\n",
            "iteration: 2 of max_iter: 20, perplexity: 3030.9906\n",
            "iteration: 3 of max_iter: 20, perplexity: 2366.5984\n",
            "iteration: 4 of max_iter: 20, perplexity: 1958.7172\n",
            "iteration: 5 of max_iter: 20, perplexity: 1712.9118\n",
            "iteration: 6 of max_iter: 20, perplexity: 1559.4449\n",
            "iteration: 7 of max_iter: 20, perplexity: 1459.0300\n",
            "iteration: 8 of max_iter: 20, perplexity: 1390.6020\n",
            "iteration: 9 of max_iter: 20, perplexity: 1343.8014\n",
            "iteration: 10 of max_iter: 20, perplexity: 1310.5640\n",
            "iteration: 11 of max_iter: 20, perplexity: 1285.9858\n",
            "iteration: 12 of max_iter: 20, perplexity: 1267.8875\n",
            "iteration: 13 of max_iter: 20, perplexity: 1254.2588\n",
            "iteration: 14 of max_iter: 20, perplexity: 1244.0670\n",
            "iteration: 15 of max_iter: 20, perplexity: 1236.3522\n",
            "iteration: 16 of max_iter: 20, perplexity: 1230.0643\n",
            "iteration: 17 of max_iter: 20, perplexity: 1225.1584\n",
            "iteration: 18 of max_iter: 20, perplexity: 1221.0972\n",
            "iteration: 19 of max_iter: 20, perplexity: 1217.6652\n",
            "iteration: 20 of max_iter: 20, perplexity: 1214.9888\n",
            "-- test perplexity: 2186.24\n",
            "---- 20 topics, alpha=0.2000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 7443.4201\n",
            "iteration: 2 of max_iter: 20, perplexity: 4923.7028\n",
            "iteration: 3 of max_iter: 20, perplexity: 3077.0832\n",
            "iteration: 4 of max_iter: 20, perplexity: 2214.0569\n",
            "iteration: 5 of max_iter: 20, perplexity: 1773.8470\n",
            "iteration: 6 of max_iter: 20, perplexity: 1534.0903\n",
            "iteration: 7 of max_iter: 20, perplexity: 1397.0089\n",
            "iteration: 8 of max_iter: 20, perplexity: 1315.1594\n",
            "iteration: 9 of max_iter: 20, perplexity: 1264.0127\n",
            "iteration: 10 of max_iter: 20, perplexity: 1231.6376\n",
            "iteration: 11 of max_iter: 20, perplexity: 1210.2890\n",
            "iteration: 12 of max_iter: 20, perplexity: 1195.2120\n",
            "iteration: 13 of max_iter: 20, perplexity: 1184.1827\n",
            "iteration: 14 of max_iter: 20, perplexity: 1176.7566\n",
            "iteration: 15 of max_iter: 20, perplexity: 1171.8463\n",
            "iteration: 16 of max_iter: 20, perplexity: 1168.3646\n",
            "iteration: 17 of max_iter: 20, perplexity: 1165.5250\n",
            "iteration: 18 of max_iter: 20, perplexity: 1162.8344\n",
            "iteration: 19 of max_iter: 20, perplexity: 1160.4984\n",
            "iteration: 20 of max_iter: 20, perplexity: 1158.7933\n",
            "-- test perplexity: 1718.60\n",
            "---- 30 topics, alpha=0.4000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 8567.2512\n",
            "iteration: 2 of max_iter: 20, perplexity: 5577.9758\n",
            "iteration: 3 of max_iter: 20, perplexity: 3324.0526\n",
            "iteration: 4 of max_iter: 20, perplexity: 2327.8548\n",
            "iteration: 5 of max_iter: 20, perplexity: 1831.2498\n",
            "iteration: 6 of max_iter: 20, perplexity: 1564.3919\n",
            "iteration: 7 of max_iter: 20, perplexity: 1413.3995\n",
            "iteration: 8 of max_iter: 20, perplexity: 1324.1233\n",
            "iteration: 9 of max_iter: 20, perplexity: 1268.7984\n",
            "iteration: 10 of max_iter: 20, perplexity: 1234.0844\n",
            "iteration: 11 of max_iter: 20, perplexity: 1211.3089\n",
            "iteration: 12 of max_iter: 20, perplexity: 1195.5001\n",
            "iteration: 13 of max_iter: 20, perplexity: 1184.0530\n",
            "iteration: 14 of max_iter: 20, perplexity: 1176.2119\n",
            "iteration: 15 of max_iter: 20, perplexity: 1170.8592\n",
            "iteration: 16 of max_iter: 20, perplexity: 1167.0844\n",
            "iteration: 17 of max_iter: 20, perplexity: 1164.1025\n",
            "iteration: 18 of max_iter: 20, perplexity: 1161.3044\n",
            "iteration: 19 of max_iter: 20, perplexity: 1158.8992\n",
            "iteration: 20 of max_iter: 20, perplexity: 1157.1552\n",
            "-- test perplexity: 1708.31\n",
            "---- 30 topics, alpha=0.4000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 10370.5693\n",
            "iteration: 2 of max_iter: 20, perplexity: 6664.5619\n",
            "iteration: 3 of max_iter: 20, perplexity: 3721.9794\n",
            "iteration: 4 of max_iter: 20, perplexity: 2508.5870\n",
            "iteration: 5 of max_iter: 20, perplexity: 1923.9188\n",
            "iteration: 6 of max_iter: 20, perplexity: 1615.5277\n",
            "iteration: 7 of max_iter: 20, perplexity: 1443.3796\n",
            "iteration: 8 of max_iter: 20, perplexity: 1342.8962\n",
            "iteration: 9 of max_iter: 20, perplexity: 1281.2353\n",
            "iteration: 10 of max_iter: 20, perplexity: 1242.9432\n",
            "iteration: 11 of max_iter: 20, perplexity: 1217.9662\n",
            "iteration: 12 of max_iter: 20, perplexity: 1200.8431\n",
            "iteration: 13 of max_iter: 20, perplexity: 1188.5201\n",
            "iteration: 14 of max_iter: 20, perplexity: 1180.1211\n",
            "iteration: 15 of max_iter: 20, perplexity: 1174.5154\n",
            "iteration: 16 of max_iter: 20, perplexity: 1170.4429\n",
            "iteration: 17 of max_iter: 20, perplexity: 1167.1643\n",
            "iteration: 18 of max_iter: 20, perplexity: 1164.2056\n",
            "iteration: 19 of max_iter: 20, perplexity: 1161.7236\n",
            "iteration: 20 of max_iter: 20, perplexity: 1159.9133\n",
            "-- test perplexity: 1752.61\n",
            "---- 30 topics, alpha=0.4000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 5793.0349\n",
            "iteration: 2 of max_iter: 20, perplexity: 3472.1516\n",
            "iteration: 3 of max_iter: 20, perplexity: 2443.7614\n",
            "iteration: 4 of max_iter: 20, perplexity: 1893.6984\n",
            "iteration: 5 of max_iter: 20, perplexity: 1597.5438\n",
            "iteration: 6 of max_iter: 20, perplexity: 1432.5572\n",
            "iteration: 7 of max_iter: 20, perplexity: 1337.2462\n",
            "iteration: 8 of max_iter: 20, perplexity: 1279.3512\n",
            "iteration: 9 of max_iter: 20, perplexity: 1243.0329\n",
            "iteration: 10 of max_iter: 20, perplexity: 1219.1662\n",
            "iteration: 11 of max_iter: 20, perplexity: 1203.3448\n",
            "iteration: 12 of max_iter: 20, perplexity: 1192.9153\n",
            "iteration: 13 of max_iter: 20, perplexity: 1185.9928\n",
            "iteration: 14 of max_iter: 20, perplexity: 1181.2556\n",
            "iteration: 15 of max_iter: 20, perplexity: 1177.8256\n",
            "iteration: 16 of max_iter: 20, perplexity: 1175.4094\n",
            "iteration: 17 of max_iter: 20, perplexity: 1173.6760\n",
            "iteration: 18 of max_iter: 20, perplexity: 1172.2381\n",
            "iteration: 19 of max_iter: 20, perplexity: 1170.9199\n",
            "iteration: 20 of max_iter: 20, perplexity: 1169.2367\n",
            "-- test perplexity: 1763.68\n",
            "---- 30 topics, alpha=0.3000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 6630.3842\n",
            "iteration: 2 of max_iter: 20, perplexity: 3764.3502\n",
            "iteration: 3 of max_iter: 20, perplexity: 2587.5097\n",
            "iteration: 4 of max_iter: 20, perplexity: 1965.5830\n",
            "iteration: 5 of max_iter: 20, perplexity: 1635.1361\n",
            "iteration: 6 of max_iter: 20, perplexity: 1453.2302\n",
            "iteration: 7 of max_iter: 20, perplexity: 1348.8617\n",
            "iteration: 8 of max_iter: 20, perplexity: 1286.0323\n",
            "iteration: 9 of max_iter: 20, perplexity: 1246.8749\n",
            "iteration: 10 of max_iter: 20, perplexity: 1221.3752\n",
            "iteration: 11 of max_iter: 20, perplexity: 1204.3497\n",
            "iteration: 12 of max_iter: 20, perplexity: 1193.1966\n",
            "iteration: 13 of max_iter: 20, perplexity: 1185.7903\n",
            "iteration: 14 of max_iter: 20, perplexity: 1180.7507\n",
            "iteration: 15 of max_iter: 20, perplexity: 1177.0475\n",
            "iteration: 16 of max_iter: 20, perplexity: 1174.5007\n",
            "iteration: 17 of max_iter: 20, perplexity: 1172.6509\n",
            "iteration: 18 of max_iter: 20, perplexity: 1171.0891\n",
            "iteration: 19 of max_iter: 20, perplexity: 1169.6505\n",
            "iteration: 20 of max_iter: 20, perplexity: 1167.8754\n",
            "-- test perplexity: 1758.03\n",
            "---- 30 topics, alpha=0.3000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 7996.9499\n",
            "iteration: 2 of max_iter: 20, perplexity: 4228.6254\n",
            "iteration: 3 of max_iter: 20, perplexity: 2814.5938\n",
            "iteration: 4 of max_iter: 20, perplexity: 2080.6479\n",
            "iteration: 5 of max_iter: 20, perplexity: 1697.3606\n",
            "iteration: 6 of max_iter: 20, perplexity: 1489.5077\n",
            "iteration: 7 of max_iter: 20, perplexity: 1371.3726\n",
            "iteration: 8 of max_iter: 20, perplexity: 1300.8501\n",
            "iteration: 9 of max_iter: 20, perplexity: 1257.5167\n",
            "iteration: 10 of max_iter: 20, perplexity: 1229.2505\n",
            "iteration: 11 of max_iter: 20, perplexity: 1210.6630\n",
            "iteration: 12 of max_iter: 20, perplexity: 1198.4427\n",
            "iteration: 13 of max_iter: 20, perplexity: 1190.4479\n",
            "iteration: 14 of max_iter: 20, perplexity: 1184.9929\n",
            "iteration: 15 of max_iter: 20, perplexity: 1180.9558\n",
            "iteration: 16 of max_iter: 20, perplexity: 1178.0927\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.0070\n",
            "iteration: 18 of max_iter: 20, perplexity: 1174.3797\n",
            "iteration: 19 of max_iter: 20, perplexity: 1172.9145\n",
            "iteration: 20 of max_iter: 20, perplexity: 1171.2868\n",
            "-- test perplexity: 1810.04\n",
            "---- 30 topics, alpha=0.3000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 4752.9366\n",
            "iteration: 2 of max_iter: 20, perplexity: 3216.5343\n",
            "iteration: 3 of max_iter: 20, perplexity: 2384.1470\n",
            "iteration: 4 of max_iter: 20, perplexity: 1913.7865\n",
            "iteration: 5 of max_iter: 20, perplexity: 1648.6328\n",
            "iteration: 6 of max_iter: 20, perplexity: 1490.7126\n",
            "iteration: 7 of max_iter: 20, perplexity: 1393.4750\n",
            "iteration: 8 of max_iter: 20, perplexity: 1332.9736\n",
            "iteration: 9 of max_iter: 20, perplexity: 1293.6137\n",
            "iteration: 10 of max_iter: 20, perplexity: 1267.8066\n",
            "iteration: 11 of max_iter: 20, perplexity: 1249.8159\n",
            "iteration: 12 of max_iter: 20, perplexity: 1236.3655\n",
            "iteration: 13 of max_iter: 20, perplexity: 1226.1701\n",
            "iteration: 14 of max_iter: 20, perplexity: 1218.9078\n",
            "iteration: 15 of max_iter: 20, perplexity: 1214.0400\n",
            "iteration: 16 of max_iter: 20, perplexity: 1210.2323\n",
            "iteration: 17 of max_iter: 20, perplexity: 1207.4859\n",
            "iteration: 18 of max_iter: 20, perplexity: 1205.4914\n",
            "iteration: 19 of max_iter: 20, perplexity: 1203.9408\n",
            "iteration: 20 of max_iter: 20, perplexity: 1202.6226\n",
            "-- test perplexity: 1942.17\n",
            "---- 30 topics, alpha=0.2000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 5306.1469\n",
            "iteration: 2 of max_iter: 20, perplexity: 3458.3059\n",
            "iteration: 3 of max_iter: 20, perplexity: 2514.9773\n",
            "iteration: 4 of max_iter: 20, perplexity: 1985.6681\n",
            "iteration: 5 of max_iter: 20, perplexity: 1690.5179\n",
            "iteration: 6 of max_iter: 20, perplexity: 1516.2657\n",
            "iteration: 7 of max_iter: 20, perplexity: 1409.5860\n",
            "iteration: 8 of max_iter: 20, perplexity: 1343.4417\n",
            "iteration: 9 of max_iter: 20, perplexity: 1300.5606\n",
            "iteration: 10 of max_iter: 20, perplexity: 1272.5069\n",
            "iteration: 11 of max_iter: 20, perplexity: 1253.1647\n",
            "iteration: 12 of max_iter: 20, perplexity: 1239.3878\n",
            "iteration: 13 of max_iter: 20, perplexity: 1228.6739\n",
            "iteration: 14 of max_iter: 20, perplexity: 1220.5753\n",
            "iteration: 15 of max_iter: 20, perplexity: 1214.9128\n",
            "iteration: 16 of max_iter: 20, perplexity: 1210.7894\n",
            "iteration: 17 of max_iter: 20, perplexity: 1207.9257\n",
            "iteration: 18 of max_iter: 20, perplexity: 1205.8119\n",
            "iteration: 19 of max_iter: 20, perplexity: 1204.2289\n",
            "iteration: 20 of max_iter: 20, perplexity: 1202.9780\n",
            "-- test perplexity: 1956.35\n",
            "---- 30 topics, alpha=0.2000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 6261.1105\n",
            "iteration: 2 of max_iter: 20, perplexity: 3836.8011\n",
            "iteration: 3 of max_iter: 20, perplexity: 2720.3814\n",
            "iteration: 4 of max_iter: 20, perplexity: 2099.5676\n",
            "iteration: 5 of max_iter: 20, perplexity: 1757.9287\n",
            "iteration: 6 of max_iter: 20, perplexity: 1558.9411\n",
            "iteration: 7 of max_iter: 20, perplexity: 1438.4304\n",
            "iteration: 8 of max_iter: 20, perplexity: 1364.1161\n",
            "iteration: 9 of max_iter: 20, perplexity: 1316.0351\n",
            "iteration: 10 of max_iter: 20, perplexity: 1284.7436\n",
            "iteration: 11 of max_iter: 20, perplexity: 1263.3441\n",
            "iteration: 12 of max_iter: 20, perplexity: 1247.8511\n",
            "iteration: 13 of max_iter: 20, perplexity: 1236.1485\n",
            "iteration: 14 of max_iter: 20, perplexity: 1227.2517\n",
            "iteration: 15 of max_iter: 20, perplexity: 1221.2161\n",
            "iteration: 16 of max_iter: 20, perplexity: 1216.9826\n",
            "iteration: 17 of max_iter: 20, perplexity: 1213.8247\n",
            "iteration: 18 of max_iter: 20, perplexity: 1211.5682\n",
            "iteration: 19 of max_iter: 20, perplexity: 1209.7898\n",
            "iteration: 20 of max_iter: 20, perplexity: 1208.3217\n",
            "-- test perplexity: 2045.88\n",
            "---- 30 topics, alpha=0.2000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 10926.2386\n",
            "iteration: 2 of max_iter: 20, perplexity: 7816.1946\n",
            "iteration: 3 of max_iter: 20, perplexity: 4564.2493\n",
            "iteration: 4 of max_iter: 20, perplexity: 2964.6208\n",
            "iteration: 5 of max_iter: 20, perplexity: 2162.6359\n",
            "iteration: 6 of max_iter: 20, perplexity: 1746.7211\n",
            "iteration: 7 of max_iter: 20, perplexity: 1521.6406\n",
            "iteration: 8 of max_iter: 20, perplexity: 1392.9582\n",
            "iteration: 9 of max_iter: 20, perplexity: 1315.7952\n",
            "iteration: 10 of max_iter: 20, perplexity: 1266.0575\n",
            "iteration: 11 of max_iter: 20, perplexity: 1233.1150\n",
            "iteration: 12 of max_iter: 20, perplexity: 1212.2455\n",
            "iteration: 13 of max_iter: 20, perplexity: 1200.0003\n",
            "iteration: 14 of max_iter: 20, perplexity: 1192.8859\n",
            "iteration: 15 of max_iter: 20, perplexity: 1188.2892\n",
            "iteration: 16 of max_iter: 20, perplexity: 1184.9526\n",
            "iteration: 17 of max_iter: 20, perplexity: 1182.6133\n",
            "iteration: 18 of max_iter: 20, perplexity: 1180.8786\n",
            "iteration: 19 of max_iter: 20, perplexity: 1179.4968\n",
            "iteration: 20 of max_iter: 20, perplexity: 1178.5946\n",
            "-- test perplexity: 1787.35\n",
            "---- 40 topics, alpha=0.4000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 13178.4936\n",
            "iteration: 2 of max_iter: 20, perplexity: 9262.2877\n",
            "iteration: 3 of max_iter: 20, perplexity: 5084.7081\n",
            "iteration: 4 of max_iter: 20, perplexity: 3171.1441\n",
            "iteration: 5 of max_iter: 20, perplexity: 2256.6175\n",
            "iteration: 6 of max_iter: 20, perplexity: 1791.6895\n",
            "iteration: 7 of max_iter: 20, perplexity: 1543.6157\n",
            "iteration: 8 of max_iter: 20, perplexity: 1403.2703\n",
            "iteration: 9 of max_iter: 20, perplexity: 1319.6664\n",
            "iteration: 10 of max_iter: 20, perplexity: 1266.3307\n",
            "iteration: 11 of max_iter: 20, perplexity: 1231.4597\n",
            "iteration: 12 of max_iter: 20, perplexity: 1209.6515\n",
            "iteration: 13 of max_iter: 20, perplexity: 1196.9259\n",
            "iteration: 14 of max_iter: 20, perplexity: 1189.5109\n",
            "iteration: 15 of max_iter: 20, perplexity: 1184.8609\n",
            "iteration: 16 of max_iter: 20, perplexity: 1181.5555\n",
            "iteration: 17 of max_iter: 20, perplexity: 1179.1279\n",
            "iteration: 18 of max_iter: 20, perplexity: 1177.3576\n",
            "iteration: 19 of max_iter: 20, perplexity: 1176.0561\n",
            "iteration: 20 of max_iter: 20, perplexity: 1175.0340\n",
            "-- test perplexity: 1752.08\n",
            "---- 40 topics, alpha=0.4000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 17000.3717\n",
            "iteration: 2 of max_iter: 20, perplexity: 11781.3875\n",
            "iteration: 3 of max_iter: 20, perplexity: 5959.6953\n",
            "iteration: 4 of max_iter: 20, perplexity: 3506.1438\n",
            "iteration: 5 of max_iter: 20, perplexity: 2409.9902\n",
            "iteration: 6 of max_iter: 20, perplexity: 1867.9469\n",
            "iteration: 7 of max_iter: 20, perplexity: 1584.1455\n",
            "iteration: 8 of max_iter: 20, perplexity: 1425.9862\n",
            "iteration: 9 of max_iter: 20, perplexity: 1333.0221\n",
            "iteration: 10 of max_iter: 20, perplexity: 1274.4030\n",
            "iteration: 11 of max_iter: 20, perplexity: 1236.6786\n",
            "iteration: 12 of max_iter: 20, perplexity: 1213.3711\n",
            "iteration: 13 of max_iter: 20, perplexity: 1199.6811\n",
            "iteration: 14 of max_iter: 20, perplexity: 1191.5427\n",
            "iteration: 15 of max_iter: 20, perplexity: 1186.4640\n",
            "iteration: 16 of max_iter: 20, perplexity: 1182.9268\n",
            "iteration: 17 of max_iter: 20, perplexity: 1180.4631\n",
            "iteration: 18 of max_iter: 20, perplexity: 1178.5846\n",
            "iteration: 19 of max_iter: 20, perplexity: 1177.1615\n",
            "iteration: 20 of max_iter: 20, perplexity: 1176.1045\n",
            "-- test perplexity: 1777.41\n",
            "---- 40 topics, alpha=0.4000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 8142.2287\n",
            "iteration: 2 of max_iter: 20, perplexity: 4205.1446\n",
            "iteration: 3 of max_iter: 20, perplexity: 2695.7775\n",
            "iteration: 4 of max_iter: 20, perplexity: 1948.7033\n",
            "iteration: 5 of max_iter: 20, perplexity: 1586.9243\n",
            "iteration: 6 of max_iter: 20, perplexity: 1406.6929\n",
            "iteration: 7 of max_iter: 20, perplexity: 1313.5597\n",
            "iteration: 8 of max_iter: 20, perplexity: 1261.4665\n",
            "iteration: 9 of max_iter: 20, perplexity: 1229.7569\n",
            "iteration: 10 of max_iter: 20, perplexity: 1211.0530\n",
            "iteration: 11 of max_iter: 20, perplexity: 1200.6120\n",
            "iteration: 12 of max_iter: 20, perplexity: 1194.2872\n",
            "iteration: 13 of max_iter: 20, perplexity: 1189.7827\n",
            "iteration: 14 of max_iter: 20, perplexity: 1186.2948\n",
            "iteration: 15 of max_iter: 20, perplexity: 1183.8392\n",
            "iteration: 16 of max_iter: 20, perplexity: 1181.9692\n",
            "iteration: 17 of max_iter: 20, perplexity: 1180.5625\n",
            "iteration: 18 of max_iter: 20, perplexity: 1179.5469\n",
            "iteration: 19 of max_iter: 20, perplexity: 1178.8265\n",
            "iteration: 20 of max_iter: 20, perplexity: 1178.3062\n",
            "-- test perplexity: 1809.31\n",
            "---- 40 topics, alpha=0.3000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 9744.1808\n",
            "iteration: 2 of max_iter: 20, perplexity: 4644.4398\n",
            "iteration: 3 of max_iter: 20, perplexity: 2879.7156\n",
            "iteration: 4 of max_iter: 20, perplexity: 2028.3013\n",
            "iteration: 5 of max_iter: 20, perplexity: 1622.5928\n",
            "iteration: 6 of max_iter: 20, perplexity: 1422.9915\n",
            "iteration: 7 of max_iter: 20, perplexity: 1320.6561\n",
            "iteration: 8 of max_iter: 20, perplexity: 1263.9238\n",
            "iteration: 9 of max_iter: 20, perplexity: 1229.7687\n",
            "iteration: 10 of max_iter: 20, perplexity: 1209.7048\n",
            "iteration: 11 of max_iter: 20, perplexity: 1198.4366\n",
            "iteration: 12 of max_iter: 20, perplexity: 1191.4589\n",
            "iteration: 13 of max_iter: 20, perplexity: 1186.5500\n",
            "iteration: 14 of max_iter: 20, perplexity: 1182.9737\n",
            "iteration: 15 of max_iter: 20, perplexity: 1180.4086\n",
            "iteration: 16 of max_iter: 20, perplexity: 1178.3252\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.8855\n",
            "iteration: 18 of max_iter: 20, perplexity: 1175.8004\n",
            "iteration: 19 of max_iter: 20, perplexity: 1175.0493\n",
            "iteration: 20 of max_iter: 20, perplexity: 1174.4370\n",
            "-- test perplexity: 1775.06\n",
            "---- 40 topics, alpha=0.3000, eta=0.0050\n",
            "iteration: 1 of max_iter: 20, perplexity: 12506.9400\n",
            "iteration: 2 of max_iter: 20, perplexity: 5371.3233\n",
            "iteration: 3 of max_iter: 20, perplexity: 3176.9104\n",
            "iteration: 4 of max_iter: 20, perplexity: 2159.6119\n",
            "iteration: 5 of max_iter: 20, perplexity: 1684.5799\n",
            "iteration: 6 of max_iter: 20, perplexity: 1455.0611\n",
            "iteration: 7 of max_iter: 20, perplexity: 1338.3638\n",
            "iteration: 8 of max_iter: 20, perplexity: 1274.3703\n",
            "iteration: 9 of max_iter: 20, perplexity: 1236.4695\n",
            "iteration: 10 of max_iter: 20, perplexity: 1214.3094\n",
            "iteration: 11 of max_iter: 20, perplexity: 1201.8597\n",
            "iteration: 12 of max_iter: 20, perplexity: 1194.2232\n",
            "iteration: 13 of max_iter: 20, perplexity: 1188.8190\n",
            "iteration: 14 of max_iter: 20, perplexity: 1184.8899\n",
            "iteration: 15 of max_iter: 20, perplexity: 1182.1500\n",
            "iteration: 16 of max_iter: 20, perplexity: 1180.0817\n",
            "iteration: 17 of max_iter: 20, perplexity: 1178.4553\n",
            "iteration: 18 of max_iter: 20, perplexity: 1177.2162\n",
            "iteration: 19 of max_iter: 20, perplexity: 1176.3645\n",
            "iteration: 20 of max_iter: 20, perplexity: 1175.6710\n",
            "-- test perplexity: 1805.08\n",
            "---- 40 topics, alpha=0.3000, eta=0.0020\n",
            "iteration: 1 of max_iter: 20, perplexity: 6138.3878\n",
            "iteration: 2 of max_iter: 20, perplexity: 3775.9710\n",
            "iteration: 3 of max_iter: 20, perplexity: 2598.9228\n",
            "iteration: 4 of max_iter: 20, perplexity: 1980.0717\n",
            "iteration: 5 of max_iter: 20, perplexity: 1654.4832\n",
            "iteration: 6 of max_iter: 20, perplexity: 1477.2112\n",
            "iteration: 7 of max_iter: 20, perplexity: 1375.5040\n",
            "iteration: 8 of max_iter: 20, perplexity: 1314.5315\n",
            "iteration: 9 of max_iter: 20, perplexity: 1276.1766\n",
            "iteration: 10 of max_iter: 20, perplexity: 1252.5585\n",
            "iteration: 11 of max_iter: 20, perplexity: 1237.7568\n",
            "iteration: 12 of max_iter: 20, perplexity: 1228.5318\n",
            "iteration: 13 of max_iter: 20, perplexity: 1222.6315\n",
            "iteration: 14 of max_iter: 20, perplexity: 1218.6583\n",
            "iteration: 15 of max_iter: 20, perplexity: 1215.6281\n",
            "iteration: 16 of max_iter: 20, perplexity: 1213.1294\n",
            "iteration: 17 of max_iter: 20, perplexity: 1211.2879\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic_word_prior \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.005\u001b[39m, \u001b[38;5;241m0.002\u001b[39m]:\n\u001b[1;32m      4\u001b[0m   lda \u001b[38;5;241m=\u001b[39m LatentDirichletAllocation(\n\u001b[1;32m      5\u001b[0m     n_components\u001b[38;5;241m=\u001b[39mn_components,\n\u001b[1;32m      6\u001b[0m     doc_topic_prior\u001b[38;5;241m=\u001b[39mdoc_topic_prior,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[1;32m     12\u001b[0m   )\n\u001b[0;32m---> 13\u001b[0m   lda\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-- test perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlda\u001b[38;5;241m.\u001b[39mperplexity(X_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m topics, alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_topic_prior\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eta=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic_word_prior\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:673\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_em_step(\n\u001b[1;32m    666\u001b[0m             X[idx_slice, :],\n\u001b[1;32m    667\u001b[0m             total_samples\u001b[38;5;241m=\u001b[39mn_samples,\n\u001b[1;32m    668\u001b[0m             batch_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    669\u001b[0m             parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[1;32m    670\u001b[0m         )\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;66;03m# batch update\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_em_step(\n\u001b[1;32m    674\u001b[0m         X, total_samples\u001b[38;5;241m=\u001b[39mn_samples, batch_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parallel\u001b[38;5;241m=\u001b[39mparallel\n\u001b[1;32m    675\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# check perplexity\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_every \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m evaluate_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:524\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"EM update for 1 iteration.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03mupdate `_component` by batch VB or online VB.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Unnormalized document topic distribution.\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# E-step\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m _, suff_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(\n\u001b[1;32m    525\u001b[0m     X, cal_sstats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parallel\u001b[38;5;241m=\u001b[39mparallel\n\u001b[1;32m    526\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# M-step\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_update:\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:467\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 467\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    468\u001b[0m     delayed(_update_doc_distribution)(\n\u001b[1;32m    469\u001b[0m         X[idx_slice, :],\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_dirichlet_component_,\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_topic_prior_,\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_doc_update_iter,\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_change_tol,\n\u001b[1;32m    474\u001b[0m         cal_sstats,\n\u001b[1;32m    475\u001b[0m         random_state,\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx_slice \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_jobs)\n\u001b[1;32m    478\u001b[0m )\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# merge result\u001b[39;00m\n\u001b[1;32m    481\u001b[0m doc_topics, sstats_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:97\u001b[0m, in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_doc_update_iter, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m     94\u001b[0m n_topics \u001b[38;5;241m=\u001b[39m exp_topic_word_distr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_state:\n\u001b[0;32m---> 97\u001b[0m     doc_topic_distr \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mgamma(\u001b[38;5;241m100.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, (n_samples, n_topics))\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m     98\u001b[0m         X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     doc_topic_distr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((n_samples, n_topics), dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for n_components in [20, 30, 40]:\n",
        "  for doc_topic_prior in [0.4, 0.3, 0.2]:\n",
        "    for topic_word_prior in [0.01, 0.005, 0.002]:\n",
        "      lda = LatentDirichletAllocation(\n",
        "        n_components=n_components,\n",
        "        doc_topic_prior=doc_topic_prior,\n",
        "        topic_word_prior=topic_word_prior,\n",
        "        max_iter=20,\n",
        "        evaluate_every=1,\n",
        "        verbose=1,\n",
        "        random_state=123,\n",
        "      )\n",
        "      lda.fit(X_train)\n",
        "      print(f\"-- test perplexity: {lda.perplexity(X_test):.2f}\")\n",
        "      print(f\"---- {n_components} topics, alpha={doc_topic_prior:.4f}, eta={topic_word_prior:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZBmH7aGNv9s"
      },
      "source": [
        "### 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOpmLdO1Nv9s",
        "outputId": "8b146d92-9454-456f-b094-6c262132525d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 20, perplexity: 3100.8906\n",
            "iteration: 2 of max_iter: 20, perplexity: 3014.2460\n",
            "iteration: 3 of max_iter: 20, perplexity: 2749.3072\n",
            "iteration: 4 of max_iter: 20, perplexity: 2337.7289\n",
            "iteration: 5 of max_iter: 20, perplexity: 1970.2551\n",
            "iteration: 6 of max_iter: 20, perplexity: 1710.4167\n",
            "iteration: 7 of max_iter: 20, perplexity: 1536.7093\n",
            "iteration: 8 of max_iter: 20, perplexity: 1420.4502\n",
            "iteration: 9 of max_iter: 20, perplexity: 1341.8394\n",
            "iteration: 10 of max_iter: 20, perplexity: 1288.1176\n",
            "iteration: 11 of max_iter: 20, perplexity: 1250.4483\n",
            "iteration: 12 of max_iter: 20, perplexity: 1223.6283\n",
            "iteration: 13 of max_iter: 20, perplexity: 1204.4556\n",
            "iteration: 14 of max_iter: 20, perplexity: 1190.7195\n",
            "iteration: 15 of max_iter: 20, perplexity: 1180.8077\n",
            "iteration: 16 of max_iter: 20, perplexity: 1173.3452\n",
            "iteration: 17 of max_iter: 20, perplexity: 1167.6131\n",
            "iteration: 18 of max_iter: 20, perplexity: 1163.0610\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.2964\n",
            "iteration: 20 of max_iter: 20, perplexity: 1156.1809\n",
            "-- test perplexity: 1702.05\n",
            "---- 15 topics, alpha=0.6000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3222.0155\n",
            "iteration: 2 of max_iter: 20, perplexity: 3129.3457\n",
            "iteration: 3 of max_iter: 20, perplexity: 2844.2119\n",
            "iteration: 4 of max_iter: 20, perplexity: 2401.5333\n",
            "iteration: 5 of max_iter: 20, perplexity: 2010.1172\n",
            "iteration: 6 of max_iter: 20, perplexity: 1735.2766\n",
            "iteration: 7 of max_iter: 20, perplexity: 1552.1868\n",
            "iteration: 8 of max_iter: 20, perplexity: 1429.9400\n",
            "iteration: 9 of max_iter: 20, perplexity: 1347.3862\n",
            "iteration: 10 of max_iter: 20, perplexity: 1291.1020\n",
            "iteration: 11 of max_iter: 20, perplexity: 1251.6732\n",
            "iteration: 12 of max_iter: 20, perplexity: 1223.5859\n",
            "iteration: 13 of max_iter: 20, perplexity: 1203.5779\n",
            "iteration: 14 of max_iter: 20, perplexity: 1189.2374\n",
            "iteration: 15 of max_iter: 20, perplexity: 1178.8540\n",
            "iteration: 16 of max_iter: 20, perplexity: 1171.0065\n",
            "iteration: 17 of max_iter: 20, perplexity: 1165.0001\n",
            "iteration: 18 of max_iter: 20, perplexity: 1160.2505\n",
            "iteration: 19 of max_iter: 20, perplexity: 1156.3157\n",
            "iteration: 20 of max_iter: 20, perplexity: 1153.0781\n",
            "-- test perplexity: 1673.88\n",
            "---- 15 topics, alpha=0.6000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3450.6931\n",
            "iteration: 2 of max_iter: 20, perplexity: 3348.3942\n",
            "iteration: 3 of max_iter: 20, perplexity: 3029.6640\n",
            "iteration: 4 of max_iter: 20, perplexity: 2529.1084\n",
            "iteration: 5 of max_iter: 20, perplexity: 2091.2587\n",
            "iteration: 6 of max_iter: 20, perplexity: 1787.3354\n",
            "iteration: 7 of max_iter: 20, perplexity: 1586.2671\n",
            "iteration: 8 of max_iter: 20, perplexity: 1452.5745\n",
            "iteration: 9 of max_iter: 20, perplexity: 1362.5142\n",
            "iteration: 10 of max_iter: 20, perplexity: 1301.4001\n",
            "iteration: 11 of max_iter: 20, perplexity: 1258.7277\n",
            "iteration: 12 of max_iter: 20, perplexity: 1228.2618\n",
            "iteration: 13 of max_iter: 20, perplexity: 1206.6382\n",
            "iteration: 14 of max_iter: 20, perplexity: 1191.1201\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.9104\n",
            "iteration: 16 of max_iter: 20, perplexity: 1171.4288\n",
            "iteration: 17 of max_iter: 20, perplexity: 1164.9619\n",
            "iteration: 18 of max_iter: 20, perplexity: 1159.8684\n",
            "iteration: 19 of max_iter: 20, perplexity: 1155.6552\n",
            "iteration: 20 of max_iter: 20, perplexity: 1152.1465\n",
            "-- test perplexity: 1674.08\n",
            "---- 15 topics, alpha=0.6000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3369.4142\n",
            "iteration: 2 of max_iter: 20, perplexity: 2938.6767\n",
            "iteration: 3 of max_iter: 20, perplexity: 2337.2095\n",
            "iteration: 4 of max_iter: 20, perplexity: 1905.4793\n",
            "iteration: 5 of max_iter: 20, perplexity: 1644.3075\n",
            "iteration: 6 of max_iter: 20, perplexity: 1483.8364\n",
            "iteration: 7 of max_iter: 20, perplexity: 1381.9680\n",
            "iteration: 8 of max_iter: 20, perplexity: 1315.5572\n",
            "iteration: 9 of max_iter: 20, perplexity: 1271.0287\n",
            "iteration: 10 of max_iter: 20, perplexity: 1240.4906\n",
            "iteration: 11 of max_iter: 20, perplexity: 1219.2566\n",
            "iteration: 12 of max_iter: 20, perplexity: 1204.0455\n",
            "iteration: 13 of max_iter: 20, perplexity: 1192.8770\n",
            "iteration: 14 of max_iter: 20, perplexity: 1184.5853\n",
            "iteration: 15 of max_iter: 20, perplexity: 1178.2674\n",
            "iteration: 16 of max_iter: 20, perplexity: 1173.1727\n",
            "iteration: 17 of max_iter: 20, perplexity: 1168.9829\n",
            "iteration: 18 of max_iter: 20, perplexity: 1165.5532\n",
            "iteration: 19 of max_iter: 20, perplexity: 1162.7461\n",
            "iteration: 20 of max_iter: 20, perplexity: 1160.4694\n",
            "-- test perplexity: 1709.04\n",
            "---- 15 topics, alpha=0.5000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3500.4311\n",
            "iteration: 2 of max_iter: 20, perplexity: 3046.9132\n",
            "iteration: 3 of max_iter: 20, perplexity: 2405.7735\n",
            "iteration: 4 of max_iter: 20, perplexity: 1944.0845\n",
            "iteration: 5 of max_iter: 20, perplexity: 1666.7243\n",
            "iteration: 6 of max_iter: 20, perplexity: 1496.9990\n",
            "iteration: 7 of max_iter: 20, perplexity: 1389.5521\n",
            "iteration: 8 of max_iter: 20, perplexity: 1319.7267\n",
            "iteration: 9 of max_iter: 20, perplexity: 1272.9827\n",
            "iteration: 10 of max_iter: 20, perplexity: 1240.9397\n",
            "iteration: 11 of max_iter: 20, perplexity: 1218.7207\n",
            "iteration: 12 of max_iter: 20, perplexity: 1202.8198\n",
            "iteration: 13 of max_iter: 20, perplexity: 1191.1168\n",
            "iteration: 14 of max_iter: 20, perplexity: 1182.4300\n",
            "iteration: 15 of max_iter: 20, perplexity: 1175.8521\n",
            "iteration: 16 of max_iter: 20, perplexity: 1170.5613\n",
            "iteration: 17 of max_iter: 20, perplexity: 1166.2169\n",
            "iteration: 18 of max_iter: 20, perplexity: 1162.7005\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.8091\n",
            "iteration: 20 of max_iter: 20, perplexity: 1157.4728\n",
            "-- test perplexity: 1680.70\n",
            "---- 15 topics, alpha=0.5000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3748.2107\n",
            "iteration: 2 of max_iter: 20, perplexity: 3255.5304\n",
            "iteration: 3 of max_iter: 20, perplexity: 2542.6650\n",
            "iteration: 4 of max_iter: 20, perplexity: 2022.8469\n",
            "iteration: 5 of max_iter: 20, perplexity: 1714.1768\n",
            "iteration: 6 of max_iter: 20, perplexity: 1526.7284\n",
            "iteration: 7 of max_iter: 20, perplexity: 1408.6219\n",
            "iteration: 8 of max_iter: 20, perplexity: 1332.3125\n",
            "iteration: 9 of max_iter: 20, perplexity: 1281.4022\n",
            "iteration: 10 of max_iter: 20, perplexity: 1246.4811\n",
            "iteration: 11 of max_iter: 20, perplexity: 1222.3577\n",
            "iteration: 12 of max_iter: 20, perplexity: 1205.1572\n",
            "iteration: 13 of max_iter: 20, perplexity: 1192.5129\n",
            "iteration: 14 of max_iter: 20, perplexity: 1183.1536\n",
            "iteration: 15 of max_iter: 20, perplexity: 1176.0764\n",
            "iteration: 16 of max_iter: 20, perplexity: 1170.4001\n",
            "iteration: 17 of max_iter: 20, perplexity: 1165.7578\n",
            "iteration: 18 of max_iter: 20, perplexity: 1162.0001\n",
            "iteration: 19 of max_iter: 20, perplexity: 1158.9141\n",
            "iteration: 20 of max_iter: 20, perplexity: 1156.4657\n",
            "-- test perplexity: 1678.83\n",
            "---- 15 topics, alpha=0.5000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3185.2840\n",
            "iteration: 2 of max_iter: 20, perplexity: 2428.0304\n",
            "iteration: 3 of max_iter: 20, perplexity: 1956.0228\n",
            "iteration: 4 of max_iter: 20, perplexity: 1675.7162\n",
            "iteration: 5 of max_iter: 20, perplexity: 1506.3573\n",
            "iteration: 6 of max_iter: 20, perplexity: 1401.8123\n",
            "iteration: 7 of max_iter: 20, perplexity: 1334.9906\n",
            "iteration: 8 of max_iter: 20, perplexity: 1290.6330\n",
            "iteration: 9 of max_iter: 20, perplexity: 1259.5918\n",
            "iteration: 10 of max_iter: 20, perplexity: 1237.1413\n",
            "iteration: 11 of max_iter: 20, perplexity: 1220.5740\n",
            "iteration: 12 of max_iter: 20, perplexity: 1208.2931\n",
            "iteration: 13 of max_iter: 20, perplexity: 1199.1575\n",
            "iteration: 14 of max_iter: 20, perplexity: 1192.3060\n",
            "iteration: 15 of max_iter: 20, perplexity: 1186.9809\n",
            "iteration: 16 of max_iter: 20, perplexity: 1182.8335\n",
            "iteration: 17 of max_iter: 20, perplexity: 1179.3436\n",
            "iteration: 18 of max_iter: 20, perplexity: 1176.3288\n",
            "iteration: 19 of max_iter: 20, perplexity: 1173.6556\n",
            "iteration: 20 of max_iter: 20, perplexity: 1171.2812\n",
            "-- test perplexity: 1740.82\n",
            "---- 15 topics, alpha=0.4000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3305.9326\n",
            "iteration: 2 of max_iter: 20, perplexity: 2500.6212\n",
            "iteration: 3 of max_iter: 20, perplexity: 1996.1591\n",
            "iteration: 4 of max_iter: 20, perplexity: 1698.9987\n",
            "iteration: 5 of max_iter: 20, perplexity: 1519.9488\n",
            "iteration: 6 of max_iter: 20, perplexity: 1409.6842\n",
            "iteration: 7 of max_iter: 20, perplexity: 1339.3400\n",
            "iteration: 8 of max_iter: 20, perplexity: 1292.6889\n",
            "iteration: 9 of max_iter: 20, perplexity: 1260.0959\n",
            "iteration: 10 of max_iter: 20, perplexity: 1236.5994\n",
            "iteration: 11 of max_iter: 20, perplexity: 1219.2990\n",
            "iteration: 12 of max_iter: 20, perplexity: 1206.5339\n",
            "iteration: 13 of max_iter: 20, perplexity: 1197.0542\n",
            "iteration: 14 of max_iter: 20, perplexity: 1189.9457\n",
            "iteration: 15 of max_iter: 20, perplexity: 1184.4507\n",
            "iteration: 16 of max_iter: 20, perplexity: 1180.1974\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.6045\n",
            "iteration: 18 of max_iter: 20, perplexity: 1173.5232\n",
            "iteration: 19 of max_iter: 20, perplexity: 1170.8035\n",
            "iteration: 20 of max_iter: 20, perplexity: 1168.4166\n",
            "-- test perplexity: 1712.93\n",
            "---- 15 topics, alpha=0.4000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3536.3619\n",
            "iteration: 2 of max_iter: 20, perplexity: 2645.5694\n",
            "iteration: 3 of max_iter: 20, perplexity: 2077.5326\n",
            "iteration: 4 of max_iter: 20, perplexity: 1748.1364\n",
            "iteration: 5 of max_iter: 20, perplexity: 1550.5659\n",
            "iteration: 6 of max_iter: 20, perplexity: 1429.3875\n",
            "iteration: 7 of max_iter: 20, perplexity: 1352.4002\n",
            "iteration: 8 of max_iter: 20, perplexity: 1301.4506\n",
            "iteration: 9 of max_iter: 20, perplexity: 1266.0304\n",
            "iteration: 10 of max_iter: 20, perplexity: 1240.5842\n",
            "iteration: 11 of max_iter: 20, perplexity: 1221.9628\n",
            "iteration: 12 of max_iter: 20, perplexity: 1208.2691\n",
            "iteration: 13 of max_iter: 20, perplexity: 1198.0850\n",
            "iteration: 14 of max_iter: 20, perplexity: 1190.4391\n",
            "iteration: 15 of max_iter: 20, perplexity: 1184.4892\n",
            "iteration: 16 of max_iter: 20, perplexity: 1179.9118\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.0603\n",
            "iteration: 18 of max_iter: 20, perplexity: 1172.8007\n",
            "iteration: 19 of max_iter: 20, perplexity: 1169.9383\n",
            "iteration: 20 of max_iter: 20, perplexity: 1167.4387\n",
            "-- test perplexity: 1712.54\n",
            "---- 15 topics, alpha=0.4000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3635.6562\n",
            "iteration: 2 of max_iter: 20, perplexity: 3570.9613\n",
            "iteration: 3 of max_iter: 20, perplexity: 3353.1709\n",
            "iteration: 4 of max_iter: 20, perplexity: 2947.8152\n",
            "iteration: 5 of max_iter: 20, perplexity: 2489.5500\n",
            "iteration: 6 of max_iter: 20, perplexity: 2092.6671\n",
            "iteration: 7 of max_iter: 20, perplexity: 1800.3111\n",
            "iteration: 8 of max_iter: 20, perplexity: 1600.3473\n",
            "iteration: 9 of max_iter: 20, perplexity: 1467.1003\n",
            "iteration: 10 of max_iter: 20, perplexity: 1377.8161\n",
            "iteration: 11 of max_iter: 20, perplexity: 1316.5842\n",
            "iteration: 12 of max_iter: 20, perplexity: 1273.5605\n",
            "iteration: 13 of max_iter: 20, perplexity: 1242.9042\n",
            "iteration: 14 of max_iter: 20, perplexity: 1220.7288\n",
            "iteration: 15 of max_iter: 20, perplexity: 1204.5941\n",
            "iteration: 16 of max_iter: 20, perplexity: 1192.7610\n",
            "iteration: 17 of max_iter: 20, perplexity: 1183.8368\n",
            "iteration: 18 of max_iter: 20, perplexity: 1176.8644\n",
            "iteration: 19 of max_iter: 20, perplexity: 1171.2881\n",
            "iteration: 20 of max_iter: 20, perplexity: 1166.5880\n",
            "-- test perplexity: 1774.02\n",
            "---- 20 topics, alpha=0.6000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3825.6049\n",
            "iteration: 2 of max_iter: 20, perplexity: 3752.8866\n",
            "iteration: 3 of max_iter: 20, perplexity: 3504.5168\n",
            "iteration: 4 of max_iter: 20, perplexity: 3051.3339\n",
            "iteration: 5 of max_iter: 20, perplexity: 2554.5800\n",
            "iteration: 6 of max_iter: 20, perplexity: 2132.3856\n",
            "iteration: 7 of max_iter: 20, perplexity: 1824.3406\n",
            "iteration: 8 of max_iter: 20, perplexity: 1614.4114\n",
            "iteration: 9 of max_iter: 20, perplexity: 1474.8077\n",
            "iteration: 10 of max_iter: 20, perplexity: 1381.3895\n",
            "iteration: 11 of max_iter: 20, perplexity: 1317.4523\n",
            "iteration: 12 of max_iter: 20, perplexity: 1272.5527\n",
            "iteration: 13 of max_iter: 20, perplexity: 1240.6447\n",
            "iteration: 14 of max_iter: 20, perplexity: 1217.6064\n",
            "iteration: 15 of max_iter: 20, perplexity: 1200.8724\n",
            "iteration: 16 of max_iter: 20, perplexity: 1188.7255\n",
            "iteration: 17 of max_iter: 20, perplexity: 1179.6492\n",
            "iteration: 18 of max_iter: 20, perplexity: 1172.5210\n",
            "iteration: 19 of max_iter: 20, perplexity: 1166.8232\n",
            "iteration: 20 of max_iter: 20, perplexity: 1162.0327\n",
            "-- test perplexity: 1723.60\n",
            "---- 20 topics, alpha=0.6000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 4191.1189\n",
            "iteration: 2 of max_iter: 20, perplexity: 4105.7525\n",
            "iteration: 3 of max_iter: 20, perplexity: 3805.9271\n",
            "iteration: 4 of max_iter: 20, perplexity: 3262.1192\n",
            "iteration: 5 of max_iter: 20, perplexity: 2689.2618\n",
            "iteration: 6 of max_iter: 20, perplexity: 2216.7267\n",
            "iteration: 7 of max_iter: 20, perplexity: 1877.6556\n",
            "iteration: 8 of max_iter: 20, perplexity: 1648.2034\n",
            "iteration: 9 of max_iter: 20, perplexity: 1496.2049\n",
            "iteration: 10 of max_iter: 20, perplexity: 1394.8211\n",
            "iteration: 11 of max_iter: 20, perplexity: 1325.5793\n",
            "iteration: 12 of max_iter: 20, perplexity: 1277.0129\n",
            "iteration: 13 of max_iter: 20, perplexity: 1242.6908\n",
            "iteration: 14 of max_iter: 20, perplexity: 1217.9688\n",
            "iteration: 15 of max_iter: 20, perplexity: 1200.0474\n",
            "iteration: 16 of max_iter: 20, perplexity: 1187.0740\n",
            "iteration: 17 of max_iter: 20, perplexity: 1177.5517\n",
            "iteration: 18 of max_iter: 20, perplexity: 1170.1322\n",
            "iteration: 19 of max_iter: 20, perplexity: 1164.1746\n",
            "iteration: 20 of max_iter: 20, perplexity: 1159.2526\n",
            "-- test perplexity: 1698.81\n",
            "---- 20 topics, alpha=0.6000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 4090.0165\n",
            "iteration: 2 of max_iter: 20, perplexity: 3760.2852\n",
            "iteration: 3 of max_iter: 20, perplexity: 3011.9193\n",
            "iteration: 4 of max_iter: 20, perplexity: 2327.1324\n",
            "iteration: 5 of max_iter: 20, perplexity: 1892.3824\n",
            "iteration: 6 of max_iter: 20, perplexity: 1632.3654\n",
            "iteration: 7 of max_iter: 20, perplexity: 1475.3067\n",
            "iteration: 8 of max_iter: 20, perplexity: 1376.8550\n",
            "iteration: 9 of max_iter: 20, perplexity: 1312.7385\n",
            "iteration: 10 of max_iter: 20, perplexity: 1269.3570\n",
            "iteration: 11 of max_iter: 20, perplexity: 1239.2057\n",
            "iteration: 12 of max_iter: 20, perplexity: 1217.8248\n",
            "iteration: 13 of max_iter: 20, perplexity: 1202.6577\n",
            "iteration: 14 of max_iter: 20, perplexity: 1191.6393\n",
            "iteration: 15 of max_iter: 20, perplexity: 1183.7049\n",
            "iteration: 16 of max_iter: 20, perplexity: 1178.0616\n",
            "iteration: 17 of max_iter: 20, perplexity: 1174.0100\n",
            "iteration: 18 of max_iter: 20, perplexity: 1170.9841\n",
            "iteration: 19 of max_iter: 20, perplexity: 1168.4705\n",
            "iteration: 20 of max_iter: 20, perplexity: 1166.3539\n",
            "-- test perplexity: 1765.86\n",
            "---- 20 topics, alpha=0.5000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 4303.0584\n",
            "iteration: 2 of max_iter: 20, perplexity: 3945.6771\n",
            "iteration: 3 of max_iter: 20, perplexity: 3130.1013\n",
            "iteration: 4 of max_iter: 20, perplexity: 2389.4111\n",
            "iteration: 5 of max_iter: 20, perplexity: 1925.4973\n",
            "iteration: 6 of max_iter: 20, perplexity: 1650.0731\n",
            "iteration: 7 of max_iter: 20, perplexity: 1484.3594\n",
            "iteration: 8 of max_iter: 20, perplexity: 1380.8075\n",
            "iteration: 9 of max_iter: 20, perplexity: 1313.5008\n",
            "iteration: 10 of max_iter: 20, perplexity: 1268.0880\n",
            "iteration: 11 of max_iter: 20, perplexity: 1236.6074\n",
            "iteration: 12 of max_iter: 20, perplexity: 1214.3869\n",
            "iteration: 13 of max_iter: 20, perplexity: 1198.6798\n",
            "iteration: 14 of max_iter: 20, perplexity: 1187.3010\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.1031\n",
            "iteration: 16 of max_iter: 20, perplexity: 1173.2461\n",
            "iteration: 17 of max_iter: 20, perplexity: 1169.0288\n",
            "iteration: 18 of max_iter: 20, perplexity: 1165.8678\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic_word_prior \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.01\u001b[39m]:\n\u001b[1;32m      4\u001b[0m   lda \u001b[38;5;241m=\u001b[39m LatentDirichletAllocation(\n\u001b[1;32m      5\u001b[0m     n_components\u001b[38;5;241m=\u001b[39mn_components,\n\u001b[1;32m      6\u001b[0m     doc_topic_prior\u001b[38;5;241m=\u001b[39mdoc_topic_prior,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[1;32m     12\u001b[0m   )\n\u001b[0;32m---> 13\u001b[0m   lda\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-- test perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlda\u001b[38;5;241m.\u001b[39mperplexity(X_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m topics, alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_topic_prior\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eta=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic_word_prior\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:682\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_every \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m evaluate_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    679\u001b[0m     doc_topics_distr, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(\n\u001b[1;32m    680\u001b[0m         X, cal_sstats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, parallel\u001b[38;5;241m=\u001b[39mparallel\n\u001b[1;32m    681\u001b[0m     )\n\u001b[0;32m--> 682\u001b[0m     bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perplexity_precomp_distr(\n\u001b[1;32m    683\u001b[0m         X, doc_topics_distr, sub_sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m of max_iter: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, perplexity: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;241m%\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_iter, bound)\n\u001b[1;32m    689\u001b[0m         )\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:888\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._perplexity_precomp_distr\u001b[0;34m(self, X, doc_topic_distr, sub_sampling)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of topics does not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    887\u001b[0m current_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 888\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_approx_bound(X, doc_topic_distr, sub_sampling)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sub_sampling:\n\u001b[1;32m    891\u001b[0m     word_cnt \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_samples) \u001b[38;5;241m/\u001b[39m current_samples)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_lda.py:809\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._approx_bound\u001b[0;34m(self, X, doc_topic_distr, sub_sampling)\u001b[0m\n\u001b[1;32m    805\u001b[0m         cnts \u001b[38;5;241m=\u001b[39m X[idx_d, ids]\n\u001b[1;32m    806\u001b[0m     temp \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    807\u001b[0m         dirichlet_doc_topic[idx_d, :, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m+\u001b[39m dirichlet_component_[:, ids]\n\u001b[1;32m    808\u001b[0m     )\n\u001b[0;32m--> 809\u001b[0m     norm_phi \u001b[38;5;241m=\u001b[39m logsumexp(temp, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    810\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(cnts, norm_phi)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# compute E[log p(theta | alpha) - log q(theta | gamma)]\u001b[39;00m\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/scipy/special/_logsumexp.py:93\u001b[0m, in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_sign\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the log of the sum of exponentials of input elements.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     a \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         a, b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_arrays(a, b)\n",
            "File \u001b[0;32m~/_anaconda3/lib/python3.11/site-packages/scipy/_lib/_util.py:242\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    240\u001b[0m a \u001b[38;5;241m=\u001b[39m toarray(a)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m objects_ok:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject arrays are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_inexact:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for n_components in [15, 20, 25]:\n",
        "  for doc_topic_prior in [0.6, 0.5, 0.4]:\n",
        "    for topic_word_prior in [0.03, 0.02, 0.01]:\n",
        "      lda = LatentDirichletAllocation(\n",
        "        n_components=n_components,\n",
        "        doc_topic_prior=doc_topic_prior,\n",
        "        topic_word_prior=topic_word_prior,\n",
        "        max_iter=20,\n",
        "        evaluate_every=1,\n",
        "        verbose=1,\n",
        "        random_state=123,\n",
        "      )\n",
        "      lda.fit(X_train)\n",
        "      print(f\"-- test perplexity: {lda.perplexity(X_test):.2f}\")\n",
        "      print(f\"---- {n_components} topics, alpha={doc_topic_prior:.4f}, eta={topic_word_prior:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPnF2AqFNv9s"
      },
      "source": [
        "### 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2IzFjiQNv9s",
        "outputId": "02ab7373-fa4b-42a6-a269-21c65b9e4045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 20, perplexity: 2266.4164\n",
            "iteration: 2 of max_iter: 20, perplexity: 2244.5659\n",
            "iteration: 3 of max_iter: 20, perplexity: 2185.8426\n",
            "iteration: 4 of max_iter: 20, perplexity: 2059.9715\n",
            "iteration: 5 of max_iter: 20, perplexity: 1883.4189\n",
            "iteration: 6 of max_iter: 20, perplexity: 1708.4065\n",
            "iteration: 7 of max_iter: 20, perplexity: 1564.9912\n",
            "iteration: 8 of max_iter: 20, perplexity: 1457.6728\n",
            "iteration: 9 of max_iter: 20, perplexity: 1380.0627\n",
            "iteration: 10 of max_iter: 20, perplexity: 1324.0296\n",
            "iteration: 11 of max_iter: 20, perplexity: 1283.0956\n",
            "iteration: 12 of max_iter: 20, perplexity: 1252.4563\n",
            "iteration: 13 of max_iter: 20, perplexity: 1228.8534\n",
            "iteration: 14 of max_iter: 20, perplexity: 1210.3411\n",
            "iteration: 15 of max_iter: 20, perplexity: 1195.5801\n",
            "iteration: 16 of max_iter: 20, perplexity: 1183.6725\n",
            "iteration: 17 of max_iter: 20, perplexity: 1173.9410\n",
            "iteration: 18 of max_iter: 20, perplexity: 1165.9833\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.4936\n",
            "iteration: 20 of max_iter: 20, perplexity: 1154.2291\n",
            "-- test perplexity: 1677.59\n",
            "---- 10 topics, alpha=0.8000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 2325.3319\n",
            "iteration: 2 of max_iter: 20, perplexity: 2302.4873\n",
            "iteration: 3 of max_iter: 20, perplexity: 2240.5991\n",
            "iteration: 4 of max_iter: 20, perplexity: 2107.0748\n",
            "iteration: 5 of max_iter: 20, perplexity: 1919.9125\n",
            "iteration: 6 of max_iter: 20, perplexity: 1735.3981\n",
            "iteration: 7 of max_iter: 20, perplexity: 1584.6832\n",
            "iteration: 8 of max_iter: 20, perplexity: 1472.0139\n",
            "iteration: 9 of max_iter: 20, perplexity: 1390.5339\n",
            "iteration: 10 of max_iter: 20, perplexity: 1331.6804\n",
            "iteration: 11 of max_iter: 20, perplexity: 1288.6593\n",
            "iteration: 12 of max_iter: 20, perplexity: 1256.5226\n",
            "iteration: 13 of max_iter: 20, perplexity: 1231.7897\n",
            "iteration: 14 of max_iter: 20, perplexity: 1212.4555\n",
            "iteration: 15 of max_iter: 20, perplexity: 1197.0600\n",
            "iteration: 16 of max_iter: 20, perplexity: 1184.6465\n",
            "iteration: 17 of max_iter: 20, perplexity: 1174.5198\n",
            "iteration: 18 of max_iter: 20, perplexity: 1166.2466\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.5395\n",
            "iteration: 20 of max_iter: 20, perplexity: 1154.1382\n",
            "-- test perplexity: 1680.74\n",
            "---- 10 topics, alpha=0.8000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2434.3925\n",
            "iteration: 2 of max_iter: 20, perplexity: 2410.0060\n",
            "iteration: 3 of max_iter: 20, perplexity: 2343.3063\n",
            "iteration: 4 of max_iter: 20, perplexity: 2197.2609\n",
            "iteration: 5 of max_iter: 20, perplexity: 1991.0067\n",
            "iteration: 6 of max_iter: 20, perplexity: 1788.7537\n",
            "iteration: 7 of max_iter: 20, perplexity: 1624.3046\n",
            "iteration: 8 of max_iter: 20, perplexity: 1501.5850\n",
            "iteration: 9 of max_iter: 20, perplexity: 1412.8962\n",
            "iteration: 10 of max_iter: 20, perplexity: 1348.8292\n",
            "iteration: 11 of max_iter: 20, perplexity: 1301.9160\n",
            "iteration: 12 of max_iter: 20, perplexity: 1266.9890\n",
            "iteration: 13 of max_iter: 20, perplexity: 1240.1775\n",
            "iteration: 14 of max_iter: 20, perplexity: 1219.2992\n",
            "iteration: 15 of max_iter: 20, perplexity: 1202.7584\n",
            "iteration: 16 of max_iter: 20, perplexity: 1189.4302\n",
            "iteration: 17 of max_iter: 20, perplexity: 1178.5753\n",
            "iteration: 18 of max_iter: 20, perplexity: 1169.7105\n",
            "iteration: 19 of max_iter: 20, perplexity: 1162.5116\n",
            "iteration: 20 of max_iter: 20, perplexity: 1156.7219\n",
            "-- test perplexity: 1720.59\n",
            "---- 10 topics, alpha=0.8000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2379.4949\n",
            "iteration: 2 of max_iter: 20, perplexity: 2328.4465\n",
            "iteration: 3 of max_iter: 20, perplexity: 2192.1655\n",
            "iteration: 4 of max_iter: 20, perplexity: 1969.9853\n",
            "iteration: 5 of max_iter: 20, perplexity: 1748.9097\n",
            "iteration: 6 of max_iter: 20, perplexity: 1579.2755\n",
            "iteration: 7 of max_iter: 20, perplexity: 1460.3186\n",
            "iteration: 8 of max_iter: 20, perplexity: 1378.4626\n",
            "iteration: 9 of max_iter: 20, perplexity: 1321.2771\n",
            "iteration: 10 of max_iter: 20, perplexity: 1280.4583\n",
            "iteration: 11 of max_iter: 20, perplexity: 1250.2091\n",
            "iteration: 12 of max_iter: 20, perplexity: 1227.0062\n",
            "iteration: 13 of max_iter: 20, perplexity: 1209.0418\n",
            "iteration: 14 of max_iter: 20, perplexity: 1194.9768\n",
            "iteration: 15 of max_iter: 20, perplexity: 1183.8080\n",
            "iteration: 16 of max_iter: 20, perplexity: 1174.8067\n",
            "iteration: 17 of max_iter: 20, perplexity: 1167.4756\n",
            "iteration: 18 of max_iter: 20, perplexity: 1161.4069\n",
            "iteration: 19 of max_iter: 20, perplexity: 1156.2828\n",
            "iteration: 20 of max_iter: 20, perplexity: 1151.9347\n",
            "-- test perplexity: 1661.59\n",
            "---- 10 topics, alpha=0.7000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 2441.3113\n",
            "iteration: 2 of max_iter: 20, perplexity: 2388.2209\n",
            "iteration: 3 of max_iter: 20, perplexity: 2245.8787\n",
            "iteration: 4 of max_iter: 20, perplexity: 2012.1180\n",
            "iteration: 5 of max_iter: 20, perplexity: 1778.9844\n",
            "iteration: 6 of max_iter: 20, perplexity: 1600.3351\n",
            "iteration: 7 of max_iter: 20, perplexity: 1475.1295\n",
            "iteration: 8 of max_iter: 20, perplexity: 1389.0026\n",
            "iteration: 9 of max_iter: 20, perplexity: 1328.7955\n",
            "iteration: 10 of max_iter: 20, perplexity: 1285.8444\n",
            "iteration: 11 of max_iter: 20, perplexity: 1254.0907\n",
            "iteration: 12 of max_iter: 20, perplexity: 1229.7576\n",
            "iteration: 13 of max_iter: 20, perplexity: 1210.9689\n",
            "iteration: 14 of max_iter: 20, perplexity: 1196.2817\n",
            "iteration: 15 of max_iter: 20, perplexity: 1184.6273\n",
            "iteration: 16 of max_iter: 20, perplexity: 1175.2629\n",
            "iteration: 17 of max_iter: 20, perplexity: 1167.6714\n",
            "iteration: 18 of max_iter: 20, perplexity: 1161.3720\n",
            "iteration: 19 of max_iter: 20, perplexity: 1156.0558\n",
            "iteration: 20 of max_iter: 20, perplexity: 1151.5575\n",
            "-- test perplexity: 1662.37\n",
            "---- 10 topics, alpha=0.7000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2555.7703\n",
            "iteration: 2 of max_iter: 20, perplexity: 2499.4051\n",
            "iteration: 3 of max_iter: 20, perplexity: 2347.3867\n",
            "iteration: 4 of max_iter: 20, perplexity: 2093.6260\n",
            "iteration: 5 of max_iter: 20, perplexity: 1838.1499\n",
            "iteration: 6 of max_iter: 20, perplexity: 1642.5661\n",
            "iteration: 7 of max_iter: 20, perplexity: 1505.6183\n",
            "iteration: 8 of max_iter: 20, perplexity: 1411.5054\n",
            "iteration: 9 of max_iter: 20, perplexity: 1345.6734\n",
            "iteration: 10 of max_iter: 20, perplexity: 1298.7256\n",
            "iteration: 11 of max_iter: 20, perplexity: 1264.1769\n",
            "iteration: 12 of max_iter: 20, perplexity: 1237.7843\n",
            "iteration: 13 of max_iter: 20, perplexity: 1217.4673\n",
            "iteration: 14 of max_iter: 20, perplexity: 1201.6678\n",
            "iteration: 15 of max_iter: 20, perplexity: 1189.1191\n",
            "iteration: 16 of max_iter: 20, perplexity: 1179.0942\n",
            "iteration: 17 of max_iter: 20, perplexity: 1170.9770\n",
            "iteration: 18 of max_iter: 20, perplexity: 1164.2380\n",
            "iteration: 19 of max_iter: 20, perplexity: 1158.5653\n",
            "iteration: 20 of max_iter: 20, perplexity: 1153.8010\n",
            "-- test perplexity: 1696.94\n",
            "---- 10 topics, alpha=0.7000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2512.0826\n",
            "iteration: 2 of max_iter: 20, perplexity: 2358.9408\n",
            "iteration: 3 of max_iter: 20, perplexity: 2074.1850\n",
            "iteration: 4 of max_iter: 20, perplexity: 1794.5916\n",
            "iteration: 5 of max_iter: 20, perplexity: 1596.3893\n",
            "iteration: 6 of max_iter: 20, perplexity: 1466.3937\n",
            "iteration: 7 of max_iter: 20, perplexity: 1380.5140\n",
            "iteration: 8 of max_iter: 20, perplexity: 1321.9803\n",
            "iteration: 9 of max_iter: 20, perplexity: 1280.9691\n",
            "iteration: 10 of max_iter: 20, perplexity: 1251.1337\n",
            "iteration: 11 of max_iter: 20, perplexity: 1228.8186\n",
            "iteration: 12 of max_iter: 20, perplexity: 1211.7022\n",
            "iteration: 13 of max_iter: 20, perplexity: 1198.3529\n",
            "iteration: 14 of max_iter: 20, perplexity: 1187.8114\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.2411\n",
            "iteration: 16 of max_iter: 20, perplexity: 1172.2718\n",
            "iteration: 17 of max_iter: 20, perplexity: 1166.5043\n",
            "iteration: 18 of max_iter: 20, perplexity: 1161.6908\n",
            "iteration: 19 of max_iter: 20, perplexity: 1157.7319\n",
            "iteration: 20 of max_iter: 20, perplexity: 1154.3644\n",
            "-- test perplexity: 1659.87\n",
            "---- 10 topics, alpha=0.6000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 2577.2362\n",
            "iteration: 2 of max_iter: 20, perplexity: 2418.7746\n",
            "iteration: 3 of max_iter: 20, perplexity: 2122.4509\n",
            "iteration: 4 of max_iter: 20, perplexity: 1828.0670\n",
            "iteration: 5 of max_iter: 20, perplexity: 1618.8317\n",
            "iteration: 6 of max_iter: 20, perplexity: 1481.6445\n",
            "iteration: 7 of max_iter: 20, perplexity: 1391.1055\n",
            "iteration: 8 of max_iter: 20, perplexity: 1329.3908\n",
            "iteration: 9 of max_iter: 20, perplexity: 1286.1861\n",
            "iteration: 10 of max_iter: 20, perplexity: 1254.8181\n",
            "iteration: 11 of max_iter: 20, perplexity: 1231.4215\n",
            "iteration: 12 of max_iter: 20, perplexity: 1213.5080\n",
            "iteration: 13 of max_iter: 20, perplexity: 1199.5573\n",
            "iteration: 14 of max_iter: 20, perplexity: 1188.5635\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.6289\n",
            "iteration: 16 of max_iter: 20, perplexity: 1172.3815\n",
            "iteration: 17 of max_iter: 20, perplexity: 1166.4133\n",
            "iteration: 18 of max_iter: 20, perplexity: 1161.4361\n",
            "iteration: 19 of max_iter: 20, perplexity: 1157.3546\n",
            "iteration: 20 of max_iter: 20, perplexity: 1153.8902\n",
            "-- test perplexity: 1659.36\n",
            "---- 10 topics, alpha=0.6000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2697.9535\n",
            "iteration: 2 of max_iter: 20, perplexity: 2530.5929\n",
            "iteration: 3 of max_iter: 20, perplexity: 2214.8839\n",
            "iteration: 4 of max_iter: 20, perplexity: 1893.6608\n",
            "iteration: 5 of max_iter: 20, perplexity: 1663.7252\n",
            "iteration: 6 of max_iter: 20, perplexity: 1513.0035\n",
            "iteration: 7 of max_iter: 20, perplexity: 1413.7533\n",
            "iteration: 8 of max_iter: 20, perplexity: 1346.1223\n",
            "iteration: 9 of max_iter: 20, perplexity: 1298.8582\n",
            "iteration: 10 of max_iter: 20, perplexity: 1264.6324\n",
            "iteration: 11 of max_iter: 20, perplexity: 1239.2239\n",
            "iteration: 12 of max_iter: 20, perplexity: 1219.8125\n",
            "iteration: 13 of max_iter: 20, perplexity: 1204.7373\n",
            "iteration: 14 of max_iter: 20, perplexity: 1192.9018\n",
            "iteration: 15 of max_iter: 20, perplexity: 1183.2966\n",
            "iteration: 16 of max_iter: 20, perplexity: 1175.5464\n",
            "iteration: 17 of max_iter: 20, perplexity: 1169.1643\n",
            "iteration: 18 of max_iter: 20, perplexity: 1163.8461\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.4988\n",
            "iteration: 20 of max_iter: 20, perplexity: 1155.8341\n",
            "-- test perplexity: 1691.04\n",
            "---- 10 topics, alpha=0.6000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2685.9423\n",
            "iteration: 2 of max_iter: 20, perplexity: 2669.8754\n",
            "iteration: 3 of max_iter: 20, perplexity: 2624.5045\n",
            "iteration: 4 of max_iter: 20, perplexity: 2522.2575\n",
            "iteration: 5 of max_iter: 20, perplexity: 2367.1592\n",
            "iteration: 6 of max_iter: 20, perplexity: 2179.1970\n",
            "iteration: 7 of max_iter: 20, perplexity: 1980.0753\n",
            "iteration: 8 of max_iter: 20, perplexity: 1795.1006\n",
            "iteration: 9 of max_iter: 20, perplexity: 1640.5776\n",
            "iteration: 10 of max_iter: 20, perplexity: 1518.8045\n",
            "iteration: 11 of max_iter: 20, perplexity: 1426.1478\n",
            "iteration: 12 of max_iter: 20, perplexity: 1356.5361\n",
            "iteration: 13 of max_iter: 20, perplexity: 1304.6918\n",
            "iteration: 14 of max_iter: 20, perplexity: 1265.6811\n",
            "iteration: 15 of max_iter: 20, perplexity: 1236.1034\n",
            "iteration: 16 of max_iter: 20, perplexity: 1213.8726\n",
            "iteration: 17 of max_iter: 20, perplexity: 1197.1743\n",
            "iteration: 18 of max_iter: 20, perplexity: 1184.6814\n",
            "iteration: 19 of max_iter: 20, perplexity: 1175.2261\n",
            "iteration: 20 of max_iter: 20, perplexity: 1167.9862\n",
            "-- test perplexity: 1761.59\n",
            "---- 15 topics, alpha=0.8000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 2791.0085\n",
            "iteration: 2 of max_iter: 20, perplexity: 2773.3458\n",
            "iteration: 3 of max_iter: 20, perplexity: 2721.8965\n",
            "iteration: 4 of max_iter: 20, perplexity: 2604.9586\n",
            "iteration: 5 of max_iter: 20, perplexity: 2431.7250\n",
            "iteration: 6 of max_iter: 20, perplexity: 2227.4874\n",
            "iteration: 7 of max_iter: 20, perplexity: 2015.3064\n",
            "iteration: 8 of max_iter: 20, perplexity: 1820.4414\n",
            "iteration: 9 of max_iter: 20, perplexity: 1658.6248\n",
            "iteration: 10 of max_iter: 20, perplexity: 1531.3824\n",
            "iteration: 11 of max_iter: 20, perplexity: 1434.6932\n",
            "iteration: 12 of max_iter: 20, perplexity: 1362.0678\n",
            "iteration: 13 of max_iter: 20, perplexity: 1308.0334\n",
            "iteration: 14 of max_iter: 20, perplexity: 1267.3989\n",
            "iteration: 15 of max_iter: 20, perplexity: 1236.5894\n",
            "iteration: 16 of max_iter: 20, perplexity: 1213.4590\n",
            "iteration: 17 of max_iter: 20, perplexity: 1196.0968\n",
            "iteration: 18 of max_iter: 20, perplexity: 1183.1370\n",
            "iteration: 19 of max_iter: 20, perplexity: 1173.3516\n",
            "iteration: 20 of max_iter: 20, perplexity: 1165.8507\n",
            "-- test perplexity: 1741.14\n",
            "---- 15 topics, alpha=0.8000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 2989.2621\n",
            "iteration: 2 of max_iter: 20, perplexity: 2969.2053\n",
            "iteration: 3 of max_iter: 20, perplexity: 2908.5147\n",
            "iteration: 4 of max_iter: 20, perplexity: 2766.5728\n",
            "iteration: 5 of max_iter: 20, perplexity: 2560.0446\n",
            "iteration: 6 of max_iter: 20, perplexity: 2325.0112\n",
            "iteration: 7 of max_iter: 20, perplexity: 2087.7126\n",
            "iteration: 8 of max_iter: 20, perplexity: 1873.5650\n",
            "iteration: 9 of max_iter: 20, perplexity: 1697.5873\n",
            "iteration: 10 of max_iter: 20, perplexity: 1559.7772\n",
            "iteration: 11 of max_iter: 20, perplexity: 1455.3633\n",
            "iteration: 12 of max_iter: 20, perplexity: 1377.0623\n",
            "iteration: 13 of max_iter: 20, perplexity: 1318.9000\n",
            "iteration: 14 of max_iter: 20, perplexity: 1275.2290\n",
            "iteration: 15 of max_iter: 20, perplexity: 1242.1495\n",
            "iteration: 16 of max_iter: 20, perplexity: 1217.3047\n",
            "iteration: 17 of max_iter: 20, perplexity: 1198.6432\n",
            "iteration: 18 of max_iter: 20, perplexity: 1184.7106\n",
            "iteration: 19 of max_iter: 20, perplexity: 1174.2494\n",
            "iteration: 20 of max_iter: 20, perplexity: 1166.1995\n",
            "-- test perplexity: 1756.01\n",
            "---- 15 topics, alpha=0.8000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 2863.4971\n",
            "iteration: 2 of max_iter: 20, perplexity: 2833.8335\n",
            "iteration: 3 of max_iter: 20, perplexity: 2742.9218\n",
            "iteration: 4 of max_iter: 20, perplexity: 2543.7046\n",
            "iteration: 5 of max_iter: 20, perplexity: 2270.7945\n",
            "iteration: 6 of max_iter: 20, perplexity: 1995.4106\n",
            "iteration: 7 of max_iter: 20, perplexity: 1766.7260\n",
            "iteration: 8 of max_iter: 20, perplexity: 1595.1888\n",
            "iteration: 9 of max_iter: 20, perplexity: 1471.3353\n",
            "iteration: 10 of max_iter: 20, perplexity: 1382.9065\n",
            "iteration: 11 of max_iter: 20, perplexity: 1319.9452\n",
            "iteration: 12 of max_iter: 20, perplexity: 1274.6783\n",
            "iteration: 13 of max_iter: 20, perplexity: 1241.4503\n",
            "iteration: 14 of max_iter: 20, perplexity: 1217.1836\n",
            "iteration: 15 of max_iter: 20, perplexity: 1199.4527\n",
            "iteration: 16 of max_iter: 20, perplexity: 1186.4133\n",
            "iteration: 17 of max_iter: 20, perplexity: 1176.6143\n",
            "iteration: 18 of max_iter: 20, perplexity: 1169.1307\n",
            "iteration: 19 of max_iter: 20, perplexity: 1163.2960\n",
            "iteration: 20 of max_iter: 20, perplexity: 1158.7066\n",
            "-- test perplexity: 1720.85\n",
            "---- 15 topics, alpha=0.7000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 2975.4632\n",
            "iteration: 2 of max_iter: 20, perplexity: 2943.2197\n",
            "iteration: 3 of max_iter: 20, perplexity: 2842.5212\n",
            "iteration: 4 of max_iter: 20, perplexity: 2622.2117\n",
            "iteration: 5 of max_iter: 20, perplexity: 2326.6604\n",
            "iteration: 6 of max_iter: 20, perplexity: 2033.5521\n",
            "iteration: 7 of max_iter: 20, perplexity: 1792.3718\n",
            "iteration: 8 of max_iter: 20, perplexity: 1612.3304\n",
            "iteration: 9 of max_iter: 20, perplexity: 1482.5193\n",
            "iteration: 10 of max_iter: 20, perplexity: 1389.9691\n",
            "iteration: 11 of max_iter: 20, perplexity: 1324.1364\n",
            "iteration: 12 of max_iter: 20, perplexity: 1276.9311\n",
            "iteration: 13 of max_iter: 20, perplexity: 1242.2660\n",
            "iteration: 14 of max_iter: 20, perplexity: 1216.8926\n",
            "iteration: 15 of max_iter: 20, perplexity: 1198.4028\n",
            "iteration: 16 of max_iter: 20, perplexity: 1184.7738\n",
            "iteration: 17 of max_iter: 20, perplexity: 1174.5272\n",
            "iteration: 18 of max_iter: 20, perplexity: 1166.7366\n",
            "iteration: 19 of max_iter: 20, perplexity: 1160.6798\n",
            "iteration: 20 of max_iter: 20, perplexity: 1155.9408\n",
            "-- test perplexity: 1695.53\n",
            "---- 15 topics, alpha=0.7000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3186.7687\n",
            "iteration: 2 of max_iter: 20, perplexity: 3150.5743\n",
            "iteration: 3 of max_iter: 20, perplexity: 3034.6150\n",
            "iteration: 4 of max_iter: 20, perplexity: 2777.2385\n",
            "iteration: 5 of max_iter: 20, perplexity: 2438.8839\n",
            "iteration: 6 of max_iter: 20, perplexity: 2111.5299\n",
            "iteration: 7 of max_iter: 20, perplexity: 1846.0866\n",
            "iteration: 8 of max_iter: 20, perplexity: 1649.6208\n",
            "iteration: 9 of max_iter: 20, perplexity: 1508.4023\n",
            "iteration: 10 of max_iter: 20, perplexity: 1408.0426\n",
            "iteration: 11 of max_iter: 20, perplexity: 1336.7578\n",
            "iteration: 12 of max_iter: 20, perplexity: 1285.8610\n",
            "iteration: 13 of max_iter: 20, perplexity: 1248.4601\n",
            "iteration: 14 of max_iter: 20, perplexity: 1221.0462\n",
            "iteration: 15 of max_iter: 20, perplexity: 1201.1217\n",
            "iteration: 16 of max_iter: 20, perplexity: 1186.4373\n",
            "iteration: 17 of max_iter: 20, perplexity: 1175.4118\n",
            "iteration: 18 of max_iter: 20, perplexity: 1167.0282\n",
            "iteration: 19 of max_iter: 20, perplexity: 1160.5484\n",
            "iteration: 20 of max_iter: 20, perplexity: 1155.4820\n",
            "-- test perplexity: 1700.89\n",
            "---- 15 topics, alpha=0.7000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3100.8906\n",
            "iteration: 2 of max_iter: 20, perplexity: 3014.2460\n",
            "iteration: 3 of max_iter: 20, perplexity: 2749.3072\n",
            "iteration: 4 of max_iter: 20, perplexity: 2337.7289\n",
            "iteration: 5 of max_iter: 20, perplexity: 1970.2551\n",
            "iteration: 6 of max_iter: 20, perplexity: 1710.4167\n",
            "iteration: 7 of max_iter: 20, perplexity: 1536.7093\n",
            "iteration: 8 of max_iter: 20, perplexity: 1420.4502\n",
            "iteration: 9 of max_iter: 20, perplexity: 1341.8394\n",
            "iteration: 10 of max_iter: 20, perplexity: 1288.1176\n",
            "iteration: 11 of max_iter: 20, perplexity: 1250.4483\n",
            "iteration: 12 of max_iter: 20, perplexity: 1223.6283\n",
            "iteration: 13 of max_iter: 20, perplexity: 1204.4556\n",
            "iteration: 14 of max_iter: 20, perplexity: 1190.7195\n",
            "iteration: 15 of max_iter: 20, perplexity: 1180.8077\n",
            "iteration: 16 of max_iter: 20, perplexity: 1173.3452\n",
            "iteration: 17 of max_iter: 20, perplexity: 1167.6131\n",
            "iteration: 18 of max_iter: 20, perplexity: 1163.0610\n",
            "iteration: 19 of max_iter: 20, perplexity: 1159.2964\n",
            "iteration: 20 of max_iter: 20, perplexity: 1156.1809\n",
            "-- test perplexity: 1702.05\n",
            "---- 15 topics, alpha=0.6000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3222.0155\n",
            "iteration: 2 of max_iter: 20, perplexity: 3129.3457\n",
            "iteration: 3 of max_iter: 20, perplexity: 2844.2119\n",
            "iteration: 4 of max_iter: 20, perplexity: 2401.5333\n",
            "iteration: 5 of max_iter: 20, perplexity: 2010.1172\n",
            "iteration: 6 of max_iter: 20, perplexity: 1735.2766\n",
            "iteration: 7 of max_iter: 20, perplexity: 1552.1868\n",
            "iteration: 8 of max_iter: 20, perplexity: 1429.9400\n",
            "iteration: 9 of max_iter: 20, perplexity: 1347.3862\n",
            "iteration: 10 of max_iter: 20, perplexity: 1291.1020\n",
            "iteration: 11 of max_iter: 20, perplexity: 1251.6732\n",
            "iteration: 12 of max_iter: 20, perplexity: 1223.5859\n",
            "iteration: 13 of max_iter: 20, perplexity: 1203.5779\n",
            "iteration: 14 of max_iter: 20, perplexity: 1189.2374\n",
            "iteration: 15 of max_iter: 20, perplexity: 1178.8540\n",
            "iteration: 16 of max_iter: 20, perplexity: 1171.0065\n",
            "iteration: 17 of max_iter: 20, perplexity: 1165.0001\n",
            "iteration: 18 of max_iter: 20, perplexity: 1160.2505\n",
            "iteration: 19 of max_iter: 20, perplexity: 1156.3157\n",
            "iteration: 20 of max_iter: 20, perplexity: 1153.0781\n",
            "-- test perplexity: 1673.88\n",
            "---- 15 topics, alpha=0.6000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3450.6931\n",
            "iteration: 2 of max_iter: 20, perplexity: 3348.3942\n",
            "iteration: 3 of max_iter: 20, perplexity: 3029.6640\n",
            "iteration: 4 of max_iter: 20, perplexity: 2529.1084\n",
            "iteration: 5 of max_iter: 20, perplexity: 2091.2587\n",
            "iteration: 6 of max_iter: 20, perplexity: 1787.3354\n",
            "iteration: 7 of max_iter: 20, perplexity: 1586.2671\n",
            "iteration: 8 of max_iter: 20, perplexity: 1452.5745\n",
            "iteration: 9 of max_iter: 20, perplexity: 1362.5142\n",
            "iteration: 10 of max_iter: 20, perplexity: 1301.4001\n",
            "iteration: 11 of max_iter: 20, perplexity: 1258.7277\n",
            "iteration: 12 of max_iter: 20, perplexity: 1228.2618\n",
            "iteration: 13 of max_iter: 20, perplexity: 1206.6382\n",
            "iteration: 14 of max_iter: 20, perplexity: 1191.1201\n",
            "iteration: 15 of max_iter: 20, perplexity: 1179.9104\n",
            "iteration: 16 of max_iter: 20, perplexity: 1171.4288\n",
            "iteration: 17 of max_iter: 20, perplexity: 1164.9619\n",
            "iteration: 18 of max_iter: 20, perplexity: 1159.8684\n",
            "iteration: 19 of max_iter: 20, perplexity: 1155.6552\n",
            "iteration: 20 of max_iter: 20, perplexity: 1152.1465\n",
            "-- test perplexity: 1674.08\n",
            "---- 15 topics, alpha=0.6000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3073.9813\n",
            "iteration: 2 of max_iter: 20, perplexity: 3053.3107\n",
            "iteration: 3 of max_iter: 20, perplexity: 2989.4185\n",
            "iteration: 4 of max_iter: 20, perplexity: 2862.4833\n",
            "iteration: 5 of max_iter: 20, perplexity: 2704.4423\n",
            "iteration: 6 of max_iter: 20, perplexity: 2535.2334\n",
            "iteration: 7 of max_iter: 20, perplexity: 2356.7764\n",
            "iteration: 8 of max_iter: 20, perplexity: 2171.1169\n",
            "iteration: 9 of max_iter: 20, perplexity: 1986.1838\n",
            "iteration: 10 of max_iter: 20, perplexity: 1814.1053\n",
            "iteration: 11 of max_iter: 20, perplexity: 1666.0939\n",
            "iteration: 12 of max_iter: 20, perplexity: 1547.1047\n",
            "iteration: 13 of max_iter: 20, perplexity: 1455.0200\n",
            "iteration: 14 of max_iter: 20, perplexity: 1384.8940\n",
            "iteration: 15 of max_iter: 20, perplexity: 1332.0308\n",
            "iteration: 16 of max_iter: 20, perplexity: 1291.6931\n",
            "iteration: 17 of max_iter: 20, perplexity: 1260.3796\n",
            "iteration: 18 of max_iter: 20, perplexity: 1236.0493\n",
            "iteration: 19 of max_iter: 20, perplexity: 1217.2839\n",
            "iteration: 20 of max_iter: 20, perplexity: 1202.8685\n",
            "-- test perplexity: 1920.67\n",
            "---- 20 topics, alpha=0.8000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3234.7544\n",
            "iteration: 2 of max_iter: 20, perplexity: 3210.8050\n",
            "iteration: 3 of max_iter: 20, perplexity: 3133.6358\n",
            "iteration: 4 of max_iter: 20, perplexity: 2980.3148\n",
            "iteration: 5 of max_iter: 20, perplexity: 2795.7716\n",
            "iteration: 6 of max_iter: 20, perplexity: 2604.6222\n",
            "iteration: 7 of max_iter: 20, perplexity: 2408.6403\n",
            "iteration: 8 of max_iter: 20, perplexity: 2209.2946\n",
            "iteration: 9 of max_iter: 20, perplexity: 2013.7706\n",
            "iteration: 10 of max_iter: 20, perplexity: 1833.6749\n",
            "iteration: 11 of max_iter: 20, perplexity: 1679.5670\n",
            "iteration: 12 of max_iter: 20, perplexity: 1556.0469\n",
            "iteration: 13 of max_iter: 20, perplexity: 1460.4648\n",
            "iteration: 14 of max_iter: 20, perplexity: 1387.6444\n",
            "iteration: 15 of max_iter: 20, perplexity: 1332.7842\n",
            "iteration: 16 of max_iter: 20, perplexity: 1290.9820\n",
            "iteration: 17 of max_iter: 20, perplexity: 1258.5505\n",
            "iteration: 18 of max_iter: 20, perplexity: 1233.3809\n",
            "iteration: 19 of max_iter: 20, perplexity: 1213.9999\n",
            "iteration: 20 of max_iter: 20, perplexity: 1199.0749\n",
            "-- test perplexity: 1882.80\n",
            "---- 20 topics, alpha=0.8000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3544.0119\n",
            "iteration: 2 of max_iter: 20, perplexity: 3515.0288\n",
            "iteration: 3 of max_iter: 20, perplexity: 3416.2793\n",
            "iteration: 4 of max_iter: 20, perplexity: 3214.9053\n",
            "iteration: 5 of max_iter: 20, perplexity: 2980.0725\n",
            "iteration: 6 of max_iter: 20, perplexity: 2746.8648\n",
            "iteration: 7 of max_iter: 20, perplexity: 2517.1181\n",
            "iteration: 8 of max_iter: 20, perplexity: 2291.1771\n",
            "iteration: 9 of max_iter: 20, perplexity: 2074.8807\n",
            "iteration: 10 of max_iter: 20, perplexity: 1878.8795\n",
            "iteration: 11 of max_iter: 20, perplexity: 1712.5301\n",
            "iteration: 12 of max_iter: 20, perplexity: 1579.8492\n",
            "iteration: 13 of max_iter: 20, perplexity: 1477.4496\n",
            "iteration: 14 of max_iter: 20, perplexity: 1399.4331\n",
            "iteration: 15 of max_iter: 20, perplexity: 1340.7564\n",
            "iteration: 16 of max_iter: 20, perplexity: 1296.1375\n",
            "iteration: 17 of max_iter: 20, perplexity: 1261.5256\n",
            "iteration: 18 of max_iter: 20, perplexity: 1234.6990\n",
            "iteration: 19 of max_iter: 20, perplexity: 1214.0747\n",
            "iteration: 20 of max_iter: 20, perplexity: 1198.1486\n",
            "-- test perplexity: 1886.01\n",
            "---- 20 topics, alpha=0.8000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3308.5659\n",
            "iteration: 2 of max_iter: 20, perplexity: 3277.5301\n",
            "iteration: 3 of max_iter: 20, perplexity: 3179.1504\n",
            "iteration: 4 of max_iter: 20, perplexity: 2984.4921\n",
            "iteration: 5 of max_iter: 20, perplexity: 2735.2191\n",
            "iteration: 6 of max_iter: 20, perplexity: 2458.9597\n",
            "iteration: 7 of max_iter: 20, perplexity: 2180.8457\n",
            "iteration: 8 of max_iter: 20, perplexity: 1930.1357\n",
            "iteration: 9 of max_iter: 20, perplexity: 1726.4449\n",
            "iteration: 10 of max_iter: 20, perplexity: 1572.6408\n",
            "iteration: 11 of max_iter: 20, perplexity: 1461.5641\n",
            "iteration: 12 of max_iter: 20, perplexity: 1382.1216\n",
            "iteration: 13 of max_iter: 20, perplexity: 1324.7770\n",
            "iteration: 14 of max_iter: 20, perplexity: 1282.3842\n",
            "iteration: 15 of max_iter: 20, perplexity: 1250.7287\n",
            "iteration: 16 of max_iter: 20, perplexity: 1227.1167\n",
            "iteration: 17 of max_iter: 20, perplexity: 1209.3922\n",
            "iteration: 18 of max_iter: 20, perplexity: 1196.3103\n",
            "iteration: 19 of max_iter: 20, perplexity: 1186.6886\n",
            "iteration: 20 of max_iter: 20, perplexity: 1179.3210\n",
            "-- test perplexity: 1821.69\n",
            "---- 20 topics, alpha=0.7000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3481.5514\n",
            "iteration: 2 of max_iter: 20, perplexity: 3445.9889\n",
            "iteration: 3 of max_iter: 20, perplexity: 3329.4538\n",
            "iteration: 4 of max_iter: 20, perplexity: 3101.0722\n",
            "iteration: 5 of max_iter: 20, perplexity: 2819.6205\n",
            "iteration: 6 of max_iter: 20, perplexity: 2518.0410\n",
            "iteration: 7 of max_iter: 20, perplexity: 2221.2366\n",
            "iteration: 8 of max_iter: 20, perplexity: 1957.2536\n",
            "iteration: 9 of max_iter: 20, perplexity: 1744.2392\n",
            "iteration: 10 of max_iter: 20, perplexity: 1583.8165\n",
            "iteration: 11 of max_iter: 20, perplexity: 1468.1330\n",
            "iteration: 12 of max_iter: 20, perplexity: 1385.3771\n",
            "iteration: 13 of max_iter: 20, perplexity: 1325.6978\n",
            "iteration: 14 of max_iter: 20, perplexity: 1281.6496\n",
            "iteration: 15 of max_iter: 20, perplexity: 1248.8005\n",
            "iteration: 16 of max_iter: 20, perplexity: 1224.3747\n",
            "iteration: 17 of max_iter: 20, perplexity: 1206.0116\n",
            "iteration: 18 of max_iter: 20, perplexity: 1192.4303\n",
            "iteration: 19 of max_iter: 20, perplexity: 1182.3966\n",
            "iteration: 20 of max_iter: 20, perplexity: 1174.7467\n",
            "-- test perplexity: 1774.90\n",
            "---- 20 topics, alpha=0.7000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 3814.3385\n",
            "iteration: 2 of max_iter: 20, perplexity: 3771.7712\n",
            "iteration: 3 of max_iter: 20, perplexity: 3625.5127\n",
            "iteration: 4 of max_iter: 20, perplexity: 3335.2133\n",
            "iteration: 5 of max_iter: 20, perplexity: 2992.0410\n",
            "iteration: 6 of max_iter: 20, perplexity: 2641.0800\n",
            "iteration: 7 of max_iter: 20, perplexity: 2307.3531\n",
            "iteration: 8 of max_iter: 20, perplexity: 2017.0013\n",
            "iteration: 9 of max_iter: 20, perplexity: 1785.5074\n",
            "iteration: 10 of max_iter: 20, perplexity: 1611.9803\n",
            "iteration: 11 of max_iter: 20, perplexity: 1487.1470\n",
            "iteration: 12 of max_iter: 20, perplexity: 1397.9806\n",
            "iteration: 13 of max_iter: 20, perplexity: 1333.8513\n",
            "iteration: 14 of max_iter: 20, perplexity: 1286.6219\n",
            "iteration: 15 of max_iter: 20, perplexity: 1251.4990\n",
            "iteration: 16 of max_iter: 20, perplexity: 1225.4597\n",
            "iteration: 17 of max_iter: 20, perplexity: 1205.8916\n",
            "iteration: 18 of max_iter: 20, perplexity: 1191.3937\n",
            "iteration: 19 of max_iter: 20, perplexity: 1180.6564\n",
            "iteration: 20 of max_iter: 20, perplexity: 1172.4657\n",
            "-- test perplexity: 1758.47\n",
            "---- 20 topics, alpha=0.7000, eta=0.0100\n",
            "iteration: 1 of max_iter: 20, perplexity: 3635.6562\n",
            "iteration: 2 of max_iter: 20, perplexity: 3570.9613\n",
            "iteration: 3 of max_iter: 20, perplexity: 3353.1709\n",
            "iteration: 4 of max_iter: 20, perplexity: 2947.8152\n",
            "iteration: 5 of max_iter: 20, perplexity: 2489.5500\n",
            "iteration: 6 of max_iter: 20, perplexity: 2092.6671\n",
            "iteration: 7 of max_iter: 20, perplexity: 1800.3111\n",
            "iteration: 8 of max_iter: 20, perplexity: 1600.3473\n",
            "iteration: 9 of max_iter: 20, perplexity: 1467.1003\n",
            "iteration: 10 of max_iter: 20, perplexity: 1377.8161\n",
            "iteration: 11 of max_iter: 20, perplexity: 1316.5842\n",
            "iteration: 12 of max_iter: 20, perplexity: 1273.5605\n",
            "iteration: 13 of max_iter: 20, perplexity: 1242.9042\n",
            "iteration: 14 of max_iter: 20, perplexity: 1220.7288\n",
            "iteration: 15 of max_iter: 20, perplexity: 1204.5941\n",
            "iteration: 16 of max_iter: 20, perplexity: 1192.7610\n",
            "iteration: 17 of max_iter: 20, perplexity: 1183.8368\n",
            "iteration: 18 of max_iter: 20, perplexity: 1176.8644\n",
            "iteration: 19 of max_iter: 20, perplexity: 1171.2881\n",
            "iteration: 20 of max_iter: 20, perplexity: 1166.5880\n",
            "-- test perplexity: 1774.02\n",
            "---- 20 topics, alpha=0.6000, eta=0.0300\n",
            "iteration: 1 of max_iter: 20, perplexity: 3825.6049\n",
            "iteration: 2 of max_iter: 20, perplexity: 3752.8866\n",
            "iteration: 3 of max_iter: 20, perplexity: 3504.5168\n",
            "iteration: 4 of max_iter: 20, perplexity: 3051.3339\n",
            "iteration: 5 of max_iter: 20, perplexity: 2554.5800\n",
            "iteration: 6 of max_iter: 20, perplexity: 2132.3856\n",
            "iteration: 7 of max_iter: 20, perplexity: 1824.3406\n",
            "iteration: 8 of max_iter: 20, perplexity: 1614.4114\n",
            "iteration: 9 of max_iter: 20, perplexity: 1474.8077\n",
            "iteration: 10 of max_iter: 20, perplexity: 1381.3895\n",
            "iteration: 11 of max_iter: 20, perplexity: 1317.4523\n",
            "iteration: 12 of max_iter: 20, perplexity: 1272.5527\n",
            "iteration: 13 of max_iter: 20, perplexity: 1240.6447\n",
            "iteration: 14 of max_iter: 20, perplexity: 1217.6064\n",
            "iteration: 15 of max_iter: 20, perplexity: 1200.8724\n",
            "iteration: 16 of max_iter: 20, perplexity: 1188.7255\n",
            "iteration: 17 of max_iter: 20, perplexity: 1179.6492\n",
            "iteration: 18 of max_iter: 20, perplexity: 1172.5210\n",
            "iteration: 19 of max_iter: 20, perplexity: 1166.8232\n",
            "iteration: 20 of max_iter: 20, perplexity: 1162.0327\n",
            "-- test perplexity: 1723.60\n",
            "---- 20 topics, alpha=0.6000, eta=0.0200\n",
            "iteration: 1 of max_iter: 20, perplexity: 4191.1189\n",
            "iteration: 2 of max_iter: 20, perplexity: 4105.7525\n",
            "iteration: 3 of max_iter: 20, perplexity: 3805.9271\n",
            "iteration: 4 of max_iter: 20, perplexity: 3262.1192\n",
            "iteration: 5 of max_iter: 20, perplexity: 2689.2618\n",
            "iteration: 6 of max_iter: 20, perplexity: 2216.7267\n",
            "iteration: 7 of max_iter: 20, perplexity: 1877.6556\n",
            "iteration: 8 of max_iter: 20, perplexity: 1648.2034\n",
            "iteration: 9 of max_iter: 20, perplexity: 1496.2049\n",
            "iteration: 10 of max_iter: 20, perplexity: 1394.8211\n",
            "iteration: 11 of max_iter: 20, perplexity: 1325.5793\n",
            "iteration: 12 of max_iter: 20, perplexity: 1277.0129\n",
            "iteration: 13 of max_iter: 20, perplexity: 1242.6908\n",
            "iteration: 14 of max_iter: 20, perplexity: 1217.9688\n",
            "iteration: 15 of max_iter: 20, perplexity: 1200.0474\n",
            "iteration: 16 of max_iter: 20, perplexity: 1187.0740\n",
            "iteration: 17 of max_iter: 20, perplexity: 1177.5517\n",
            "iteration: 18 of max_iter: 20, perplexity: 1170.1322\n",
            "iteration: 19 of max_iter: 20, perplexity: 1164.1746\n",
            "iteration: 20 of max_iter: 20, perplexity: 1159.2526\n",
            "-- test perplexity: 1698.81\n",
            "---- 20 topics, alpha=0.6000, eta=0.0100\n"
          ]
        }
      ],
      "source": [
        "for n_components in [10, 15, 20]:\n",
        "  for doc_topic_prior in [0.8, 0.7, 0.6]:\n",
        "    for topic_word_prior in [0.03, 0.02, 0.01]:\n",
        "      lda = LatentDirichletAllocation(\n",
        "        n_components=n_components,\n",
        "        doc_topic_prior=doc_topic_prior,\n",
        "        topic_word_prior=topic_word_prior,\n",
        "        max_iter=20,\n",
        "        evaluate_every=1,\n",
        "        verbose=1,\n",
        "        random_state=123,\n",
        "      )\n",
        "      lda.fit(X_train)\n",
        "      print(f\"-- test perplexity: {lda.perplexity(X_test):.2f}\")\n",
        "      print(f\"---- {n_components} topics, alpha={doc_topic_prior:.4f}, eta={topic_word_prior:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G37inpUqNv9s"
      },
      "source": [
        "## 最も良かった設定で改めて変分推論を実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIU_puXWNv9s"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)\n",
        "X = vectorizer.fit_transform(ds[\"train\"][\"title\"] + ds[\"test\"][\"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmSETnCzNv9s",
        "outputId": "2e46d978-16b7-4dbb-a9f9-fff8b5b199bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 50, perplexity: 3212.0452\n",
            "iteration: 2 of max_iter: 50, perplexity: 3116.1717\n",
            "iteration: 3 of max_iter: 50, perplexity: 2825.9628\n",
            "iteration: 4 of max_iter: 50, perplexity: 2385.6992\n",
            "iteration: 5 of max_iter: 50, perplexity: 2001.4003\n",
            "iteration: 6 of max_iter: 50, perplexity: 1732.1999\n",
            "iteration: 7 of max_iter: 50, perplexity: 1553.8136\n",
            "iteration: 8 of max_iter: 50, perplexity: 1436.3327\n",
            "iteration: 9 of max_iter: 50, perplexity: 1357.6988\n",
            "iteration: 10 of max_iter: 50, perplexity: 1303.5938\n",
            "iteration: 11 of max_iter: 50, perplexity: 1265.2954\n",
            "iteration: 12 of max_iter: 50, perplexity: 1237.3723\n",
            "iteration: 13 of max_iter: 50, perplexity: 1216.6442\n",
            "iteration: 14 of max_iter: 50, perplexity: 1201.1017\n",
            "iteration: 15 of max_iter: 50, perplexity: 1189.4617\n",
            "iteration: 16 of max_iter: 50, perplexity: 1180.6088\n",
            "iteration: 17 of max_iter: 50, perplexity: 1173.7038\n",
            "iteration: 18 of max_iter: 50, perplexity: 1168.3038\n",
            "iteration: 19 of max_iter: 50, perplexity: 1163.9205\n",
            "iteration: 20 of max_iter: 50, perplexity: 1160.3484\n",
            "iteration: 21 of max_iter: 50, perplexity: 1157.4298\n",
            "iteration: 22 of max_iter: 50, perplexity: 1155.0283\n",
            "iteration: 23 of max_iter: 50, perplexity: 1153.0702\n",
            "iteration: 24 of max_iter: 50, perplexity: 1151.4418\n",
            "iteration: 25 of max_iter: 50, perplexity: 1150.0450\n",
            "iteration: 26 of max_iter: 50, perplexity: 1148.7961\n",
            "iteration: 27 of max_iter: 50, perplexity: 1147.6395\n",
            "iteration: 28 of max_iter: 50, perplexity: 1146.7128\n",
            "iteration: 29 of max_iter: 50, perplexity: 1146.0396\n",
            "iteration: 30 of max_iter: 50, perplexity: 1145.5194\n",
            "iteration: 31 of max_iter: 50, perplexity: 1145.0720\n",
            "iteration: 32 of max_iter: 50, perplexity: 1144.6372\n",
            "iteration: 33 of max_iter: 50, perplexity: 1144.1936\n",
            "iteration: 34 of max_iter: 50, perplexity: 1143.7314\n",
            "iteration: 35 of max_iter: 50, perplexity: 1143.2849\n",
            "iteration: 36 of max_iter: 50, perplexity: 1142.8658\n",
            "iteration: 37 of max_iter: 50, perplexity: 1142.4911\n",
            "iteration: 38 of max_iter: 50, perplexity: 1142.1731\n",
            "iteration: 39 of max_iter: 50, perplexity: 1141.9215\n",
            "iteration: 40 of max_iter: 50, perplexity: 1141.7293\n",
            "iteration: 41 of max_iter: 50, perplexity: 1141.5834\n",
            "iteration: 42 of max_iter: 50, perplexity: 1141.4721\n",
            "iteration: 43 of max_iter: 50, perplexity: 1141.3877\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(doc_topic_prior=0.6, evaluate_every=1, max_iter=50,\n",
              "                          n_components=15, random_state=123,\n",
              "                          topic_word_prior=0.02, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(doc_topic_prior=0.6, evaluate_every=1, max_iter=50,\n",
              "                          n_components=15, random_state=123,\n",
              "                          topic_word_prior=0.02, verbose=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LatentDirichletAllocation(doc_topic_prior=0.6, evaluate_every=1, max_iter=50,\n",
              "                          n_components=15, random_state=123,\n",
              "                          topic_word_prior=0.02, verbose=1)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda = LatentDirichletAllocation(\n",
        "  n_components=15,\n",
        "  doc_topic_prior=0.6,\n",
        "  topic_word_prior=0.02,\n",
        "  max_iter=50,\n",
        "  evaluate_every=1,\n",
        "  verbose=1,\n",
        "  random_state=123,\n",
        ")\n",
        "lda.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* モデルを保存"
      ],
      "metadata": {
        "id": "mLNTEzdJOCS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDPziS_3Nv9s"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "outfile = \"lda_model.pk\"\n",
        "with open(outfile, 'wb') as pickle_file:\n",
        "  pickle.dump(lda, pickle_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Y82I77Nv9s"
      },
      "source": [
        "## 可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIL_sSsyNv9t"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "ds = load_dataset(\"CShorten/ML-ArXiv-Papers\")\n",
        "ds = ds[\"train\"].train_test_split(test_size=0.1, seed=1234)\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=\"english\", min_df=10)\n",
        "X = vectorizer.fit_transform(ds[\"train\"][\"title\"] + ds[\"test\"][\"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbATHJeDNv9t"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "outfile = \"lda_model.pk\"\n",
        "with open(outfile, \"rb\") as pickle_file:\n",
        "  lda_model = pickle.load(pickle_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pyLDAvisはあらかじめインストールしておく。"
      ],
      "metadata": {
        "id": "hzqtRHVtOEUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHaXwnCuNv9t",
        "outputId": "d4e45bfe-0b7f-4310-98f5-941242376233"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el4775713135100880484769392\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el4775713135100880484769392_data = {\"mdsDat\": {\"x\": [0.15424362883091197, 0.12400663668830521, -0.2074190035720894, -0.10850773396674483, 0.3732554314681667, 0.41406979810083544, 0.14151852600130443, -0.28690204927658436, -0.47287755502625534, 0.3468345263501632, 0.4863130079789284, -0.12729695114112033, -0.4704499640839521, -0.3532912109804888, -0.013497087371380587], \"y\": [0.05366620941492175, -0.3302547530148887, -0.16942848831955623, 0.46902175285946984, -0.3568962035838024, -0.12910261121357117, 0.4643227465287762, -0.4126652202464424, 0.10971482148143107, 0.3286038246511122, 0.11123977874832416, 0.16957886890793988, -0.1530647406776649, 0.34751163682768677, -0.5022476223637364], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [8.307789240105382, 6.92297560709111, 6.859198313542338, 6.80885332561313, 6.798789038932069, 6.771714438024954, 6.7544352109722094, 6.636831881363801, 6.406670747520256, 6.386405836232897, 6.368452184141344, 6.366238092715713, 6.336056200840997, 6.333101452321094, 5.942488430582705]}, \"tinfo\": {\"Term\": [\"learning\", \"neural\", \"deep\", \"networks\", \"based\", \"using\", \"data\", \"network\", \"models\", \"multi\", \"model\", \"detection\", \"graph\", \"classification\", \"adversarial\", \"machine\", \"optimization\", \"reinforcement\", \"efficient\", \"time\", \"prediction\", \"approach\", \"analysis\", \"training\", \"supervised\", \"image\", \"robust\", \"convolutional\", \"bayesian\", \"generative\", \"machine\", \"reinforcement\", \"federated\", \"large\", \"scale\", \"study\", \"active\", \"agent\", \"covid\", \"19\", \"case\", \"heterogeneous\", \"learning\", \"edge\", \"social\", \"user\", \"techniques\", \"computing\", \"explainable\", \"intelligence\", \"resource\", \"environments\", \"world\", \"policies\", \"mobile\", \"robot\", \"computational\", \"personalized\", \"safe\", \"agents\", \"artificial\", \"network\", \"graph\", \"classification\", \"prediction\", \"attention\", \"dynamic\", \"text\", \"temporal\", \"application\", \"forecasting\", \"predicting\", \"memory\", \"interpretable\", \"hybrid\", \"recommendation\", \"novel\", \"flow\", \"long\", \"traffic\", \"spatial\", \"net\", \"term\", \"disease\", \"short\", \"diagnosis\", \"signal\", \"residual\", \"clinical\", \"lstm\", \"node\", \"images\", \"data\", \"analysis\", \"framework\", \"systems\", \"generation\", \"performance\", \"driven\", \"ensemble\", \"dataset\", \"anomaly\", \"automated\", \"ai\", \"augmentation\", \"review\", \"autonomous\", \"resolution\", \"open\", \"datasets\", \"set\", \"fine\", \"event\", \"comparison\", \"testing\", \"mining\", \"tuning\", \"evaluating\", \"driving\", \"behavior\", \"motion\", \"approaches\", \"deep\", \"applications\", \"embedding\", \"attacks\", \"design\", \"survey\", \"privacy\", \"predictive\", \"power\", \"constraints\", \"preserving\", \"channel\", \"sensing\", \"imaging\", \"health\", \"trajectory\", \"prior\", \"ensembles\", \"wireless\", \"interactive\", \"impact\", \"phase\", \"identifying\", \"vehicle\", \"intelligent\", \"smart\", \"response\", \"analytics\", \"flexible\", \"topological\", \"using\", \"neural\", \"networks\", \"convolutional\", \"estimation\", \"quantum\", \"sequence\", \"processing\", \"layer\", \"parameter\", \"matching\", \"detecting\", \"density\", \"variable\", \"cost\", \"mixed\", \"modelling\", \"architectures\", \"maximum\", \"quantization\", \"effects\", \"depth\", \"input\", \"stability\", \"wise\", \"shift\", \"likelihood\", \"hardware\", \"sensitive\", \"type\", \"precision\", \"recurrent\", \"artificial\", \"multi\", \"adversarial\", \"training\", \"language\", \"aware\", \"task\", \"label\", \"local\", \"evaluation\", \"understanding\", \"level\", \"noise\", \"risk\", \"classifiers\", \"bias\", \"natural\", \"fairness\", \"extraction\", \"tasks\", \"context\", \"pre\", \"empirical\", \"attack\", \"examples\", \"complex\", \"trained\", \"invariant\", \"modal\", \"ranking\", \"reasoning\", \"clustering\", \"linear\", \"non\", \"algorithms\", \"optimal\", \"regression\", \"high\", \"low\", \"kernel\", \"matrix\", \"bandits\", \"dimensional\", \"rank\", \"structured\", \"bounds\", \"tensor\", \"private\", \"statistical\", \"generalized\", \"complexity\", \"vector\", \"nonlinear\", \"factorization\", \"perspective\", \"bandit\", \"feedback\", \"support\", \"regret\", \"contextual\", \"machines\", \"optimization\", \"gradient\", \"stochastic\", \"methods\", \"descent\", \"regularization\", \"convergence\", \"functions\", \"loss\", \"convex\", \"state\", \"approximation\", \"function\", \"order\", \"theory\", \"improved\", \"global\", \"general\", \"box\", \"games\", \"collaborative\", \"regularized\", \"implicit\", \"minimization\", \"universal\", \"entropy\", \"black\", \"variance\", \"mean\", \"boosting\", \"models\", \"bayesian\", \"generative\", \"inference\", \"variational\", \"policy\", \"gaussian\", \"distributed\", \"sampling\", \"meta\", \"free\", \"problems\", \"processes\", \"process\", \"energy\", \"constrained\", \"communication\", \"markov\", \"compression\", \"sequential\", \"autoencoders\", \"error\", \"inverse\", \"autoencoder\", \"mixture\", \"approximate\", \"discrete\", \"guarantees\", \"solving\", \"hidden\", \"model\", \"feature\", \"recognition\", \"domain\", \"sparse\", \"selection\", \"end\", \"speech\", \"adaptation\", \"automatic\", \"cross\", \"identification\", \"scalable\", \"discovery\", \"synthesis\", \"source\", \"multimodal\", \"audio\", \"classifier\", \"fusion\", \"accuracy\", \"tracking\", \"speaker\", \"coding\", \"code\", \"music\", \"verification\", \"eeg\", \"agnostic\", \"emotion\", \"based\", \"detection\", \"robust\", \"shot\", \"human\", \"embeddings\", \"object\", \"transformer\", \"point\", \"cnn\", \"metric\", \"vision\", \"transformers\", \"zero\", \"word\", \"action\", \"distance\", \"imitation\", \"alignment\", \"activity\", \"monitoring\", \"localization\", \"cloud\", \"supervision\", \"geometric\", \"entity\", \"computer\", \"consistency\", \"pattern\", \"cnns\", \"3d\", \"supervised\", \"image\", \"self\", \"unsupervised\", \"segmentation\", \"semi\", \"random\", \"robustness\", \"features\", \"uncertainty\", \"decision\", \"semantic\", \"conditional\", \"contrastive\", \"video\", \"medical\", \"guided\", \"reconstruction\", \"single\", \"translation\", \"gan\", \"learned\", \"trees\", \"making\", \"exploring\", \"auto\", \"retrieval\", \"brain\", \"improve\", \"mri\", \"efficient\", \"time\", \"adaptive\", \"algorithm\", \"method\", \"fast\", \"search\", \"series\", \"architecture\", \"probabilistic\", \"real\", \"sample\", \"differential\", \"physics\", \"spectral\", \"tree\", \"simple\", \"binary\", \"decomposition\", \"dual\", \"pruning\", \"weighted\", \"parallel\", \"accurate\", \"partial\", \"effective\", \"informed\", \"equations\", \"multivariate\", \"flows\", \"approach\", \"information\", \"modeling\", \"control\", \"generalization\", \"latent\", \"hierarchical\", \"space\", \"graphs\", \"multiple\", \"structure\", \"causal\", \"dynamics\", \"continuous\", \"joint\", \"view\", \"problem\", \"noisy\", \"similarity\", \"planning\", \"differentiable\", \"value\", \"unified\", \"programming\", \"batch\", \"diffusion\", \"labels\", \"group\", \"structural\", \"objective\", \"online\", \"representation\", \"knowledge\", \"transfer\", \"representations\", \"visual\", \"improving\", \"distribution\", \"new\", \"class\", \"exploration\", \"reduction\", \"distillation\", \"continual\", \"quality\", \"explanations\", \"learn\", \"better\", \"benchmark\", \"assessment\", \"signals\", \"wasserstein\", \"gans\", \"manifold\", \"reward\", \"predictions\", \"relational\", \"molecular\", \"incremental\", \"counterfactual\"], \"Freq\": [29975.0, 13960.0, 13878.0, 12506.0, 11028.0, 10105.0, 8189.0, 6370.0, 6066.0, 5916.0, 5710.0, 5181.0, 4945.0, 4874.0, 4288.0, 4489.0, 3964.0, 4290.0, 3790.0, 3772.0, 3872.0, 3544.0, 3596.0, 3453.0, 3040.0, 3035.0, 2850.0, 2802.0, 2617.0, 2585.0, 4489.687458025038, 4289.716464819593, 1601.3967416400374, 1311.116267631433, 1276.4438776804266, 1032.930813373252, 931.3326474702765, 753.1326898150488, 663.6295436624423, 634.6014962615861, 578.9644054099093, 577.351736109842, 29960.530051884605, 541.8730115088181, 476.5599048568925, 452.3698653561647, 433.824168405627, 421.72914865527036, 410.4404635549274, 406.40879030484973, 374.9617389539048, 366.8983924536631, 354.8033727032937, 333.0323371526752, 332.22600250264964, 306.4232937018914, 299.9726165016728, 299.97261650169474, 277.3952463010372, 262.8812226006218, 270.8808743932829, 6370.593887242261, 4945.4160847706235, 4874.697406771344, 3871.867264576718, 1665.837392521293, 1512.613590187993, 1447.7881353546632, 1322.0660411324839, 1104.998987826913, 1101.0701723825127, 953.7395932158436, 937.0421275769597, 819.1776642436337, 725.8682974380908, 723.9038897158669, 691.4911622992014, 645.3275808269914, 596.2173877714843, 583.4487375770387, 556.9292333270215, 544.1605831325785, 509.78344799374577, 478.352924438167, 461.6554587992941, 444.9579931603768, 442.0113815770209, 395.84780010481654, 380.13253832704896, 376.2037228826117, 355.5774417992843, 1236.9762714062292, 8189.006947110042, 3596.0658692063944, 2431.231960630343, 2230.095510364875, 1564.197165311524, 1092.6005367765667, 1037.9226668015342, 931.4960984571804, 845.573731353528, 829.9514827892078, 780.1555654904987, 767.4624885320154, 673.7289971461996, 600.4997070010118, 598.5469259304908, 536.0579316732538, 516.53012096789, 501.8842629388349, 491.1439670508777, 470.6397658102672, 468.6869847396816, 437.4424876110742, 436.4660970758158, 429.6313633289446, 422.7966295820603, 419.86745797623934, 418.8910674410063, 405.2215999472005, 395.4576945945076, 380.8118365654822, 13877.835717138714, 1212.3440937204557, 1208.3496155612152, 1150.4296822522224, 1075.533216766433, 1033.591196094406, 1031.5939570147964, 686.0715962403871, 680.0798790015325, 530.286948029958, 530.2869480299995, 474.36425380059694, 431.42361358875957, 406.4581250934876, 385.4871147574849, 369.5092021204938, 363.5174848816326, 353.5312894835333, 338.5519963863968, 330.56304006788406, 327.5671814484487, 305.59755157263953, 300.60445387358146, 287.6223998560705, 282.6293021570098, 277.6362044579752, 268.648628599647, 265.6527699802323, 254.66795504229557, 217.71903206932123, 9957.393560608447, 13959.908916305378, 12506.40367020912, 2801.7459070329915, 2355.263410244265, 938.8025634445107, 846.1915652022728, 563.4843074101504, 544.962107761741, 532.2890237917202, 529.3644659524849, 518.6410872086506, 450.4014042933405, 449.42655168024146, 416.2815628356516, 406.53303670489095, 385.0862792172095, 376.31260569954384, 368.51378479493104, 361.6898165034101, 325.6202698195657, 321.72085936728615, 314.8968910757406, 313.92203846265323, 311.97233323650653, 299.29924926651404, 292.47528097500947, 262.2548499696275, 256.4057342911636, 247.6320607734644, 242.75779770811408, 1254.5113882415799, 327.64698147501025, 5916.083021712262, 4288.16638175141, 3452.762453339428, 1795.6018018816112, 1538.254500713956, 1481.716078487759, 1054.7535106414705, 1046.9551075757481, 1025.5094991451217, 990.4166853495483, 865.6422362985825, 775.9606010432063, 734.0441845651494, 708.6993746016747, 706.7497738352562, 705.7749734520688, 683.3545646382065, 645.3373496929835, 614.143737430234, 611.2193362806157, 589.7737278500168, 577.1013228682345, 545.9077106055156, 497.1676914450077, 438.6796684523027, 438.67966845234486, 436.73006768589215, 431.85606576987453, 424.05766270416706, 412.360058105646, 2056.763823507715, 1973.9160334066612, 1864.09454420283, 1852.534387444612, 1829.4140739280274, 1727.299355896399, 1622.2945986752106, 1382.4213459405755, 1198.4221842043821, 1157.9616355503695, 1002.8628657099355, 990.3393625550926, 854.5075206451478, 808.2668936119178, 803.4501616293301, 791.8900048710187, 683.9952084602812, 657.9848557540827, 654.1314701679939, 648.3513917888525, 609.8175359278791, 607.8908431348011, 588.6239152043629, 562.6135624981366, 532.749824205934, 528.8964386197949, 524.079706637195, 523.1163602406806, 516.372935464996, 515.4095890684644, 3964.413019778457, 2401.4795410594534, 2340.9468793441324, 1727.6815524563056, 1025.10574107043, 978.4658213879783, 960.6037244883652, 956.6343696217544, 937.7799340054621, 934.8029178555586, 903.0480789227848, 871.293239990137, 780.99041677527, 766.1053360255794, 743.281545542676, 730.3811422262472, 649.0093674612277, 582.5226734458906, 567.6375926962216, 520.005334297156, 504.1279148307866, 504.12791483079667, 503.1355761141464, 500.1585599642202, 478.3271081979655, 477.33476948133017, 476.3424307647197, 470.3883984648294, 438.63355953212294, 434.664204665515, 6065.775154948515, 2617.224300530156, 2585.4073134804944, 2349.3457966602637, 1676.0572965121148, 1606.2651958869942, 1534.420386419998, 1461.5492225319333, 1324.017730123659, 1113.6150738273216, 1065.3764160423066, 1049.98109972795, 1029.4540113088385, 985.3207712076421, 849.841987641202, 774.9181149112992, 755.4173809131081, 727.7058115472817, 704.0996598652222, 680.4935081831951, 663.0454830269368, 642.518394607762, 623.0176606095866, 610.7014075580845, 535.7775348282001, 515.2504464090373, 507.0396110413654, 420.8258396809244, 412.6150043132607, 397.2196879989151, 5710.295844392412, 2374.8847752801717, 2298.5498747792626, 2075.9064149848027, 1984.728617164168, 1712.2554306537788, 1694.2319124799483, 1599.8734938051537, 1211.8377495918478, 1089.9139501805425, 1066.5893972496947, 1005.0973940683446, 972.2309785748613, 743.2262770719522, 700.8179990158739, 681.7342738906475, 641.4464097373385, 635.0851680289429, 600.098338632638, 587.3758552158165, 480.2949531241553, 463.33164190172727, 448.4887445821559, 405.02025957461495, 402.8998456718114, 390.17736225499505, 378.5150857895713, 374.2742579839456, 372.15384408114727, 362.6119815185572, 11028.128323437919, 5181.325611459952, 2850.484027683886, 1287.361394068875, 1284.1670017658478, 1086.1146789781135, 1086.1146789781271, 921.0710766549921, 857.1832305944437, 637.8349591198361, 615.4742129986328, 592.0486694431222, 583.5302899683602, 571.8175181906097, 559.0399489784934, 550.5215695037299, 513.2536593017373, 460.0137875845956, 427.0050671199763, 406.77391586748615, 399.32033382706265, 398.25553639273505, 391.86675178668685, 376.9595877058662, 375.89479027152663, 336.4972852008724, 316.26613394834726, 308.812551907929, 288.5814006554239, 277.9334263120025, 1021.0358418161248, 3040.681943544818, 3035.395676509711, 2169.5051361924984, 1886.1612231217161, 1692.6838496441967, 1391.3666286547364, 1380.7940945848845, 1203.1755222121183, 1194.7174949562595, 1155.5991188979738, 1111.194475804797, 1011.8126555486165, 890.2285137458022, 833.1368297688575, 817.2780286641384, 768.6443719430305, 714.724448186997, 708.3809277451319, 690.4076198264373, 667.1480448728742, 596.3120666051659, 549.7929166980027, 468.384404360508, 460.9836305116466, 453.58285666274674, 433.49504193013144, 417.6362408254191, 627.8679244189491, 396.49117268579045, 386.97589202298894, 3789.9597525499926, 3771.820970731655, 2226.823554700242, 2026.2299675358747, 1774.4209964147828, 1616.506895881178, 1605.837024223496, 1603.7030498919523, 1175.8411964191341, 1125.6927996280326, 1121.4248509649806, 863.2139568492014, 803.4626755662399, 768.252099095898, 703.1658819840529, 672.2232541768012, 625.2758188830197, 617.8069087226377, 574.060434926178, 558.0556274396598, 531.3809482954684, 506.8402434828018, 501.5053076539731, 500.4383204882109, 485.50050016747116, 474.8306285097832, 451.35691086292746, 449.2229365314151, 434.2851162106403, 406.5434499006817, 3544.177063303203, 1947.1387389755816, 1905.89072927438, 1690.131909299021, 1330.5338760067946, 1263.9024757202915, 1244.864932781255, 1222.6544660190934, 1191.9828690618158, 1134.870240244805, 1033.3366779034607, 1013.2414936900791, 1004.7803634949486, 887.3821820377739, 738.2547623489005, 732.9665559769638, 675.8539271599561, 671.6233620624073, 574.3203648186153, 548.9369742332809, 544.7064091357239, 526.7265074710986, 498.1701930625967, 488.6514215931106, 478.07500884922473, 452.691618263874, 444.2304880687762, 427.30822767853294, 413.5588911114764, 410.3859672883035, 2470.745916002951, 2368.8958235885784, 1931.7414943498407, 1790.9823778672107, 1755.5065029813197, 1461.4000563468246, 1388.1595404534046, 1123.8070534006413, 1026.5344932296946, 1023.1013440472012, 851.4438849220099, 761.0376231160874, 672.9201274318511, 601.9683776600826, 601.9683776600781, 571.0700350175549, 516.1396480974865, 485.2413054549497, 465.7867934207611, 461.20926117741755, 461.20926117740885, 460.064878116597, 448.6210475082494, 448.6210475082437, 415.4339387440414, 414.2895556832025, 409.71202343987204, 398.26819283152645, 394.83504364902694, 373.09176549317914], \"Total\": [29975.0, 13960.0, 13878.0, 12506.0, 11028.0, 10105.0, 8189.0, 6370.0, 6066.0, 5916.0, 5710.0, 5181.0, 4945.0, 4874.0, 4288.0, 4489.0, 3964.0, 4290.0, 3790.0, 3772.0, 3872.0, 3544.0, 3596.0, 3453.0, 3040.0, 3035.0, 2850.0, 2802.0, 2617.0, 2585.0, 4489.974261540245, 4290.0032683348, 1601.6835451552438, 1311.4030711466394, 1276.730681195633, 1033.2176168884585, 931.619450985483, 753.4194933302554, 663.9163471776488, 634.8882997767927, 579.2512089251159, 577.6385396250486, 29975.60055880442, 542.1598150240246, 476.846708372099, 452.6566688713712, 434.1109719208335, 422.01595217047685, 410.7272670701339, 406.6955938200562, 375.24854246911127, 367.1851959688696, 355.0901762185002, 333.3191406678817, 332.5128060178561, 306.7100972170979, 300.2594200168793, 300.25942001690123, 277.6820498162437, 263.1680261158283, 598.7951623312382, 6370.8771733732465, 4945.699370901609, 4874.980692902329, 3872.150550707702, 1666.1206786522775, 1512.8968763189775, 1448.0714214856478, 1322.3493272634685, 1105.2822739578976, 1101.3534585134973, 954.0228793468284, 937.3254137079446, 819.4609503746185, 726.1515835690757, 724.1871758468517, 691.7744484301862, 645.6108669579762, 596.5006739024691, 583.7320237080236, 557.2125194580063, 544.4438692635633, 510.06673412473054, 478.6362105691518, 461.93874493027886, 445.2412792913616, 442.2946677080057, 396.1310862358013, 380.41582445803374, 376.4870090135965, 355.8607279302691, 1238.9844405641038, 8189.290349507543, 3596.349271603896, 2431.5153630278446, 2230.3789127623763, 1564.4805677090255, 1092.8839391740682, 1038.2060691990357, 931.779500854682, 845.8571337510297, 830.2348851867094, 780.4389678880003, 767.745890929517, 674.0123995437012, 600.7831093985134, 598.8303283279924, 536.3413340707555, 516.8135233653916, 502.16766533633654, 491.4273694483793, 470.9231682077688, 468.9703871371832, 437.72589000857585, 436.7494994733174, 429.9147657264462, 423.0800319795619, 420.15086037374095, 419.17446983850795, 405.5050023447021, 395.7410969920092, 381.09523896298384, 13878.118674956124, 1212.6270515378665, 1208.632573378626, 1150.7126400696332, 1075.8161745838438, 1033.8741539118168, 1031.8769148322071, 686.3545540577978, 680.3628368189433, 530.5699058473688, 530.5699058474103, 474.6472116180077, 431.7065714061703, 406.74108291089834, 385.77007257489566, 369.79215993790456, 363.80044269904334, 353.8142473009441, 338.83495420380757, 330.8459978852948, 327.85013926585947, 305.8805093900503, 300.8874116909922, 287.90535767348126, 282.9122599744206, 277.919162275386, 268.93158641705776, 265.93572779764304, 254.9509128597063, 218.00198988673196, 10105.800264583057, 13960.192349461322, 12506.687103365064, 2802.0293401889367, 2355.54684340021, 939.0859966004563, 846.4749983582184, 563.767740566096, 545.2455409176865, 532.5724569476657, 529.6478991084305, 518.9245203645961, 450.68483744928596, 449.70998483618695, 416.5649959915971, 406.81646986083643, 385.369712373155, 376.5960388554893, 368.79721795087653, 361.9732496593556, 325.9037029755112, 322.00429252323164, 315.1803242316861, 314.2054716185987, 312.255766392452, 299.5826824224595, 292.75871413095496, 262.538283125573, 256.68916744710907, 247.9154939294098, 243.0412308640595, 1284.4054405975928, 598.7951623312382, 5916.366455912805, 4288.449815951953, 3453.04588753997, 1795.8852360821538, 1538.5379349144987, 1481.9995126883016, 1055.036944842013, 1047.2385417762907, 1025.7929333456643, 990.7001195500911, 865.9256704991253, 776.2440352437492, 734.3276187656923, 708.9828088022175, 707.033208035799, 706.0584076526117, 683.6379988387494, 645.6207838935263, 614.4271716307768, 611.5027704811586, 590.0571620505597, 577.3847570687774, 546.1911448060584, 497.45112564555046, 438.96310265284546, 438.96310265288764, 437.01350188643494, 432.1394999704173, 424.34109690470984, 412.64349230618876, 2057.0474867879916, 1974.1996966869376, 1864.3782074831065, 1852.8180507248885, 1829.6977372083038, 1727.5830191766754, 1622.578261955487, 1382.705009220852, 1198.7058474846585, 1158.2452988306459, 1003.146528990212, 990.6230258353692, 854.7911839254243, 808.5505568921943, 803.7338249096066, 792.1736681512953, 684.2788717405577, 658.2685190343592, 654.4151334482705, 648.6350550691291, 610.1011992081557, 608.1745064150776, 588.9075784846394, 562.8972257784131, 533.0334874862106, 529.1801019000715, 524.3633699174716, 523.4000235209571, 516.6565987452725, 515.6932523487409, 3964.696103212331, 2401.762624493327, 2341.229962778006, 1727.9646358901794, 1025.3888245043038, 978.7489048218524, 960.8868079222393, 956.9174530556286, 938.0630174393362, 935.0860012894327, 903.331162356659, 871.5763234240111, 781.2735002091441, 766.3884194594535, 743.5646289765501, 730.6642256601214, 649.2924508951019, 582.8057568797648, 567.9206761300958, 520.2884177310301, 504.41099826466063, 504.4109982646707, 503.4186595480204, 500.44164339809424, 478.61019163183954, 477.6178529152042, 476.62551419859375, 470.6714818987034, 438.91664296599697, 434.947288099389, 6066.057558068303, 2617.506703649944, 2585.6897166002823, 2349.6281997800515, 1676.3396996319025, 1606.5475990067819, 1534.7027895397857, 1461.831625651721, 1324.3001332434467, 1113.8974769471092, 1065.6588191620942, 1050.2635028477378, 1029.7364144286262, 985.60317432743, 850.1243907609899, 775.2005180310871, 755.699784032896, 727.9882146670695, 704.3820629850101, 680.775911302983, 663.3278861467247, 642.8007977275499, 623.3000637293745, 610.9838106778724, 536.059937947988, 515.5328495288252, 507.32201416115316, 421.10824280071216, 412.8974074330485, 397.5020911187029, 5710.577570461591, 2375.1665013493503, 2298.831600848441, 2076.1881410539813, 1985.010343233347, 1712.5371567229577, 1694.513638549127, 1600.1552198743325, 1212.1194756610266, 1090.1956762497214, 1066.8711233188735, 1005.3791201375235, 972.5127046440402, 743.5080031411311, 701.0997250850528, 682.0159999598264, 641.7281358065175, 635.3668940981219, 600.380064701817, 587.6575812849954, 480.5766791933342, 463.61336797090615, 448.7704706513348, 405.30198564379384, 403.1815717409903, 390.45908832417393, 378.7968118587502, 374.55598405312446, 372.43557015032616, 362.89370758773606, 11028.409957697439, 5181.607245719471, 2850.765661943406, 1287.6430283283948, 1284.4486360253677, 1086.3963132376334, 1086.396313237647, 921.3527109145123, 857.4648648539638, 638.1165933793562, 615.7558472581529, 592.3303037026424, 583.8119242278804, 572.0991524501298, 559.3215832380135, 550.80320376325, 513.5352935612575, 460.2954218441157, 427.2867013794964, 407.05555012700626, 399.60196808658276, 398.53717065225516, 392.14838604620695, 377.24122196538633, 376.17642453104673, 336.7789194603925, 316.54776820786736, 309.0941861674491, 288.863034914944, 278.2150605715226, 1028.8435495168671, 3040.963728684885, 3035.6774616497783, 2169.7869213325657, 1886.4430082617835, 1692.965634784264, 1391.6484137948037, 1381.0758797249518, 1203.4573073521856, 1194.9992800963269, 1155.880904038041, 1111.4762609448644, 1012.0944406886838, 890.5102988858695, 833.4186149089248, 817.5598138042058, 768.9261570830978, 715.0062333270644, 708.6627128851992, 690.6894049665046, 667.4298300129415, 596.5938517452332, 550.07470183807, 468.66618950057534, 461.26541565171397, 453.8646418028141, 433.7768270701988, 417.9180259654865, 628.298847831537, 396.7729578258578, 387.2576771630563, 3790.241343014884, 3772.1025611965465, 2227.1051451651333, 2026.5115580007664, 1774.7025868796745, 1616.7884863460697, 1606.1186146883877, 1603.984640356844, 1176.1227868840258, 1125.9743900929243, 1121.7064414298723, 863.495547314093, 803.7442660311315, 768.5336895607895, 703.4474724489445, 672.5048446416928, 625.5574093479113, 618.0884991875292, 574.3420253910696, 558.3372179045514, 531.66253876036, 507.1218339476934, 501.7868981188647, 500.7199109531025, 485.7820906323628, 475.1122189746748, 451.6385013278191, 449.5045269963067, 434.5667066755319, 406.82504036557333, 3544.458840685922, 1947.4205163583008, 1906.1725066570991, 1690.41368668174, 1330.8156533895137, 1264.1842531030106, 1245.1467101639741, 1222.9362434018126, 1192.264646444535, 1135.1520176275242, 1033.6184552861798, 1013.5232710727983, 1005.0621408776677, 887.663959420493, 738.5365397316197, 733.248333359683, 676.1357045426753, 671.9051394451265, 574.6021422013345, 549.2187516160001, 544.9881865184431, 527.0082848538177, 498.45197044531585, 488.9331989758298, 478.3567862319439, 452.97339564659313, 444.51226545149535, 427.5900050612521, 413.84066849419554, 410.66774467102266, 2471.0259585499416, 2369.175866135569, 1932.0215368968309, 1791.262420414201, 1755.78654552831, 1461.6800988938148, 1388.4395830003948, 1124.0870959476315, 1026.8145357766848, 1023.3813865941914, 851.7239274690002, 761.3176656630776, 673.2001699788414, 602.2484202070729, 602.2484202070683, 571.3500775645451, 516.4196906444768, 485.52134800194, 466.0668359677514, 461.4893037244078, 461.4893037243991, 460.3449206635873, 448.90109005523965, 448.90109005523396, 415.7139812910317, 414.56959823019275, 409.9920659868623, 398.5482353785167, 395.1150861960172, 373.3718080401694], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7308, -2.7764, -3.7617, -3.9617, -3.9885, -4.2002, -4.3038, -4.5161, -4.6427, -4.6874, -4.7791, -4.7819, -0.8327, -4.8453, -4.9738, -5.0259, -5.0677, -5.096, -5.1231, -5.133, -5.2136, -5.2353, -5.2688, -5.3321, -5.3346, -5.4154, -5.4367, -5.4367, -5.5149, -5.5687, -5.5387, -2.1986, -2.4518, -2.4662, -2.6965, -3.5399, -3.6364, -3.6802, -3.7711, -3.9504, -3.954, -4.0976, -4.1153, -4.2497, -4.3707, -4.3734, -4.4192, -4.4883, -4.5674, -4.5891, -4.6356, -4.6588, -4.724, -4.7877, -4.8232, -4.86, -4.8667, -4.977, -5.0175, -5.0279, -5.0843, -3.8376, -1.9382, -2.7612, -3.1526, -3.239, -3.5936, -3.9525, -4.0038, -4.112, -4.2088, -4.2274, -4.2893, -4.3057, -4.4359, -4.551, -4.5543, -4.6645, -4.7016, -4.7304, -4.752, -4.7947, -4.7988, -4.8678, -4.8701, -4.8858, -4.9019, -4.9088, -4.9112, -4.9443, -4.9687, -5.0065, -1.4034, -3.8411, -3.8444, -3.8935, -3.9608, -4.0006, -4.0025, -4.4104, -4.4192, -4.668, -4.668, -4.7794, -4.8743, -4.9339, -4.9869, -5.0292, -5.0456, -5.0734, -5.1167, -5.1406, -5.1497, -5.2191, -5.2356, -5.2798, -5.2973, -5.3151, -5.348, -5.3592, -5.4014, -5.5582, -1.7353, -1.396, -1.5059, -3.0019, -3.1755, -4.0953, -4.1992, -4.6058, -4.6392, -4.6627, -4.6682, -4.6887, -4.8298, -4.832, -4.9086, -4.9323, -4.9865, -5.0095, -5.0304, -5.0491, -5.1542, -5.1662, -5.1877, -5.1908, -5.197, -5.2385, -5.2615, -5.3706, -5.3932, -5.428, -5.4479, -3.8054, -5.148, -2.2505, -2.5723, -2.789, -3.4428, -3.5975, -3.635, -3.9749, -3.9823, -4.003, -4.0378, -4.1725, -4.2818, -4.3374, -4.3725, -4.3753, -4.3766, -4.4089, -4.4662, -4.5157, -4.5205, -4.5562, -4.5779, -4.6335, -4.727, -4.8522, -4.8522, -4.8566, -4.8678, -4.8861, -4.914, -3.3045, -3.3456, -3.4029, -3.4091, -3.4216, -3.4791, -3.5418, -3.7018, -3.8446, -3.879, -4.0228, -4.0353, -4.1829, -4.2385, -4.2445, -4.259, -4.4054, -4.4442, -4.4501, -4.4589, -4.5202, -4.5234, -4.5556, -4.6008, -4.6553, -4.6626, -4.6717, -4.6736, -4.6866, -4.6884, -2.6307, -3.132, -3.1575, -3.4613, -3.9833, -4.0298, -4.0483, -4.0524, -4.0723, -4.0755, -4.11, -4.1458, -4.2553, -4.2745, -4.3047, -4.3222, -4.4404, -4.5484, -4.5743, -4.662, -4.693, -4.693, -4.695, -4.7009, -4.7455, -4.7476, -4.7497, -4.7623, -4.8322, -4.8412, -2.1701, -3.0107, -3.0229, -3.1186, -3.4563, -3.4989, -3.5446, -3.5933, -3.6921, -3.8652, -3.9094, -3.924, -3.9437, -3.9876, -4.1355, -4.2278, -4.2533, -4.2906, -4.3236, -4.3577, -4.3837, -4.4151, -4.4459, -4.4659, -4.5968, -4.6359, -4.6519, -4.8383, -4.858, -4.896, -2.2273, -3.1046, -3.1373, -3.2392, -3.2841, -3.4318, -3.4424, -3.4997, -3.7775, -3.8835, -3.9051, -3.9645, -3.9978, -4.2664, -4.3251, -4.3527, -4.4136, -4.4236, -4.4803, -4.5017, -4.703, -4.7389, -4.7715, -4.8734, -4.8787, -4.9108, -4.9411, -4.9524, -4.958, -4.984, -1.5663, -2.3217, -2.9193, -3.7142, -3.7167, -3.8842, -3.8842, -4.049, -4.1209, -4.4165, -4.4521, -4.4909, -4.5054, -4.5257, -4.5483, -4.5637, -4.6338, -4.7433, -4.8177, -4.8663, -4.8848, -4.8874, -4.9036, -4.9424, -4.9452, -5.0559, -5.118, -5.1418, -5.2096, -5.2472, -3.946, -2.8544, -2.8561, -3.1919, -3.3319, -3.4401, -3.6361, -3.6438, -3.7815, -3.7885, -3.8218, -3.861, -3.9547, -4.0827, -4.149, -4.1682, -4.2296, -4.3023, -4.3112, -4.3369, -4.3712, -4.4834, -4.5646, -4.7249, -4.7408, -4.757, -4.8023, -4.8396, -4.4319, -4.8915, -4.9158, -2.6293, -2.6341, -3.1611, -3.2555, -3.3882, -3.4814, -3.488, -3.4894, -3.7997, -3.8433, -3.8471, -4.1088, -4.1805, -4.2253, -4.3138, -4.3588, -4.4312, -4.4433, -4.5167, -4.545, -4.594, -4.6412, -4.6518, -4.654, -4.6843, -4.7065, -4.7572, -4.7619, -4.7957, -4.8617, -2.6959, -3.2949, -3.3163, -3.4364, -3.6756, -3.727, -3.7422, -3.7602, -3.7856, -3.8347, -3.9284, -3.9481, -3.9564, -4.0807, -4.2647, -4.2719, -4.353, -4.3593, -4.5158, -4.561, -4.5687, -4.6023, -4.658, -4.6773, -4.6992, -4.7538, -4.7726, -4.8115, -4.8442, -4.8519, -2.993, -3.0351, -3.2391, -3.3148, -3.3348, -3.5182, -3.5696, -3.7808, -3.8714, -3.8747, -4.0584, -4.1706, -4.2937, -4.4051, -4.4051, -4.4578, -4.5589, -4.6207, -4.6616, -4.6715, -4.6715, -4.6739, -4.6991, -4.6991, -4.776, -4.7787, -4.7899, -4.8182, -4.8268, -4.8835], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.4879, 2.4879, 2.4878, 2.4878, 2.4878, 2.4877, 2.4877, 2.4876, 2.4875, 2.4875, 2.4875, 2.4875, 2.4875, 2.4874, 2.4874, 2.4873, 2.4873, 2.4873, 2.4873, 2.4873, 2.4872, 2.4872, 2.4872, 2.4871, 2.4871, 2.487, 2.487, 2.487, 2.4869, 2.4869, 1.6947, 2.6703, 2.6703, 2.6703, 2.6703, 2.6702, 2.6701, 2.6701, 2.6701, 2.6701, 2.6701, 2.67, 2.67, 2.67, 2.6699, 2.6699, 2.6699, 2.6699, 2.6698, 2.6698, 2.6698, 2.6698, 2.6698, 2.6697, 2.6697, 2.6697, 2.6697, 2.6696, 2.6696, 2.6696, 2.6695, 2.6687, 2.6795, 2.6795, 2.6795, 2.6795, 2.6794, 2.6793, 2.6793, 2.6793, 2.6792, 2.6792, 2.6792, 2.6792, 2.6792, 2.6791, 2.6791, 2.6791, 2.679, 2.679, 2.679, 2.679, 2.679, 2.6789, 2.6789, 2.6789, 2.6789, 2.6789, 2.6789, 2.6789, 2.6789, 2.6788, 2.6869, 2.6867, 2.6867, 2.6867, 2.6867, 2.6867, 2.6867, 2.6865, 2.6865, 2.6864, 2.6864, 2.6864, 2.6863, 2.6863, 2.6862, 2.6862, 2.6862, 2.6861, 2.6861, 2.6861, 2.6861, 2.686, 2.686, 2.686, 2.6859, 2.6859, 2.6859, 2.6859, 2.6858, 2.6856, 2.6722, 2.6884, 2.6884, 2.6883, 2.6883, 2.6881, 2.6881, 2.6879, 2.6879, 2.6879, 2.6879, 2.6879, 2.6878, 2.6878, 2.6877, 2.6877, 2.6877, 2.6877, 2.6877, 2.6876, 2.6876, 2.6875, 2.6875, 2.6875, 2.6875, 2.6875, 2.6875, 2.6873, 2.6873, 2.6873, 2.6873, 2.6649, 2.0854, 2.6924, 2.6923, 2.6923, 2.6923, 2.6922, 2.6922, 2.6921, 2.6921, 2.6921, 2.6921, 2.6921, 2.6921, 2.692, 2.692, 2.692, 2.692, 2.692, 2.692, 2.692, 2.692, 2.6919, 2.6919, 2.6919, 2.6918, 2.6918, 2.6918, 2.6918, 2.6918, 2.6917, 2.6917, 2.6948, 2.6948, 2.6948, 2.6948, 2.6948, 2.6948, 2.6948, 2.6948, 2.6947, 2.6947, 2.6947, 2.6947, 2.6946, 2.6946, 2.6946, 2.6946, 2.6946, 2.6945, 2.6945, 2.6945, 2.6945, 2.6945, 2.6945, 2.6945, 2.6944, 2.6944, 2.6944, 2.6944, 2.6944, 2.6944, 2.7125, 2.7124, 2.7124, 2.7124, 2.7123, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7122, 2.7121, 2.7121, 2.712, 2.712, 2.712, 2.712, 2.712, 2.712, 2.712, 2.7119, 2.7119, 2.7119, 2.7119, 2.7119, 2.7119, 2.7478, 2.7477, 2.7477, 2.7477, 2.7477, 2.7477, 2.7476, 2.7476, 2.7476, 2.7476, 2.7476, 2.7476, 2.7476, 2.7475, 2.7475, 2.7475, 2.7475, 2.7474, 2.7474, 2.7474, 2.7474, 2.7474, 2.7474, 2.7474, 2.7473, 2.7473, 2.7473, 2.7472, 2.7471, 2.7471, 2.7509, 2.7509, 2.7509, 2.7509, 2.7509, 2.7508, 2.7508, 2.7508, 2.7508, 2.7507, 2.7507, 2.7507, 2.7507, 2.7506, 2.7506, 2.7506, 2.7506, 2.7506, 2.7505, 2.7505, 2.7504, 2.7504, 2.7504, 2.7503, 2.7503, 2.7503, 2.7503, 2.7502, 2.7502, 2.7502, 2.7538, 2.7538, 2.7537, 2.7536, 2.7536, 2.7536, 2.7536, 2.7535, 2.7535, 2.7534, 2.7534, 2.7533, 2.7533, 2.7533, 2.7533, 2.7533, 2.7533, 2.7532, 2.7532, 2.7531, 2.7531, 2.7531, 2.7531, 2.7531, 2.7531, 2.753, 2.7529, 2.7529, 2.7528, 2.7528, 2.7462, 2.7541, 2.7541, 2.754, 2.754, 2.754, 2.754, 2.754, 2.7539, 2.7539, 2.7539, 2.7539, 2.7539, 2.7538, 2.7538, 2.7538, 2.7538, 2.7538, 2.7538, 2.7538, 2.7537, 2.7537, 2.7536, 2.7536, 2.7536, 2.7535, 2.7535, 2.7535, 2.7535, 2.7535, 2.7534, 2.7588, 2.7588, 2.7588, 2.7588, 2.7588, 2.7587, 2.7587, 2.7587, 2.7587, 2.7587, 2.7587, 2.7586, 2.7586, 2.7585, 2.7585, 2.7585, 2.7585, 2.7585, 2.7584, 2.7584, 2.7584, 2.7584, 2.7584, 2.7584, 2.7583, 2.7583, 2.7583, 2.7583, 2.7583, 2.7582, 2.7593, 2.7592, 2.7592, 2.7592, 2.7592, 2.7592, 2.7592, 2.7591, 2.7591, 2.7591, 2.7591, 2.7591, 2.7591, 2.7591, 2.759, 2.759, 2.759, 2.759, 2.7589, 2.7589, 2.7589, 2.7588, 2.7588, 2.7588, 2.7588, 2.7588, 2.7587, 2.7587, 2.7587, 2.7587, 2.8229, 2.8229, 2.8229, 2.8229, 2.8229, 2.8229, 2.8228, 2.8228, 2.8228, 2.8228, 2.8227, 2.8227, 2.8226, 2.8226, 2.8226, 2.8226, 2.8225, 2.8225, 2.8224, 2.8224, 2.8224, 2.8224, 2.8224, 2.8224, 2.8224, 2.8224, 2.8224, 2.8223, 2.8223, 2.8223]}, \"token.table\": {\"Topic\": [1, 11, 12, 10, 13, 11, 1, 11, 10, 13, 6, 1, 1, 10, 3, 13, 7, 11, 3, 4, 3, 2, 4, 14, 3, 9, 8, 13, 5, 1, 5, 15, 6, 4, 2, 10, 3, 12, 9, 9, 3, 10, 3, 6, 7, 7, 11, 14, 9, 3, 15, 15, 6, 13, 8, 8, 7, 8, 12, 1, 14, 4, 15, 2, 10, 6, 2, 11, 7, 11, 11, 10, 10, 8, 9, 3, 6, 7, 9, 1, 11, 1, 12, 11, 9, 4, 6, 7, 15, 14, 12, 14, 8, 8, 5, 5, 15, 1, 10, 3, 3, 3, 12, 13, 4, 5, 5, 8, 4, 5, 11, 2, 14, 13, 14, 7, 10, 9, 2, 11, 15, 9, 15, 10, 3, 3, 13, 2, 14, 1, 10, 13, 5, 13, 4, 11, 10, 6, 10, 9, 3, 4, 11, 8, 1, 13, 9, 5, 3, 6, 3, 6, 1, 15, 15, 12, 6, 7, 6, 13, 10, 12, 1, 7, 3, 4, 2, 13, 2, 3, 9, 8, 8, 10, 8, 12, 15, 9, 8, 14, 7, 3, 9, 11, 8, 8, 2, 14, 14, 9, 12, 5, 4, 1, 9, 14, 7, 11, 2, 10, 4, 12, 2, 12, 4, 11, 4, 8, 12, 8, 15, 15, 9, 14, 13, 5, 1, 4, 4, 2, 6, 9, 14, 7, 15, 6, 14, 6, 1, 14, 5, 15, 12, 1, 4, 15, 6, 5, 7, 6, 11, 2, 8, 7, 2, 1, 7, 12, 15, 9, 5, 7, 5, 8, 12, 2, 9, 13, 8, 11, 8, 3, 5, 9, 1, 6, 10, 14, 5, 9, 15, 11, 3, 12, 6, 10, 14, 13, 10, 6, 2, 2, 5, 5, 15, 2, 6, 14, 7, 7, 2, 11, 14, 15, 3, 7, 8, 8, 13, 5, 13, 11, 3, 1, 7, 4, 13, 14, 11, 1, 9, 4, 6, 5, 2, 2, 15, 4, 4, 4, 4, 7, 13, 14, 9, 9, 9, 5, 14, 13, 15, 5, 5, 12, 7, 6, 13, 6, 10, 2, 12, 2, 5, 15, 7, 7, 8, 8, 1, 15, 15, 15, 2, 3, 1, 4, 12, 3, 15, 6, 1, 11, 12, 1, 13, 9, 10, 1, 13, 12, 10, 12, 12, 12, 4, 5, 5, 9, 13, 3, 5, 2, 11, 2, 15, 14, 13, 12, 4, 1, 9, 10, 14, 10, 2, 10, 13, 10, 5, 8, 7, 8, 14, 14, 7, 1, 12, 11, 7, 4, 10, 3, 6, 6, 1, 2, 7, 2, 3, 2, 8, 13, 4, 10, 2, 6, 6, 4, 15, 11, 11, 12, 13, 12, 3, 5, 12, 6, 14, 8, 12, 1, 2, 4, 5, 10, 11, 12, 14, 5, 8, 9, 7, 4, 10, 12, 14, 11, 15, 15, 13, 4, 5, 11, 1, 11], \"Freq\": [1.0001759368116354, 0.9923763437885669, 0.007775720617344305, 0.9988000266798169, 0.9985622482003319, 1.000357289564413, 0.9993350815240839, 0.9998635318275628, 0.9999014324384472, 0.9999527884144305, 0.9998951098948904, 0.9994432141270979, 0.9993615253406417, 0.9988304818732798, 0.9990284663997172, 0.9997475671931173, 1.0000982013722504, 0.9993290187160734, 0.9999028816231356, 1.000241683217555, 0.9997170858622055, 0.9997446136932181, 0.9994828982768682, 0.9998705470407344, 0.9997500914384473, 0.9989664101340735, 0.9993387573657956, 0.9998956002847703, 0.998417299190664, 0.4525754666168958, 0.5477666164219256, 0.9989397290024732, 0.9996500404521821, 0.999380696757107, 0.9999275690807852, 0.9994225476625712, 0.9999816033893298, 0.9982091549808098, 1.0000264971376405, 0.999505695217143, 0.9994375371988559, 0.9998205127263076, 1.0002833384749923, 0.9996503596679086, 0.9999371756428128, 0.9998539306213226, 0.9999628271256681, 0.9992541420081978, 0.999806417439452, 0.9987546335019738, 0.9998565957442292, 0.998926209930654, 0.9999530318584451, 0.999856817935222, 0.9986876191476122, 1.0001211914686061, 0.9990869801831606, 1.000139674206695, 0.999524354003563, 0.9995663212760798, 0.9994837108453914, 0.9986364364897427, 0.9996273270168996, 1.0000039604459765, 0.9993669598240146, 1.0000242476934125, 0.9989069212390779, 0.999621607402996, 0.9999769150744956, 0.9998172851473133, 0.9992269988149426, 0.9995496526783051, 0.9992549120051456, 0.999185191706615, 0.9990739920168278, 0.9983416790618402, 1.0000840556915411, 0.9990209362504138, 0.9994575912631974, 0.9991360137281797, 0.9982695559315785, 0.9999622000770473, 0.9994269590295498, 0.9996952832771883, 0.999741333982082, 0.9989258609636772, 0.9991778116053948, 0.9987291389544485, 0.9995875120652248, 0.9992520148943227, 0.9994977135122299, 0.9997552748862605, 1.0001177995959851, 0.9999080284708421, 0.9999895289501377, 0.9986436786647132, 0.9990041882323119, 1.0001259990399496, 1.0001207987340828, 0.9999645452175766, 1.0001689011575001, 0.9996661168213126, 0.9995715059676942, 0.9994044917906945, 0.9999914487720631, 0.9984804515431185, 0.9999866693602187, 0.999620802865204, 1.0001708706566224, 1.000145453977297, 0.9998828074590229, 0.9994580931674942, 1.0000216765828125, 0.9990740014422664, 1.000058732706297, 0.9993710767677303, 0.9993167482542422, 0.9993652667296813, 0.9986707847105941, 0.9989576304336448, 0.9997026590488716, 1.000115180397882, 0.9999225185059543, 0.9999093815005196, 0.9998015141645293, 0.9995837775173303, 0.9993960318357121, 1.0000681630603094, 0.9999381721038527, 0.9997052252498324, 0.9985156182872635, 0.9997638053281034, 1.0002954769264958, 0.9999363251589958, 0.9994766206103004, 0.9996352038084036, 1.0002929023293639, 0.9993336210142943, 0.9996968814310832, 0.9998536793411156, 0.999163427770232, 1.000525000619599, 0.9976871490007732, 0.9987063864731331, 0.9994956333455085, 0.9988775930696893, 1.0003098973634668, 0.9997678486412859, 0.9996409376060619, 1.000201860090477, 1.0000631444194112, 0.9990931256915642, 0.9982293187512926, 0.9993872800962286, 0.9991500444619991, 1.0002982347262133, 0.9990384697813125, 1.000156937215171, 0.9990667592500225, 1.000130823330149, 0.9999298990831776, 1.0000006024302148, 0.999573233328574, 0.9996596585936909, 1.0001631514383198, 1.0001925356522285, 0.9990538155578846, 1.0004300611247268, 0.9996790689575947, 0.9997880486236357, 0.999381772899311, 0.9996499302624869, 1.0000862633909622, 0.9988810128450014, 0.999445657982763, 0.9990045962701493, 1.0002203379473822, 0.999542067985687, 1.0003332896388586, 1.000138521522509, 0.9993656420411872, 0.9996928260286868, 0.9997332562388077, 0.9995310058803747, 0.9995495852528414, 0.9996824729948123, 0.9998585900902663, 0.9997780304521113, 0.9986201617103572, 0.9997429572976481, 0.9999912821360517, 0.9979496966340885, 0.9980038042615497, 0.9988945688674736, 0.99873688433364, 0.9998821743953732, 0.9996436153687958, 0.9996507170370347, 0.9997912507904608, 0.999622908284119, 1.000374187502146, 0.9997768334553533, 0.9983983329417758, 0.0016142252755727985, 0.9981779983826696, 0.9993581907833623, 1.0004571013282963, 0.9991683670438511, 0.9980518888431982, 0.9990909289974869, 0.9996833978188342, 0.9997087274061711, 0.9997326386446543, 0.9997840649439766, 0.9985862557644181, 0.9994278696421622, 0.9982896450548614, 1.0003101315778515, 1.0004654797570154, 0.9994374956190313, 0.9999691041892833, 0.9995185886431983, 0.9992735095655326, 0.9994111587207657, 0.9999888526621368, 0.9999649824186786, 0.9988475785904917, 1.0000639038149768, 0.999692641297319, 0.9998542513857783, 0.9995496690953708, 0.9991873070448708, 0.9998641969212174, 0.9995129185560176, 0.00043368605658116317, 6.672093178171742e-05, 1.0000858381999829, 0.9974083977885776, 0.9998988467644521, 0.999772218299103, 0.99865214416167, 0.999160648219903, 0.9999328217420741, 0.9994901231888578, 0.9987064387297918, 1.0000057324292426, 0.998655688540458, 0.9994245923437833, 1.0002203379473948, 1.0000161889062116, 0.9987767361873405, 0.9997882151294777, 1.0005498470141672, 1.0001899154095406, 1.000096033820962, 0.999652827392509, 1.0000920399363609, 0.9996041100718122, 1.0000204657601701, 0.9987724887038937, 0.9991174927108476, 1.00019825853948, 1.0004511374360687, 0.9998881879734989, 0.9984577856594534, 0.9996771876432798, 0.9998988595366293, 0.999909501025486, 0.9990406293974733, 0.9999905114536498, 0.9986244190041488, 0.998493580776228, 0.9981273185988461, 0.9993346105752016, 0.9999380606465919, 0.998865351593783, 0.9998660817008088, 0.9986959270767259, 0.9988242345026612, 0.9999172764576151, 0.9991847290627706, 1.0000192793901705, 0.9999450611213517, 0.9999862215751397, 1.0001806209562225, 1.00039136678706, 0.999685620458684, 1.0001411814693841, 0.9997971401502181, 0.9997130652251337, 0.9988804899748124, 0.9996352038083911, 0.9983740026342766, 0.9999894948291208, 1.0003608199595748, 0.9996186598506874, 0.9998244245727266, 0.9994931819824111, 1.0004246860209667, 0.9989251097382191, 1.000448574313132, 1.000474152343848, 1.000106196844671, 0.9991360137281068, 1.0001825807925144, 1.0003906447330952, 0.9993055742799063, 0.9996017040289386, 0.9994578613386765, 0.9990425372295085, 0.9996591454824492, 0.9994667010023067, 0.9999031245543042, 0.9998303544468036, 0.9999760180313033, 0.9999611196140928, 0.9986260492022947, 0.9994834243384827, 0.998925860963599, 1.0005485350690508, 1.0001192828001322, 0.9995924589343985, 1.0000227446621353, 0.9997992939261104, 0.9997491078695744, 0.9993880150316666, 0.9992848515228678, 0.9986381970608587, 1.0001366260755256, 0.9987538359164729, 0.9995875120652323, 1.0000739014296487, 0.9999084252126349, 0.9999450575264793, 1.0002442889895247, 0.999196172826064, 0.9993702082792966, 0.9984405611182854, 1.0000732542355415, 0.9997415366453668, 0.9990648401938617, 0.023357110653503585, 0.9771057956715666, 0.9995827422935196, 0.9996625232071606, 0.9992357212400066, 0.9992348345748712, 0.9991851917065951, 0.9999992381509767, 1.0000193516260336, 0.9999257690667532, 1.0001215719941776, 0.9996690836938678, 0.999363587981995, 0.9993376590686379, 1.0002543902851044, 1.000196148597142, 0.99869651894958, 0.998282517973501, 0.9995538520446188, 0.9976847934791163, 0.9997314188417423, 0.9996200053384596, 0.997543774195361, 0.9994261148008993, 0.9997733646354685, 0.9994728041684269, 0.9994276935563664, 0.999926148238802, 1.0000202988265265, 0.9996863386462309, 1.0000982025771008, 0.9999066878693459, 0.9995340678088113, 0.9983633063451667, 0.9973151673911168, 0.9994388512842793, 0.9988602544683199, 1.0000095759290766, 0.9991303507396037, 0.9980550196768789, 1.0001326043125705, 0.9995006159981857, 0.9993337751288464, 0.9989397290024921, 0.998952071081692, 0.9991089397398516, 0.999001859646974, 1.000290867761518, 1.0003214694055964, 1.0002484698743674, 0.9999765401987235, 1.0000521340327686, 0.999994789330251, 0.9996186025069698, 0.9982831520750094, 0.9993638864784222, 0.9999029969890392, 0.9993460597056434, 0.9996333987241235, 0.9995920828254812, 0.9999017769370535, 1.0003850068829248, 0.9994016599809951, 0.9993190816733706, 0.9997893794251071, 1.0000119275724246, 0.999360563079163, 0.9993070265042946, 1.0001217228302952, 0.9998577590583982, 0.9998301128296146, 1.0000003288204173, 0.9993047644204226, 0.9997443696934393, 0.9997358283047707, 0.9997807701034792, 0.9998691658948411, 0.9982839145225781, 0.99995067820234, 0.9992406457293063, 0.9999728106023411, 0.9999908721625294, 0.9986769838549077, 0.9987459593130191, 1.000084055691445, 0.9999867109961859, 1.0005620456153812, 0.9998534997378328, 0.9996171814438336, 1.000322151303039, 0.9993559922053032, 0.9992493070559785, 0.9985785415814074, 0.9998108348928986, 1.0003408664349727, 1.0001030348036228, 0.9992933083015988, 0.9990932517632299, 0.9987250759751708, 0.9997651621279607, 0.9985493003494049, 0.013061805749576234, 0.9852757564282618, 0.0003958122954417041, 0.0005937184431625562, 0.0005937184431625562, 9.895307386042602e-05, 0.9999842794619064, 0.9984212384422695, 0.9985733533376727, 0.999797356328209, 0.9998341271771192, 1.0003287272153722, 1.0005364040427183, 0.9993152625719202, 0.9996613243448571, 0.9994423656858722, 0.9995347142686491, 0.9992507342905184, 0.9997597540876026, 1.000487097904584, 0.9991809073843313, 0.9994250476869642, 0.9997460469916107, 0.999826686598459], \"Term\": [\"19\", \"3d\", \"3d\", \"accuracy\", \"accurate\", \"action\", \"active\", \"activity\", \"adaptation\", \"adaptive\", \"adversarial\", \"agent\", \"agents\", \"agnostic\", \"ai\", \"algorithm\", \"algorithms\", \"alignment\", \"analysis\", \"analytics\", \"anomaly\", \"application\", \"applications\", \"approach\", \"approaches\", \"approximate\", \"approximation\", \"architecture\", \"architectures\", \"artificial\", \"artificial\", \"assessment\", \"attack\", \"attacks\", \"attention\", \"audio\", \"augmentation\", \"auto\", \"autoencoder\", \"autoencoders\", \"automated\", \"automatic\", \"autonomous\", \"aware\", \"bandit\", \"bandits\", \"based\", \"batch\", \"bayesian\", \"behavior\", \"benchmark\", \"better\", \"bias\", \"binary\", \"black\", \"boosting\", \"bounds\", \"box\", \"brain\", \"case\", \"causal\", \"channel\", \"class\", \"classification\", \"classifier\", \"classifiers\", \"clinical\", \"cloud\", \"clustering\", \"cnn\", \"cnns\", \"code\", \"coding\", \"collaborative\", \"communication\", \"comparison\", \"complex\", \"complexity\", \"compression\", \"computational\", \"computer\", \"computing\", \"conditional\", \"consistency\", \"constrained\", \"constraints\", \"context\", \"contextual\", \"continual\", \"continuous\", \"contrastive\", \"control\", \"convergence\", \"convex\", \"convolutional\", \"cost\", \"counterfactual\", \"covid\", \"cross\", \"data\", \"dataset\", \"datasets\", \"decision\", \"decomposition\", \"deep\", \"density\", \"depth\", \"descent\", \"design\", \"detecting\", \"detection\", \"diagnosis\", \"differentiable\", \"differential\", \"diffusion\", \"dimensional\", \"discovery\", \"discrete\", \"disease\", \"distance\", \"distillation\", \"distributed\", \"distribution\", \"domain\", \"driven\", \"driving\", \"dual\", \"dynamic\", \"dynamics\", \"edge\", \"eeg\", \"effective\", \"effects\", \"efficient\", \"embedding\", \"embeddings\", \"emotion\", \"empirical\", \"end\", \"energy\", \"ensemble\", \"ensembles\", \"entity\", \"entropy\", \"environments\", \"equations\", \"error\", \"estimation\", \"evaluating\", \"evaluation\", \"event\", \"examples\", \"explainable\", \"explanations\", \"exploration\", \"exploring\", \"extraction\", \"factorization\", \"fairness\", \"fast\", \"feature\", \"features\", \"federated\", \"feedback\", \"fine\", \"flexible\", \"flow\", \"flows\", \"forecasting\", \"framework\", \"free\", \"function\", \"functions\", \"fusion\", \"games\", \"gan\", \"gans\", \"gaussian\", \"general\", \"generalization\", \"generalized\", \"generation\", \"generative\", \"geometric\", \"global\", \"gradient\", \"graph\", \"graphs\", \"group\", \"guarantees\", \"guided\", \"hardware\", \"health\", \"heterogeneous\", \"hidden\", \"hierarchical\", \"high\", \"human\", \"hybrid\", \"identification\", \"identifying\", \"image\", \"images\", \"images\", \"imaging\", \"imitation\", \"impact\", \"implicit\", \"improve\", \"improved\", \"improving\", \"incremental\", \"inference\", \"information\", \"informed\", \"input\", \"intelligence\", \"intelligent\", \"interactive\", \"interpretable\", \"invariant\", \"inverse\", \"joint\", \"kernel\", \"knowledge\", \"label\", \"labels\", \"language\", \"large\", \"latent\", \"layer\", \"learn\", \"learned\", \"learning\", \"learning\", \"learning\", \"level\", \"likelihood\", \"linear\", \"local\", \"localization\", \"long\", \"loss\", \"low\", \"lstm\", \"machine\", \"machines\", \"making\", \"manifold\", \"markov\", \"matching\", \"matrix\", \"maximum\", \"mean\", \"medical\", \"memory\", \"meta\", \"method\", \"methods\", \"metric\", \"minimization\", \"mining\", \"mixed\", \"mixture\", \"mobile\", \"modal\", \"model\", \"modeling\", \"modelling\", \"models\", \"molecular\", \"monitoring\", \"motion\", \"mri\", \"multi\", \"multimodal\", \"multiple\", \"multivariate\", \"music\", \"natural\", \"net\", \"network\", \"networks\", \"neural\", \"new\", \"node\", \"noise\", \"noisy\", \"non\", \"nonlinear\", \"novel\", \"object\", \"objective\", \"online\", \"open\", \"optimal\", \"optimization\", \"order\", \"parallel\", \"parameter\", \"partial\", \"pattern\", \"performance\", \"personalized\", \"perspective\", \"phase\", \"physics\", \"planning\", \"point\", \"policies\", \"policy\", \"power\", \"pre\", \"precision\", \"predicting\", \"prediction\", \"predictions\", \"predictive\", \"preserving\", \"prior\", \"privacy\", \"private\", \"probabilistic\", \"problem\", \"problems\", \"process\", \"processes\", \"processing\", \"programming\", \"pruning\", \"quality\", \"quantization\", \"quantum\", \"random\", \"rank\", \"ranking\", \"real\", \"reasoning\", \"recognition\", \"recommendation\", \"reconstruction\", \"recurrent\", \"recurrent\", \"reduction\", \"regression\", \"regret\", \"regularization\", \"regularized\", \"reinforcement\", \"relational\", \"representation\", \"representations\", \"residual\", \"resolution\", \"resource\", \"response\", \"retrieval\", \"review\", \"reward\", \"risk\", \"robot\", \"robust\", \"robustness\", \"safe\", \"sample\", \"sampling\", \"scalable\", \"scale\", \"search\", \"segmentation\", \"selection\", \"self\", \"semantic\", \"semi\", \"sensing\", \"sensitive\", \"sequence\", \"sequential\", \"series\", \"set\", \"shift\", \"short\", \"shot\", \"signal\", \"signals\", \"similarity\", \"simple\", \"single\", \"smart\", \"social\", \"solving\", \"source\", \"space\", \"sparse\", \"spatial\", \"speaker\", \"spectral\", \"speech\", \"stability\", \"state\", \"statistical\", \"stochastic\", \"structural\", \"structure\", \"structured\", \"study\", \"supervised\", \"supervision\", \"support\", \"survey\", \"synthesis\", \"systems\", \"task\", \"tasks\", \"techniques\", \"temporal\", \"tensor\", \"term\", \"testing\", \"text\", \"theory\", \"time\", \"topological\", \"tracking\", \"traffic\", \"trained\", \"training\", \"trajectory\", \"transfer\", \"transformer\", \"transformers\", \"translation\", \"tree\", \"trees\", \"tuning\", \"type\", \"uncertainty\", \"understanding\", \"unified\", \"universal\", \"unsupervised\", \"user\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"value\", \"variable\", \"variance\", \"variational\", \"vector\", \"vehicle\", \"verification\", \"video\", \"view\", \"vision\", \"visual\", \"wasserstein\", \"weighted\", \"wireless\", \"wise\", \"word\", \"world\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 5, 10, 11, 15, 3, 2, 9, 4, 14, 13, 6, 7, 1, 12]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el4775713135100880484769392\", ldavis_el4775713135100880484769392_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el4775713135100880484769392\", ldavis_el4775713135100880484769392_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el4775713135100880484769392\", ldavis_el4775713135100880484769392_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster      Freq\n",
              "topic                                               \n",
              "7      0.154244  0.053666       1        1  8.307789\n",
              "4      0.124007 -0.330255       2        1  6.922976\n",
              "9     -0.207419 -0.169428       3        1  6.859198\n",
              "10    -0.108508  0.469022       4        1  6.808853\n",
              "14     0.373255 -0.356896       5        1  6.798789\n",
              "2      0.414070 -0.129103       6        1  6.771714\n",
              "1      0.141519  0.464323       7        1  6.754435\n",
              "8     -0.286902 -0.412665       8        1  6.636832\n",
              "3     -0.472878  0.109715       9        1  6.406671\n",
              "13     0.346835  0.328604      10        1  6.386406\n",
              "12     0.486313  0.111240      11        1  6.368452\n",
              "5     -0.127297  0.169579      12        1  6.366238\n",
              "6     -0.470450 -0.153065      13        1  6.336056\n",
              "0     -0.353291  0.347512      14        1  6.333101\n",
              "11    -0.013497 -0.502248      15        1  5.942488, topic_info=                Term          Freq         Total Category  logprob  loglift\n",
              "2796        learning  29975.000000  29975.000000  Default  30.0000  30.0000\n",
              "3327          neural  13960.000000  13960.000000  Default  29.0000  29.0000\n",
              "1267            deep  13878.000000  13878.000000  Default  28.0000  28.0000\n",
              "3326        networks  12506.000000  12506.000000  Default  27.0000  27.0000\n",
              "455            based  11028.000000  11028.000000  Default  26.0000  26.0000\n",
              "...              ...           ...           ...      ...      ...      ...\n",
              "3834     predictions    414.289556    414.569598  Topic15  -4.7787   2.8224\n",
              "4201      relational    409.712023    409.992066  Topic15  -4.7899   2.8224\n",
              "3188       molecular    398.268193    398.548235  Topic15  -4.8182   2.8223\n",
              "2465     incremental    394.835044    395.115086  Topic15  -4.8268   2.8223\n",
              "1115  counterfactual    373.091765    373.371808  Topic15  -4.8835   2.8223\n",
              "\n",
              "[486 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "4         1  1.000176        19\n",
              "17       11  0.992376        3d\n",
              "17       12  0.007776        3d\n",
              "61       10  0.998800  accuracy\n",
              "62       13  0.998562  accurate\n",
              "...     ...       ...       ...\n",
              "5559      4  1.000487  wireless\n",
              "5561      5  0.999181      wise\n",
              "5564     11  0.999425      word\n",
              "5577      1  0.999746     world\n",
              "5597     11  0.999827      zero\n",
              "\n",
              "[466 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 5, 10, 11, 15, 3, 2, 9, 4, 14, 13, 6, 7, 1, 12])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.lda_model\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "pyLDAvis.lda_model.prepare(lda_model, X, vectorizer, mds='mmds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpGMMnK0Nv9t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}